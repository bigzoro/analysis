package db

import (
	"fmt"
	"log"
	"math"
	"math/rand"
	"strings"
	"time"

	"gorm.io/gorm"
)

// deduplicateKlines å»é‡Kçº¿æ•°æ®ï¼ŒåŸºäº(symbol, kind, interval, open_time)çš„ç»„åˆ
func deduplicateKlines(klines []MarketKline) []MarketKline {
	if len(klines) <= 1 {
		return klines
	}

	// ä½¿ç”¨mapæ¥è·Ÿè¸ªå”¯ä¸€è®°å½•
	seen := make(map[string]MarketKline)
	var result []MarketKline

	for _, kline := range klines {
		// åˆ›å»ºå”¯ä¸€é”®
		key := fmt.Sprintf("%s:%s:%s:%d",
			kline.Symbol,
			kline.Kind,
			kline.Interval,
			kline.OpenTime.Unix())

		// å¦‚æœè¿™ä¸ªé”®è¿˜æ²¡æœ‰å‡ºç°è¿‡ï¼Œæˆ–è€…æ–°è®°å½•çš„æ›´æ–°æ—¶é—´æ›´æ™šï¼Œåˆ™ä¿ç•™
		if existing, exists := seen[key]; !exists {
			seen[key] = kline
			result = append(result, kline)
		} else {
			// å¦‚æœå·²å­˜åœ¨ç›¸åŒè®°å½•ï¼Œä¿ç•™æ›´æ–°æ—¶é—´æ›´æ™šçš„é‚£ä¸ª
			if kline.UpdatedAt.After(existing.UpdatedAt) {
				seen[key] = kline
				// æ›´æ–°resultä¸­çš„è®°å½•ï¼ˆéœ€è¦æ‰¾åˆ°å¹¶æ›¿æ¢ï¼‰
				for i, r := range result {
					if r.Symbol == kline.Symbol && r.Kind == kline.Kind &&
						r.Interval == kline.Interval && r.OpenTime.Equal(kline.OpenTime) {
						result[i] = kline
						break
					}
				}
			}
		}
	}

	return result
}

// insertKlinesBatch ä½¿ç”¨INSERT ... ON DUPLICATE KEY UPDATEæ‰¹é‡æ’å…¥Kçº¿æ•°æ®
// ä½¿ç”¨æ›´å®‰å…¨çš„upsertç­–ç•¥é¿å…æ­»é”
func insertKlinesBatch(tx *gorm.DB, klines []MarketKline) error {
	if len(klines) == 0 {
		return nil
	}

	// æ„å»ºINSERT ... ON DUPLICATE KEY UPDATEè¯­å¥
	var valueStrings []string
	var valueArgs []interface{}

	for _, kline := range klines {
		valueStrings = append(valueStrings, "(?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)")
		valueArgs = append(valueArgs,
			kline.Symbol, kline.Kind, kline.Interval, kline.OpenTime,
			kline.OpenPrice, kline.HighPrice, kline.LowPrice, kline.ClosePrice,
			kline.Volume, kline.QuoteVolume, kline.TradeCount,
			kline.TakerBuyVolume, kline.TakerBuyQuoteVolume,
			kline.CreatedAt, kline.UpdatedAt)
	}

	query := fmt.Sprintf(`INSERT INTO market_klines
		(symbol, kind, `+"`interval`"+`, open_time, open_price, high_price, low_price, close_price, volume, quote_volume, trade_count, taker_buy_volume, taker_buy_quote_volume, created_at, updated_at)
		VALUES %s
		ON DUPLICATE KEY UPDATE
			open_price = VALUES(open_price),
			high_price = VALUES(high_price),
			low_price = VALUES(low_price),
			close_price = VALUES(close_price),
			volume = VALUES(volume),
			quote_volume = VALUES(quote_volume),
			trade_count = VALUES(trade_count),
			taker_buy_volume = VALUES(taker_buy_volume),
			taker_buy_quote_volume = VALUES(taker_buy_quote_volume),
			updated_at = VALUES(updated_at)`,
		strings.Join(valueStrings, ", "))

	return tx.Exec(query, valueArgs...).Error
}

// insertSingleKlineUpsert ä½¿ç”¨INSERT ... ON DUPLICATE KEY UPDATEæ’å…¥å•æ¡Kçº¿æ•°æ®
// è¿™ç§æ–¹å¼æ¯”INSERT IGNOREæ›´å®‰å…¨ï¼Œé¿å…æ­»é”é—®é¢˜
func insertSingleKlineUpsert(tx *gorm.DB, kline MarketKline) error {
	query := `INSERT INTO market_klines
		(symbol, kind, ` + "`interval`" + `, open_time, open_price, high_price, low_price, close_price, volume, quote_volume, trade_count, taker_buy_volume, taker_buy_quote_volume, created_at, updated_at)
		VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
		ON DUPLICATE KEY UPDATE
			open_price = VALUES(open_price),
			high_price = VALUES(high_price),
			low_price = VALUES(low_price),
			close_price = VALUES(close_price),
			volume = VALUES(volume),
			quote_volume = VALUES(quote_volume),
			trade_count = VALUES(trade_count),
			taker_buy_volume = VALUES(taker_buy_volume),
			taker_buy_quote_volume = VALUES(taker_buy_quote_volume),
			updated_at = VALUES(updated_at)`

	return tx.Exec(query,
		kline.Symbol, kline.Kind, kline.Interval, kline.OpenTime,
		kline.OpenPrice, kline.HighPrice, kline.LowPrice, kline.ClosePrice,
		kline.Volume, kline.QuoteVolume, kline.TradeCount,
		kline.TakerBuyVolume, kline.TakerBuyQuoteVolume,
		kline.CreatedAt, kline.UpdatedAt).Error
}

// insertSingleKlineIgnore ä¿ç•™åŸæœ‰å‡½æ•°ä»¥å‘åå…¼å®¹ï¼Œä½†å†…éƒ¨ä½¿ç”¨æ›´å®‰å…¨çš„upsert
func insertSingleKlineIgnore(tx *gorm.DB, kline MarketKline) error {
	return insertSingleKlineUpsert(tx, kline)
}

// isUniqueConstraintError æ£€æŸ¥é”™è¯¯æ˜¯å¦æ˜¯å”¯ä¸€ç´¢å¼•å†²çª
func isUniqueConstraintError(err error) bool {
	if err == nil {
		return false
	}

	errStr := strings.ToLower(err.Error())

	// MySQLå”¯ä¸€çº¦æŸé”™è¯¯
	if strings.Contains(errStr, "duplicate entry") ||
		strings.Contains(errStr, "unique constraint") ||
		strings.Contains(errStr, "duplicate key") {
		return true
	}

	// PostgreSQLå”¯ä¸€çº¦æŸé”™è¯¯
	if strings.Contains(errStr, "unique_violation") ||
		strings.Contains(errStr, "duplicate key value") {
		return true
	}

	// SQLiteå”¯ä¸€çº¦æŸé”™è¯¯
	if strings.Contains(errStr, "unique constraint failed") ||
		strings.Contains(errStr, "constraint failed") {
		return true
	}

	return false
}

// ============================================================================
// Kçº¿æ•°æ®å­˜å‚¨å’ŒæŸ¥è¯¢
// ============================================================================

// MarketKline Kçº¿æ•°æ®æ¨¡å‹
type MarketKline struct {
	ID                  uint      `gorm:"primaryKey" json:"id"`
	Symbol              string    `gorm:"size:32;index:idx_symbol_kind_interval_time,priority:1" json:"symbol"`
	Kind                string    `gorm:"size:16;index:idx_symbol_kind_interval_time,priority:2;index:idx_kind_interval_time,priority:1" json:"kind"`
	Interval            string    `gorm:"size:8;index:idx_symbol_kind_interval_time,priority:3;index:idx_kind_interval_time,priority:2" json:"interval"`
	OpenTime            time.Time `gorm:"index:idx_symbol_kind_interval_time,priority:4;index:idx_symbol_time,priority:2;index:idx_kind_interval_time,priority:3" json:"open_time"`
	OpenPrice           string    `gorm:"size:32" json:"open_price"`
	HighPrice           string    `gorm:"size:32" json:"high_price"`
	LowPrice            string    `gorm:"size:32" json:"low_price"`
	ClosePrice          string    `gorm:"size:32" json:"close_price"`
	Volume              string    `gorm:"size:32" json:"volume"`
	QuoteVolume         *string   `gorm:"size:32" json:"quote_volume,omitempty"`
	TradeCount          *int      `json:"trade_count,omitempty"`
	TakerBuyVolume      *string   `gorm:"size:32" json:"taker_buy_volume,omitempty"`
	TakerBuyQuoteVolume *string   `gorm:"size:32" json:"taker_buy_quote_volume,omitempty"`
	CreatedAt           time.Time `json:"created_at"`
	UpdatedAt           time.Time `json:"updated_at"`
}

// TechnicalIndicatorsCache æŠ€æœ¯æŒ‡æ ‡ç¼“å­˜æ¨¡å‹
type TechnicalIndicatorsCache struct {
	ID           uint      `gorm:"primaryKey" json:"id"`
	Symbol       string    `gorm:"size:32;index:idx_symbol_kind_updated,priority:1" json:"symbol"`
	Kind         string    `gorm:"size:16;index:idx_symbol_kind_updated,priority:2" json:"kind"`
	Interval     string    `gorm:"size:8" json:"interval"`
	DataPoints   int       `gorm:"index:uk_symbol_kind_interval_data_points,priority:4" json:"data_points"`
	Indicators   []byte    `gorm:"type:json" json:"indicators"` // JSONæ•°æ®
	CalculatedAt time.Time `gorm:"index:idx_calculated_at" json:"calculated_at"`
	DataFrom     time.Time `json:"data_from"`
	DataTo       time.Time `json:"data_to"`
	CreatedAt    time.Time `json:"created_at"`
	UpdatedAt    time.Time `json:"updated_at"`
}

// PriceCache ä»·æ ¼ç¼“å­˜æ¨¡å‹
type PriceCache struct {
	ID             uint      `gorm:"primaryKey" json:"id"`
	Symbol         string    `gorm:"size:32;uniqueIndex:uk_symbol_kind" json:"symbol"`
	Kind           string    `gorm:"size:16;uniqueIndex:uk_symbol_kind" json:"kind"`
	Price          string    `gorm:"size:32" json:"price"`
	PriceChange24h *string   `gorm:"column:price_change_24h;size:16" json:"price_change_24h,omitempty"`
	LastUpdated    time.Time `gorm:"index:idx_last_updated" json:"last_updated"`
	CreatedAt      time.Time `json:"created_at"`
	UpdatedAt      time.Time `json:"updated_at"`
}

// ============================================================================
// Kçº¿æ•°æ®æ“ä½œ
// ============================================================================

// SaveMarketKlines æ‰¹é‡ä¿å­˜Kçº¿æ•°æ®ï¼ˆè¦†ç›–æ¨¡å¼ï¼ŒåŒæ—¶é—´ç‚¹æ•°æ®ä¼šè¢«æ›¿æ¢ï¼‰
func SaveMarketKlines(gdb *gorm.DB, klines []MarketKline) error {
	if len(klines) == 0 {
		return nil
	}

	// å»é‡å¤„ç†ï¼šç§»é™¤é‡å¤çš„Kçº¿æ•°æ®
	uniqueKlines := deduplicateKlines(klines)
	if len(uniqueKlines) != len(klines) {
		log.Printf("[SaveMarketKlines] Removed %d duplicate klines from batch, saving %d unique records",
			len(klines)-len(uniqueKlines), len(uniqueKlines))
	}

	// ä¼˜åŒ–äº‹åŠ¡ç­–ç•¥ï¼šæŒ‰äº¤æ˜“å¯¹åˆ†ç»„ï¼Œä½¿ç”¨æ›´å°çš„äº‹åŠ¡èŒƒå›´
	return saveMarketKlinesOptimized(gdb, uniqueKlines)
}

// saveMarketKlinesOptimized ä¼˜åŒ–ç‰ˆKçº¿ä¿å­˜ï¼šæŒ‰äº¤æ˜“å¯¹åˆ†ç»„äº‹åŠ¡ï¼Œè¿›ä¸€æ­¥åˆ†æ‰¹å¤„ç†å‡å°‘æ­»é”é£é™©
func saveMarketKlinesOptimized(gdb *gorm.DB, klines []MarketKline) error {
	if len(klines) == 0 {
		return nil
	}

	log.Printf("[SaveMarketKlines] Inserting %d unique klines with optimized transaction strategy", len(klines))

	// æŒ‰äº¤æ˜“å¯¹åˆ†ç»„Kçº¿æ•°æ®
	klinesBySymbol := groupKlinesBySymbol(klines)
	log.Printf("[SaveMarketKlines] Grouped into %d symbol groups for smaller transactions", len(klinesBySymbol))

	totalInserted := 0
	totalErrors := 0
	errorStats := make(map[string]int)

	// ä¸ºæ¯ä¸ªäº¤æ˜“å¯¹ä½¿ç”¨ç‹¬ç«‹çš„å°äº‹åŠ¡ï¼Œåˆ†æ‰¹å¤„ç†Kçº¿æ•°æ®
	for symbol, symbolKlines := range klinesBySymbol {
		log.Printf("[SaveMarketKlines] Processing symbol %s: %d klines", symbol, len(symbolKlines))

		symbolInserted, symbolErrors := saveSymbolKlinesInBatches(gdb, symbol, symbolKlines)
		totalInserted += symbolInserted
		totalErrors += symbolErrors

		// å°å»¶è¿Ÿé¿å…å¯¹æ•°æ®åº“é€ æˆè¿‡å¤§å‹åŠ›
		time.Sleep(5 * time.Millisecond)
	}

	log.Printf("[SaveMarketKlines] Successfully processed %d out of %d klines, %d errors",
		totalInserted, len(klines), totalErrors)

	// è¾“å‡ºé”™è¯¯ç»Ÿè®¡æ‘˜è¦
	if totalErrors > 0 {
		log.Printf("[SaveMarketKlines] é”™è¯¯ç»Ÿè®¡æ‘˜è¦:")
		for errorType, count := range errorStats {
			log.Printf("[SaveMarketKlines]   %s: %d æ¬¡", errorType, count)
		}

		if totalInserted > 0 {
			log.Printf("[SaveMarketKlines] éƒ¨åˆ†æˆåŠŸ: %d æ¡æ’å…¥æˆåŠŸ, %d æ¡å¤±è´¥", totalInserted, totalErrors)
		} else {
			log.Printf("[SaveMarketKlines] å®Œå…¨å¤±è´¥: æ‰€æœ‰ %d æ¡è®°å½•æ’å…¥å¤±è´¥", totalErrors)
			return fmt.Errorf("all %d kline insertions failed", totalErrors)
		}
	}

	return nil
}

// saveSymbolKlinesInBatches å°†å•ä¸ªäº¤æ˜“å¯¹çš„Kçº¿æ•°æ®åˆ†æ‰¹ä¿å­˜ï¼Œè¿›ä¸€æ­¥å‡å°‘æ­»é”é£é™©
func saveSymbolKlinesInBatches(gdb *gorm.DB, symbol string, klines []MarketKline) (int, int) {
	if len(klines) == 0 {
		return 0, 0
	}

	// è®¾ç½®æ‰¹æ¬¡å¤§å°ï¼šå•æ¡æ’å…¥é¿å…æ­»é”ï¼Œ10æ¡ä¸€æ‰¹å¹³è¡¡æ€§èƒ½
	batchSize := 10
	totalInserted := 0
	totalErrors := 0

	// åˆ†æ‰¹å¤„ç†
	for i := 0; i < len(klines); i += batchSize {
		end := i + batchSize
		if end > len(klines) {
			end = len(klines)
		}

		batchKlines := klines[i:end]
		batchInserted, batchErrors := saveKlineBatch(gdb, symbol, batchKlines)
		totalInserted += batchInserted
		totalErrors += batchErrors

		// æ‰¹æ¬¡é—´å°å»¶è¿Ÿ
		if i+batchSize < len(klines) {
			time.Sleep(1 * time.Millisecond)
		}
	}

	return totalInserted, totalErrors
}

// saveKlineBatch ä¿å­˜ä¸€æ‰¹Kçº¿æ•°æ®ï¼Œä½¿ç”¨å•ä¸ªäº‹åŠ¡
func saveKlineBatch(gdb *gorm.DB, symbol string, klines []MarketKline) (int, int) {
	if len(klines) == 0 {
		return 0, 0
	}

	err := gdb.Transaction(func(tx *gorm.DB) error {
		// è®¾ç½®æ—¶é—´æˆ³
		now := time.Now()
		for i := range klines {
			klines[i].CreatedAt = now
			klines[i].UpdatedAt = now
		}

		inserted := 0
		errors := 0

		// å•æ¡æ’å…¥ï¼Œé¿å…æ‰¹é‡æ“ä½œçš„æ­»é”é£é™©
		for i, kline := range klines {
			err := insertKlineWithSmartRetry(tx, kline, i+1, len(klines))
			if err != nil {
				errors++
				errorType := classifyDatabaseError(err)
				if errorType == "deadlock" {
					log.Printf("[SaveMarketKlines] ğŸ”´ æ­»é”é”™è¯¯ %s %d/%d: %s %s %s %v",
						symbol, i+1, len(klines), kline.Symbol, kline.Kind, kline.Interval, kline.OpenTime)
				}
			} else {
				inserted++
			}
		}

		if inserted == 0 && len(klines) > 0 {
			return fmt.Errorf("all %d kline insertions failed for symbol %s", len(klines), symbol)
		}

		return nil
	})

	if err != nil {
		log.Printf("[SaveMarketKlines] Transaction failed for symbol %s batch: %v", symbol, err)
		return 0, len(klines)
	}

	return len(klines), 0 // å‡è®¾äº‹åŠ¡æˆåŠŸï¼Œæ‰€æœ‰è®°å½•éƒ½æ’å…¥äº†
}

// groupKlinesBySymbol æŒ‰äº¤æ˜“å¯¹åˆ†ç»„Kçº¿æ•°æ®
func groupKlinesBySymbol(klines []MarketKline) map[string][]MarketKline {
	groups := make(map[string][]MarketKline)

	for _, kline := range klines {
		key := kline.Symbol + "_" + kline.Kind // ä½¿ç”¨ symbol_kind ä½œä¸ºåˆ†ç»„é”®
		groups[key] = append(groups[key], kline)
	}

	return groups
}

// insertKlineWithSmartRetry ä½¿ç”¨æ™ºèƒ½é‡è¯•ç­–ç•¥æ’å…¥å•æ¡Kçº¿æ•°æ®
func insertKlineWithSmartRetry(tx *gorm.DB, kline MarketKline, index, total int) error {
	maxRetries := 10                    // è¿›ä¸€æ­¥å¢åŠ æœ€å¤§é‡è¯•æ¬¡æ•°
	baseDelay := 500 * time.Millisecond // å¢åŠ åŸºç¡€å»¶è¿Ÿ

	for attempt := 1; attempt <= maxRetries; attempt++ {
		err := insertSingleKlineUpsert(tx, kline)
		if err == nil {
			// æˆåŠŸæ’å…¥
			if attempt > 1 {
				log.Printf("[SaveMarketKlines] Successfully inserted kline after %d attempts for %s %s %s %v",
					attempt, kline.Symbol, kline.Kind, kline.Interval, kline.OpenTime)
			}
			return nil
		}

		// åˆ†æé”™è¯¯ç±»å‹
		errorType := classifyDatabaseError(err)

		// æ ¹æ®é”™è¯¯ç±»å‹å†³å®šæ˜¯å¦é‡è¯•
		if !isRetryableError(errorType) || attempt == maxRetries {
			// ä¸å¯é‡è¯•çš„é”™è¯¯æˆ–å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°
			log.Printf("[SaveMarketKlines] Failed to insert kline after %d attempts for %s %s %s %v: %v (error type: %s)",
				attempt, kline.Symbol, kline.Kind, kline.Interval, kline.OpenTime, err, errorType)
			return err
		}

		// è®¡ç®—é‡è¯•å»¶è¿Ÿï¼ˆæŒ‡æ•°é€€é¿ + éšæœºæŠ–åŠ¨ï¼‰
		backoffDelay := calculateBackoffDelay(attempt, errorType, baseDelay)
		log.Printf("[SaveMarketKlines] Database error detected (%s), retrying %d/%d after %v for %s %s %s %v: %v",
			errorType, attempt, maxRetries, backoffDelay, kline.Symbol, kline.Kind, kline.Interval, kline.OpenTime, err)

		time.Sleep(backoffDelay)
	}

	// ä¸åº”è¯¥åˆ°è¾¾è¿™é‡Œ
	return fmt.Errorf("unexpected error in insertKlineWithSmartRetry")
}

// classifyDatabaseError åˆ†ç±»æ•°æ®åº“é”™è¯¯ç±»å‹
func classifyDatabaseError(err error) string {
	if err == nil {
		return "none"
	}

	errMsg := strings.ToLower(err.Error())

	// æ­»é”é”™è¯¯
	if strings.Contains(errMsg, "1213") || strings.Contains(errMsg, "deadlock") ||
		strings.Contains(errMsg, "try restarting transaction") || strings.Contains(errMsg, "40001") {
		return "deadlock"
	}

	// é”ç­‰å¾…è¶…æ—¶
	if strings.Contains(errMsg, "lock wait timeout") || strings.Contains(errMsg, "1205") {
		return "lock_timeout"
	}

	// è¿æ¥é”™è¯¯
	if strings.Contains(errMsg, "connection") || strings.Contains(errMsg, "dial tcp") ||
		strings.Contains(errMsg, "no such host") || strings.Contains(errMsg, "connection refused") {
		return "connection"
	}

	// ç½‘ç»œè¶…æ—¶
	if strings.Contains(errMsg, "timeout") || strings.Contains(errMsg, "i/o timeout") {
		return "network_timeout"
	}

	// å”¯ä¸€çº¦æŸå†²çªï¼ˆé€šå¸¸ä¸åº”è¯¥é‡è¯•ï¼‰
	if strings.Contains(errMsg, "duplicate entry") || strings.Contains(errMsg, "unique constraint") {
		return "unique_violation"
	}

	// å…¶ä»–æœåŠ¡å™¨é”™è¯¯
	if strings.Contains(errMsg, "server error") || strings.Contains(errMsg, "internal server error") {
		return "server_error"
	}

	// æœªçŸ¥é”™è¯¯
	return "unknown"
}

// isRetryableError åˆ¤æ–­é”™è¯¯æ˜¯å¦å¯ä»¥é‡è¯•
func isRetryableError(errorType string) bool {
	switch errorType {
	case "deadlock", "lock_timeout", "connection", "network_timeout", "server_error":
		return true
	case "unique_violation", "none", "unknown":
		return false
	default:
		return false
	}
}

// calculateBackoffDelay æ ¹æ®é”™è¯¯ç±»å‹å’Œå°è¯•æ¬¡æ•°è®¡ç®—é‡è¯•å»¶è¿Ÿ
func calculateBackoffDelay(attempt int, errorType string, baseDelay time.Duration) time.Duration {
	var multiplier float64

	// æ ¹æ®é”™è¯¯ç±»å‹è®¾ç½®ä¸åŒçš„åŸºç¡€ä¹˜æ•°
	switch errorType {
	case "deadlock":
		// æ­»é”éœ€è¦è¾ƒé•¿çš„ç­‰å¾…æ—¶é—´ï¼Œé¿å…ç«‹å³å†æ¬¡å†²çª
		multiplier = 2.0
	case "lock_timeout":
		// é”è¶…æ—¶ä¹Ÿéœ€è¦è¾ƒé•¿ç­‰å¾…
		multiplier = 1.8
	case "connection", "network_timeout":
		// ç½‘ç»œé—®é¢˜å¯ä»¥ä½¿ç”¨è¾ƒçŸ­çš„æŒ‡æ•°é€€é¿
		multiplier = 1.5
	case "server_error":
		// æœåŠ¡å™¨é”™è¯¯ä½¿ç”¨ä¸­ç­‰å»¶è¿Ÿ
		multiplier = 1.3
	default:
		multiplier = 1.2
	}

	// æŒ‡æ•°é€€é¿ï¼šdelay = baseDelay * multiplier^attempt
	delay := time.Duration(float64(baseDelay) * math.Pow(multiplier, float64(attempt-1)))

	// æ·»åŠ éšæœºæŠ–åŠ¨ï¼Œé¿å…æƒŠç¾¤æ•ˆåº”ï¼ˆÂ±25%ï¼‰
	jitter := time.Duration(float64(delay) * 0.25 * (2.0*rand.Float64() - 1.0))
	delay += jitter

	// è®¾ç½®æœ€å¤§å»¶è¿Ÿä¸Šé™ï¼ˆæ­»é”æƒ…å†µä¸‹å…è®¸æ›´é•¿çš„ç­‰å¾…ï¼‰
	maxDelay := 15 * time.Second
	if delay > maxDelay {
		delay = maxDelay
	}

	// è®¾ç½®æœ€å°å»¶è¿Ÿä¸‹é™
	minDelay := 100 * time.Millisecond
	if delay < minDelay {
		delay = minDelay
	}

	return delay
}

// GetMarketKlines è·å–Kçº¿æ•°æ®ï¼ˆä¼˜å…ˆä»æ•°æ®åº“æŸ¥è¯¢ï¼Œç¼ºå¤±æ—¶è¿”å›ç©ºï¼‰
func GetMarketKlines(gdb *gorm.DB, symbol, kind, interval string, startTime, endTime *time.Time, limit int) ([]MarketKline, error) {
	query := gdb.Where("symbol = ? AND kind = ? AND `interval` = ?", symbol, kind, interval)

	if startTime != nil {
		query = query.Where("open_time >= ?", *startTime)
	}
	if endTime != nil {
		query = query.Where("open_time <= ?", *endTime)
	}

	if limit > 0 {
		query = query.Limit(limit)
	}

	query = query.Order("open_time DESC")

	var klines []MarketKline
	if err := query.Find(&klines).Error; err != nil {
		return nil, fmt.Errorf("failed to query klines: %w", err)
	}

	// åè½¬é¡ºåºï¼Œä»æ—§åˆ°æ–°
	for i, j := 0, len(klines)-1; i < j; i, j = i+1, j-1 {
		klines[i], klines[j] = klines[j], klines[i]
	}

	return klines, nil
}

// GetLatestKline è·å–æœ€æ–°çš„Kçº¿æ•°æ®
func GetLatestKline(gdb *gorm.DB, symbol, kind, interval string) (*MarketKline, error) {
	var kline MarketKline
	err := gdb.Where("symbol = ? AND kind = ? AND `interval` = ?", symbol, kind, interval).
		Order("open_time DESC").
		First(&kline).Error

	if err != nil {
		if err == gorm.ErrRecordNotFound {
			return nil, nil // æ²¡æœ‰æ‰¾åˆ°æ•°æ®
		}
		return nil, fmt.Errorf("failed to get latest kline: %w", err)
	}

	return &kline, nil
}

// IsKlineDataFresh æ£€æŸ¥Kçº¿æ•°æ®æ˜¯å¦æ–°é²œï¼ˆæ˜¯å¦æœ‰æœ€è¿‘çš„æ•°æ®ï¼‰
func IsKlineDataFresh(gdb *gorm.DB, symbol, kind, interval string, maxAge time.Duration) (bool, error) {
	var latest MarketKline
	err := gdb.Where("symbol = ? AND kind = ? AND `interval` = ?", symbol, kind, interval).
		Order("open_time DESC").
		First(&latest).Error

	if err != nil {
		if err == gorm.ErrRecordNotFound {
			return false, nil // æ²¡æœ‰æ•°æ®ï¼Œè‚¯å®šä¸æ–°é²œ
		}
		return false, fmt.Errorf("failed to check kline freshness: %w", err)
	}

	// æ£€æŸ¥æ•°æ®æ˜¯å¦åœ¨å…è®¸çš„æ—¶é—´èŒƒå›´å†…
	return time.Since(latest.OpenTime) <= maxAge, nil
}

// ============================================================================
// æŠ€æœ¯æŒ‡æ ‡ç¼“å­˜æ“ä½œ
// ============================================================================

// SaveTechnicalIndicatorsCache ä¿å­˜æŠ€æœ¯æŒ‡æ ‡ç¼“å­˜
func SaveTechnicalIndicatorsCache(gdb *gorm.DB, cache *TechnicalIndicatorsCache) error {
	// ä½¿ç”¨ON DUPLICATE KEY UPDATEå¤„ç†é‡å¤æ•°æ®
	sql := fmt.Sprintf(`
		INSERT INTO technical_indicators_caches (
			symbol, kind, %s, data_points, indicators,
			calculated_at, data_from, data_to, created_at, updated_at
		) VALUES (?, ?, ?, ?, ?, ?, ?, ?, NOW(3), NOW(3))
		ON DUPLICATE KEY UPDATE
			indicators = VALUES(indicators),
			calculated_at = VALUES(calculated_at),
			data_from = VALUES(data_from),
			data_to = VALUES(data_to),
			updated_at = NOW(3)
	`, "`interval`")

	return gdb.Exec(sql,
		cache.Symbol, cache.Kind, cache.Interval, cache.DataPoints, cache.Indicators,
		cache.CalculatedAt, cache.DataFrom, cache.DataTo,
	).Error
}

// GetTechnicalIndicatorsCache è·å–æŠ€æœ¯æŒ‡æ ‡ç¼“å­˜
func GetTechnicalIndicatorsCache(gdb *gorm.DB, symbol, kind, interval string, dataPoints int) (*TechnicalIndicatorsCache, error) {
	var cache TechnicalIndicatorsCache
	err := gdb.Where("symbol = ? AND kind = ? AND `interval` = ? AND data_points = ?",
		symbol, kind, interval, dataPoints).
		Order("calculated_at DESC").
		First(&cache).Error

	if err != nil {
		if err == gorm.ErrRecordNotFound {
			return nil, nil // æ²¡æœ‰ç¼“å­˜æ•°æ®
		}
		return nil, fmt.Errorf("failed to get technical indicators cache: %w", err)
	}

	return &cache, nil
}

// IsTechnicalIndicatorsCacheFresh æ£€æŸ¥æŠ€æœ¯æŒ‡æ ‡ç¼“å­˜æ˜¯å¦æ–°é²œ
func IsTechnicalIndicatorsCacheFresh(gdb *gorm.DB, symbol, kind, interval string, dataPoints int, maxAge time.Duration) (bool, error) {
	var cache TechnicalIndicatorsCache
	err := gdb.Where("symbol = ? AND kind = ? AND `interval` = ? AND data_points = ?",
		symbol, kind, interval, dataPoints).
		Order("calculated_at DESC").
		First(&cache).Error

	if err != nil {
		if err == gorm.ErrRecordNotFound {
			return false, nil // æ²¡æœ‰ç¼“å­˜
		}
		return false, fmt.Errorf("failed to check cache freshness: %w", err)
	}

	return time.Since(cache.CalculatedAt) <= maxAge, nil
}

// ============================================================================
// ä»·æ ¼ç¼“å­˜æ“ä½œ
// ============================================================================

// SavePriceCache ä¿å­˜ä»·æ ¼ç¼“å­˜
func SavePriceCache(gdb *gorm.DB, cache *PriceCache) error {
	return gdb.Exec(`
		INSERT INTO price_caches (
			symbol, kind, price, price_change_24h, last_updated, created_at, updated_at
		) VALUES (?, ?, ?, ?, ?, NOW(3), NOW(3))
		ON DUPLICATE KEY UPDATE
			price = VALUES(price),
			price_change_24h = VALUES(price_change_24h),
			last_updated = VALUES(last_updated),
			updated_at = NOW(3)
	`,
		cache.Symbol, cache.Kind, cache.Price, cache.PriceChange24h, cache.LastUpdated,
	).Error
}

// GetPriceCache è·å–ä»·æ ¼ç¼“å­˜
func GetPriceCache(gdb *gorm.DB, symbol, kind string) (*PriceCache, error) {
	var cache PriceCache
	err := gdb.Where("symbol = ? AND kind = ?", symbol, kind).First(&cache).Error

	if err != nil {
		if err == gorm.ErrRecordNotFound {
			return nil, nil // æ²¡æœ‰ç¼“å­˜æ•°æ®ï¼Œè¿™æ˜¯æ­£å¸¸æƒ…å†µï¼Œä¸è®°å½•é”™è¯¯æ—¥å¿—
		}
		return nil, fmt.Errorf("failed to get price cache: %w", err)
	}

	return &cache, nil
}

// IsPriceCacheFresh æ£€æŸ¥ä»·æ ¼ç¼“å­˜æ˜¯å¦æ–°é²œ
func IsPriceCacheFresh(gdb *gorm.DB, symbol, kind string, maxAge time.Duration) (bool, error) {
	var cache PriceCache
	err := gdb.Where("symbol = ? AND kind = ?", symbol, kind).First(&cache).Error

	if err != nil {
		if err == gorm.ErrRecordNotFound {
			return false, nil // æ²¡æœ‰ç¼“å­˜
		}
		return false, fmt.Errorf("failed to check price cache freshness: %w", err)
	}

	return time.Since(cache.LastUpdated) <= maxAge, nil
}

// ============================================================================
// æ•°æ®æ¸…ç†æ“ä½œ
// ============================================================================

// CleanupOldKlineData æ¸…ç†è¿‡æœŸçš„Kçº¿æ•°æ®
func CleanupOldKlineData(gdb *gorm.DB, interval string, retentionDays int) error {
	if retentionDays <= 0 {
		return nil // ä¸æ¸…ç†
	}

	cutoffDate := time.Now().AddDate(0, 0, -retentionDays)

	result := gdb.Where("`interval` = ? AND open_time < ?", interval, cutoffDate).
		Delete(&MarketKline{})

	if result.Error != nil {
		return fmt.Errorf("failed to cleanup old kline data: %w", result.Error)
	}

	// è®°å½•æ¸…ç†çš„è¡Œæ•°
	if result.RowsAffected > 0 {
		// è¿™é‡Œå¯ä»¥æ·»åŠ æ—¥å¿—è®°å½•æ¸…ç†çš„è¡Œæ•°
	}

	return nil
}

// CleanupOldTechnicalIndicatorsCache æ¸…ç†è¿‡æœŸçš„æŠ€æœ¯æŒ‡æ ‡ç¼“å­˜
func CleanupOldTechnicalIndicatorsCache(gdb *gorm.DB, retentionDays int) error {
	if retentionDays <= 0 {
		return nil
	}

	cutoffDate := time.Now().AddDate(0, 0, -retentionDays)

	result := gdb.Where("calculated_at < ?", cutoffDate).
		Delete(&TechnicalIndicatorsCache{})

	return result.Error
}

// GetKlineDataStats è·å–Kçº¿æ•°æ®ç»Ÿè®¡ä¿¡æ¯
func GetKlineDataStats(gdb *gorm.DB) (map[string]interface{}, error) {
	stats := make(map[string]interface{})

	// Kçº¿æ•°æ®ç»Ÿè®¡
	var totalKlines int64
	gdb.Model(&MarketKline{}).Count(&totalKlines)
	stats["total_klines"] = totalKlines

	// æŒ‰é—´éš”ç»Ÿè®¡
	var intervalStats []struct {
		Interval string `json:"interval"`
		Count    int64  `json:"count"`
	}
	gdb.Model(&MarketKline{}).
		Select("`interval`, COUNT(*) as count").
		Group("`interval`").
		Scan(&intervalStats)
	stats["interval_stats"] = intervalStats

	// æŠ€æœ¯æŒ‡æ ‡ç¼“å­˜ç»Ÿè®¡
	var totalCache int64
	gdb.Model(&TechnicalIndicatorsCache{}).Count(&totalCache)
	stats["total_technical_cache"] = totalCache

	// ä»·æ ¼ç¼“å­˜ç»Ÿè®¡
	var totalPriceCache int64
	gdb.Model(&PriceCache{}).Count(&totalPriceCache)
	stats["total_price_cache"] = totalPriceCache

	// æ—¶é—´èŒƒå›´ç»Ÿè®¡
	var oldestKline, newestKline MarketKline
	if err := gdb.Order("open_time ASC").First(&oldestKline).Error; err == nil {
		stats["oldest_kline"] = oldestKline.OpenTime.Format("2006-01-02")
	}
	if err := gdb.Order("open_time DESC").First(&newestKline).Error; err == nil {
		stats["newest_kline"] = newestKline.OpenTime.Format("2006-01-02")
	}

	return stats, nil
}

// ============================================================================
// ç‰¹å¾æ•°æ®ç¼“å­˜æ“ä½œ
// ============================================================================

// SaveFeatureCache ä¿å­˜ç‰¹å¾æ•°æ®ç¼“å­˜
func SaveFeatureCache(gdb *gorm.DB, cache *FeatureCache) error {
	// ä½¿ç”¨ON DUPLICATE KEY UPDATEå¤„ç†é‡å¤æ•°æ®
	sql := `
		INSERT INTO feature_cache (
			symbol, features, computed_at, expires_at,
			feature_count, quality_score, source, time_window, data_points,
			created_at, updated_at
		) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, NOW(3), NOW(3))
		ON DUPLICATE KEY UPDATE
			features = VALUES(features),
			computed_at = VALUES(computed_at),
			expires_at = VALUES(expires_at),
			feature_count = VALUES(feature_count),
			quality_score = VALUES(quality_score),
			source = VALUES(source),
			data_points = VALUES(data_points),
			updated_at = NOW(3)
	`

	return gdb.Exec(sql,
		cache.Symbol,       // symbol
		cache.Features,     // features
		cache.ComputedAt,   // computed_at
		cache.ExpiresAt,    // expires_at
		cache.FeatureCount, // feature_count
		cache.QualityScore, // quality_score
		cache.Source,       // source
		cache.TimeWindow,   // time_window
		cache.DataPoints,   // data_points
	).Error
}

// GetFeatureCache è·å–ç‰¹å¾æ•°æ®ç¼“å­˜
func GetFeatureCache(gdb *gorm.DB, symbol string, timeWindow int) (*FeatureCache, error) {
	var cache FeatureCache
	err := gdb.Where("symbol = ? AND time_window = ? AND expires_at > NOW()",
		symbol, timeWindow).
		Order("computed_at DESC").
		First(&cache).Error

	if err != nil {
		if err == gorm.ErrRecordNotFound {
			return nil, nil // æ²¡æœ‰ç¼“å­˜æ•°æ®
		}
		return nil, fmt.Errorf("failed to get feature cache: %w", err)
	}

	return &cache, nil
}

// IsFeatureCacheFresh æ£€æŸ¥ç‰¹å¾ç¼“å­˜æ˜¯å¦æ–°é²œ
func IsFeatureCacheFresh(gdb *gorm.DB, symbol string, timeWindow int, maxAge time.Duration) (bool, error) {
	var cache FeatureCache
	err := gdb.Where("symbol = ? AND time_window = ?",
		symbol, timeWindow).
		Order("computed_at DESC").
		First(&cache).Error

	if err != nil {
		if err == gorm.ErrRecordNotFound {
			return false, nil
		}
		return false, fmt.Errorf("failed to check feature cache freshness: %w", err)
	}

	// æ£€æŸ¥æ˜¯å¦åœ¨å…è®¸çš„æ—¶é—´èŒƒå›´å†…
	return time.Since(cache.ComputedAt) <= maxAge, nil
}

// CleanupExpiredFeatureCache æ¸…ç†è¿‡æœŸçš„ç‰¹å¾ç¼“å­˜
func CleanupExpiredFeatureCache(gdb *gorm.DB) error {
	result := gdb.Where("expires_at < NOW()").Delete(&FeatureCache{})
	if result.Error != nil {
		return fmt.Errorf("failed to cleanup expired feature cache: %w", result.Error)
	}

	if result.RowsAffected > 0 {
		log.Printf("[FeatureCache] æ¸…ç†äº† %d æ¡è¿‡æœŸçš„ç‰¹å¾ç¼“å­˜è®°å½•", result.RowsAffected)
	}

	return nil
}

// GetFeatureCacheStats è·å–ç‰¹å¾ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
func GetFeatureCacheStats(gdb *gorm.DB) (map[string]interface{}, error) {
	var stats struct {
		TotalRecords    int64
		ExpiredRecords  int64
		FreshRecords    int64
		AvgQualityScore float64
		AvgFeatureCount float64
	}

	// æ€»è®°å½•æ•°
	gdb.Model(&FeatureCache{}).Count(&stats.TotalRecords)

	// è¿‡æœŸè®°å½•æ•°
	gdb.Model(&FeatureCache{}).Where("expires_at < NOW()").Count(&stats.ExpiredRecords)

	// æ–°é²œè®°å½•æ•°
	stats.FreshRecords = stats.TotalRecords - stats.ExpiredRecords

	// å¹³å‡è´¨é‡è¯„åˆ†
	gdb.Model(&FeatureCache{}).Where("expires_at > NOW()").Select("COALESCE(AVG(quality_score), 0)").Scan(&stats.AvgQualityScore)

	// å¹³å‡ç‰¹å¾æ•°é‡
	gdb.Model(&FeatureCache{}).Where("expires_at > NOW()").Select("COALESCE(AVG(feature_count), 0)").Scan(&stats.AvgFeatureCount)

	return map[string]interface{}{
		"total_records":     stats.TotalRecords,
		"expired_records":   stats.ExpiredRecords,
		"fresh_records":     stats.FreshRecords,
		"avg_quality_score": stats.AvgQualityScore,
		"avg_feature_count": stats.AvgFeatureCount,
	}, nil
}

// ============================================================================
// MLæ¨¡å‹å­˜å‚¨æ“ä½œ
// ============================================================================

// SaveMLModel ä¿å­˜MLæ¨¡å‹
func SaveMLModel(gdb *gorm.DB, model *MLModel) error {
	// ä½¿ç”¨ON DUPLICATE KEY UPDATEå¤„ç†é‡å¤æ•°æ®
	sql := `
		INSERT INTO ml_models (
			symbol, model_type, model_name, model_data, performance,
			trained_at, expires_at, training_samples, feature_count,
			accuracy, ` + "`precision`" + `, ` + "`recall`" + `, f1_score, auc,
			sharpe_ratio, max_drawdown, win_rate, profit_factor,
			status, version, description, created_at, updated_at
		) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, NOW(3), NOW(3))
		ON DUPLICATE KEY UPDATE
			model_data = VALUES(model_data),
			performance = VALUES(performance),
			trained_at = VALUES(trained_at),
			expires_at = VALUES(expires_at),
			training_samples = VALUES(training_samples),
			feature_count = VALUES(feature_count),
			accuracy = VALUES(accuracy),
			` + "`precision`" + ` = VALUES(` + "`precision`" + `),
			` + "`recall`" + ` = VALUES(` + "`recall`" + `),
			f1_score = VALUES(f1_score),
			auc = VALUES(auc),
			sharpe_ratio = VALUES(sharpe_ratio),
			max_drawdown = VALUES(max_drawdown),
			win_rate = VALUES(win_rate),
			profit_factor = VALUES(profit_factor),
			status = VALUES(status),
			version = VALUES(version),
			description = VALUES(description),
			updated_at = NOW(3)
	`

	return gdb.Exec(sql,
		model.Symbol,          // symbol
		model.ModelType,       // model_type
		model.ModelName,       // model_name
		model.ModelData,       // model_data
		model.Performance,     // performance
		model.TrainedAt,       // trained_at
		model.ExpiresAt,       // expires_at
		model.TrainingSamples, // training_samples
		model.FeatureCount,    // feature_count
		model.Accuracy,        // accuracy
		model.Precision,       // precision
		model.Recall,          // recall
		model.F1Score,         // f1_score
		model.AUC,             // auc
		model.SharpeRatio,     // sharpe_ratio
		model.MaxDrawdown,     // max_drawdown
		model.WinRate,         // win_rate
		model.ProfitFactor,    // profit_factor
		model.Status,          // status
		model.Version,         // version
		model.Description,     // description
	).Error
}

// GetMLModel è·å–MLæ¨¡å‹
func GetMLModel(gdb *gorm.DB, symbol, modelType string) (*MLModel, error) {
	var model MLModel
	err := gdb.Where("symbol = ? AND model_type = ? AND expires_at > NOW() AND status = 'active'",
		symbol, modelType).
		Order("version DESC, trained_at DESC").
		First(&model).Error

	if err != nil {
		if err == gorm.ErrRecordNotFound {
			return nil, nil // æ²¡æœ‰æ‰¾åˆ°æ¨¡å‹
		}
		return nil, fmt.Errorf("failed to get ML model: %w", err)
	}

	return &model, nil
}

// GetMLModelsBySymbol è·å–æŒ‡å®šäº¤æ˜“å¯¹çš„æ‰€æœ‰æ¨¡å‹
func GetMLModelsBySymbol(gdb *gorm.DB, symbol string, includeExpired bool) ([]MLModel, error) {
	var models []MLModel
	query := gdb.Where("symbol = ?", symbol)

	if !includeExpired {
		query = query.Where("expires_at > NOW()")
	}

	err := query.Order("trained_at DESC").Find(&models).Error
	if err != nil {
		return nil, fmt.Errorf("failed to get ML models by symbol: %w", err)
	}

	return models, nil
}

// GetBestMLModels è·å–è¡¨ç°æœ€å¥½çš„æ¨¡å‹
func GetBestMLModels(gdb *gorm.DB, modelType string, limit int) ([]MLModel, error) {
	var models []MLModel
	err := gdb.Where("model_type = ? AND expires_at > NOW() AND status = 'active'", modelType).
		Order("accuracy DESC, trained_at DESC").
		Limit(limit).
		Find(&models).Error

	if err != nil {
		return nil, fmt.Errorf("failed to get best ML models: %w", err)
	}

	return models, nil
}

// UpdateMLModelStatus æ›´æ–°æ¨¡å‹çŠ¶æ€
func UpdateMLModelStatus(gdb *gorm.DB, symbol, modelType string, status string) error {
	return gdb.Model(&MLModel{}).
		Where("symbol = ? AND model_type = ?", symbol, modelType).
		Update("status", status).Error
}

// CleanupExpiredMLModels æ¸…ç†è¿‡æœŸçš„MLæ¨¡å‹
func CleanupExpiredMLModels(gdb *gorm.DB) error {
	result := gdb.Where("expires_at < NOW()").Delete(&MLModel{})
	if result.Error != nil {
		return fmt.Errorf("failed to cleanup expired ML models: %w", result.Error)
	}

	if result.RowsAffected > 0 {
		log.Printf("[MLModel] æ¸…ç†äº† %d æ¡è¿‡æœŸçš„MLæ¨¡å‹è®°å½•", result.RowsAffected)
	}

	return nil
}

// GetMLModelStats è·å–MLæ¨¡å‹ç»Ÿè®¡ä¿¡æ¯
func GetMLModelStats(gdb *gorm.DB) (map[string]interface{}, error) {
	var stats struct {
		TotalModels        int64
		ActiveModels       int64
		ExpiredModels      int64
		AvgAccuracy        float64
		AvgTrainingSamples float64
		BestAccuracy       float64
		WorstAccuracy      float64
	}

	// æ€»æ¨¡å‹æ•°
	gdb.Model(&MLModel{}).Count(&stats.TotalModels)

	// æ´»è·ƒæ¨¡å‹æ•°
	gdb.Model(&MLModel{}).Where("expires_at > NOW() AND status = 'active'").Count(&stats.ActiveModels)

	// è¿‡æœŸæ¨¡å‹æ•°
	stats.ExpiredModels = stats.TotalModels - stats.ActiveModels

	// å¹³å‡å‡†ç¡®ç‡
	gdb.Model(&MLModel{}).Where("expires_at > NOW() AND status = 'active'").
		Select("COALESCE(AVG(accuracy), 0)").Scan(&stats.AvgAccuracy)

	// å¹³å‡è®­ç»ƒæ ·æœ¬æ•°
	gdb.Model(&MLModel{}).Where("expires_at > NOW() AND status = 'active'").
		Select("COALESCE(AVG(training_samples), 0)").Scan(&stats.AvgTrainingSamples)

	// æœ€ä½³å‡†ç¡®ç‡
	gdb.Model(&MLModel{}).Where("expires_at > NOW() AND status = 'active'").
		Select("MAX(accuracy)").Scan(&stats.BestAccuracy)

	// æœ€å·®å‡†ç¡®ç‡
	gdb.Model(&MLModel{}).Where("expires_at > NOW() AND status = 'active'").
		Select("MIN(accuracy)").Scan(&stats.WorstAccuracy)

	// æŒ‰æ¨¡å‹ç±»å‹ç»Ÿè®¡
	var modelTypeStats []struct {
		ModelType   string
		Count       int64
		AvgAccuracy float64
	}

	gdb.Model(&MLModel{}).
		Select("model_type, COUNT(*) as count, AVG(accuracy) as avg_accuracy").
		Where("expires_at > NOW() AND status = 'active'").
		Group("model_type").
		Find(&modelTypeStats)

	modelTypeMap := make(map[string]interface{})
	for _, stat := range modelTypeStats {
		modelTypeMap[stat.ModelType] = map[string]interface{}{
			"count":        stat.Count,
			"avg_accuracy": stat.AvgAccuracy,
		}
	}

	return map[string]interface{}{
		"total_models":         stats.TotalModels,
		"active_models":        stats.ActiveModels,
		"expired_models":       stats.ExpiredModels,
		"avg_accuracy":         stats.AvgAccuracy,
		"avg_training_samples": stats.AvgTrainingSamples,
		"best_accuracy":        stats.BestAccuracy,
		"worst_accuracy":       stats.WorstAccuracy,
		"model_types":          modelTypeMap,
	}, nil
}
