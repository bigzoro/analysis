package server

import (
	"context"
	"encoding/json"
	"fmt"
	"log"
	"math"
	"net/http"
	"runtime"
	"sort"
	"strconv"
	"strings"
	"sync"
	"time"

	"github.com/gin-gonic/gin"
	"gorm.io/gorm"

	"analysis/internal/analysis"
	"analysis/internal/config"
	pdb "analysis/internal/db"
	bf "analysis/internal/exchange/binancefutures"
	"analysis/internal/netutil"
	"analysis/internal/server/strategy/factory"
	"analysis/internal/server/strategy/router"
	"analysis/internal/server/strategy/shared/execution"
	traditional_execution "analysis/internal/server/strategy/traditional/execution"
	"analysis/internal/service"
)

// PositionSnapshot æŒä»“å¿«ç…§ï¼Œç”¨äºæ£€æµ‹æŒä»“å˜åŒ–
type PositionSnapshot struct {
	Symbol       string    `json:"symbol"`
	PositionAmt  string    `json:"position_amt"`
	EntryPrice   string    `json:"entry_price"`
	MarkPrice    string    `json:"mark_price"`
	UpdateTime   int64     `json:"update_time"`
	SnapshotTime time.Time `json:"snapshot_time"`
	UserID       uint      `json:"user_id"` // å…³è”ç”¨æˆ·ID
}

// DetectedChange æ£€æµ‹åˆ°çš„æŒä»“å˜åŒ–
type DetectedChange struct {
	Symbol     string    `json:"symbol"`
	Type       string    `json:"type"` // "new", "changed", "closed", "disappeared"
	OldAmt     string    `json:"old_amt"`
	NewAmt     string    `json:"new_amt"`
	Confidence float64   `json:"confidence"` // ç½®ä¿¡åº¦ 0-1
	Timestamp  time.Time `json:"timestamp"`
}

// å…¨å±€æ•°æ®åŒæ­¥çŠ¶æ€å­˜å‚¨
var (
	globalDataSyncStats = &DataSyncStats{
		mu:           sync.RWMutex{},
		lastUpdate:   time.Now(),
		globalHealth: "unknown",
		syncers:      make(map[string]*SyncerStats),
		websocket:    &WebSocketStats{},
		apiStats:     make(map[string]*APIStats),
		alerts:       []DataSyncAlert{},
	}
)

// DataSyncStats æ•°æ®åŒæ­¥å…¨å±€ç»Ÿè®¡
type DataSyncStats struct {
	mu           sync.RWMutex
	lastUpdate   time.Time
	globalHealth string
	syncers      map[string]*SyncerStats
	websocket    *WebSocketStats
	apiStats     map[string]*APIStats
	alerts       []DataSyncAlert
}

// SyncerStats åŒæ­¥å™¨ç»Ÿè®¡
type SyncerStats struct {
	Name            string     `json:"name"`
	DisplayName     string     `json:"display_name"`
	Status          string     `json:"status"`
	TotalSyncs      int64      `json:"total_syncs"`
	SuccessfulSyncs int64      `json:"successful_syncs"`
	FailedSyncs     int64      `json:"failed_syncs"`
	LastSyncTime    *time.Time `json:"last_sync_time"`
	TotalUpdates    int64      `json:"total_updates"`
}

// WebSocketStats WebSocketç»Ÿè®¡
type WebSocketStats struct {
	IsRunning                bool       `json:"is_running"`
	IsHealthy                bool       `json:"is_healthy"`
	SpotConnections          int        `json:"spot_connections"`
	HealthySpot              int        `json:"healthy_spot"`
	FuturesConnections       int        `json:"futures_connections"`
	HealthyFutures           int        `json:"healthy_futures"`
	MessagesReceived         int64      `json:"messages_received"`
	LastMessageTime          *time.Time `json:"last_message_time"`
	TotalSpotPriceUpdates    int64      `json:"total_spot_price_updates"`
	TotalFuturesPriceUpdates int64      `json:"total_futures_price_updates"`
	TotalKlineUpdates        int64      `json:"total_kline_updates"`
	TotalDepthUpdates        int64      `json:"total_depth_updates"`
}

// APIStats APIç»Ÿè®¡
type APIStats struct {
	TotalCalls      int64      `json:"total_calls"`
	APICallsTotal   int64      `json:"api_calls_total"`
	APISuccessRate  string     `json:"api_success_rate"`
	APIAvgLatency   *string    `json:"api_avg_latency"`
	TotalSyncs      int64      `json:"total_syncs"`
	SuccessfulSyncs int64      `json:"successful_syncs"`
	FailedSyncs     int64      `json:"failed_syncs"`
	LastSyncTime    *time.Time `json:"last_sync_time"`
	TotalUpdates    int64      `json:"total_updates"`
	// Price specific
	WebSocketHits    int64  `json:"websocket_hits,omitempty"`
	RestAPICalls     int64  `json:"rest_api_calls,omitempty"`
	WebSocketHitRate string `json:"websocket_hit_rate,omitempty"`
}

// DataSyncAlert æ•°æ®åŒæ­¥å‘Šè­¦ä¿¡æ¯
type DataSyncAlert struct {
	ID        string    `json:"id"`
	Title     string    `json:"title"`
	Message   string    `json:"message"`
	Severity  string    `json:"severity"`
	Component string    `json:"component"`
	Metric    string    `json:"metric"`
	Value     string    `json:"value"`
	Timestamp time.Time `json:"timestamp"`
}

// UpdateDataSyncStats æ›´æ–°æ•°æ®åŒæ­¥ç»Ÿè®¡ä¿¡æ¯
func UpdateDataSyncStats(stats *DataSyncStats) {
	globalDataSyncStats.mu.Lock()
	defer globalDataSyncStats.mu.Unlock()

	globalDataSyncStats.lastUpdate = time.Now()
	globalDataSyncStats.globalHealth = stats.globalHealth
	globalDataSyncStats.syncers = stats.syncers
	globalDataSyncStats.websocket = stats.websocket
	globalDataSyncStats.apiStats = stats.apiStats
	globalDataSyncStats.alerts = stats.alerts
}

// AddAlert æ·»åŠ å‘Šè­¦
func AddAlert(alert DataSyncAlert) {
	globalDataSyncStats.mu.Lock()
	defer globalDataSyncStats.mu.Unlock()

	globalDataSyncStats.alerts = append(globalDataSyncStats.alerts, alert)
	// ä¿ç•™æœ€è¿‘çš„100ä¸ªå‘Šè­¦
	if len(globalDataSyncStats.alerts) > 100 {
		globalDataSyncStats.alerts = globalDataSyncStats.alerts[len(globalDataSyncStats.alerts)-100:]
	}
}

type Server struct {
	db                     Database // ä½¿ç”¨æ¥å£è€Œéå…·ä½“å®ç°
	Mailer                 Mailer
	XBearer                string
	cache                  pdb.CacheInterface // ç¼“å­˜æ¥å£
	arkhamClient           *ArkhamClient
	nansenClient           *NansenClient
	cfg                    *config.Config
	priceService           *service.PriceService          // ç»Ÿä¸€ä»·æ ¼æœåŠ¡
	dataManager            *DataManager                   // å¤šæºæ•°æ®ç®¡ç†å™¨
	dataService            *DataService                   // æ•°æ®æœåŠ¡
	backtestEngine         *BacktestEngine                // å›æµ‹å¼•æ“
	ensembleModels         map[string]*EnsemblePredictor  // é›†æˆå­¦ä¹ æ¨¡å‹
	recommendationCache    *RecommendationCache           // æ¨èç¼“å­˜
	recommendationEnhancer *RecommendationEnhancer        // æ¨èå¢å¼ºå™¨
	batchPerformanceLoader *BatchPerformanceLoader        // æ‰¹é‡æ€§èƒ½åŠ è½½å™¨
	userBehaviorService    *UserBehaviorService           // ç”¨æˆ·è¡Œä¸ºæœåŠ¡
	feedbackService        *RecommendationFeedbackService // æ¨èåé¦ˆæœåŠ¡
	abTestingService       *ABTestingService              // A/Bæµ‹è¯•æœåŠ¡
	algorithmOptimizer     *AlgorithmOptimizer            // ç®—æ³•ä¼˜åŒ–å™¨
	weightController       *AdaptiveWeightController      // è‡ªé€‚åº”æƒé‡æ§åˆ¶å™¨

	// ç­–ç•¥ç›¸å…³
	strategyHandler *StrategyHandler         // ç­–ç•¥å¤„ç†å™¨
	scannerRegistry *StrategyScannerRegistry // ç­–ç•¥æ‰«æå™¨æ³¨å†Œè¡¨
	strategyRouter  *router.StrategyRouter   // ç­–ç•¥è·¯ç”±å™¨
	strategyFactory *factory.StrategyFactory // ç­–ç•¥å·¥å‚
	scanMutex       sync.Mutex               // æ‰«æå¹¶å‘æ§åˆ¶é”

	// æ•°æ®åŒæ­¥æœåŠ¡ç›¸å…³
	dataSyncService      interface{}      // æ•°æ®åŒæ­¥æœåŠ¡å®ä¾‹
	binanceWSClient      *BinanceWSClient // å¸å®‰WebSocketå®¢æˆ·ç«¯
	binanceFuturesClient *bf.Client       // å¸å®‰æœŸè´§å®¢æˆ·ç«¯
	coincap              *coinCapCache    // CoinCapå¸‚å€¼æ•°æ®ç¼“å­˜
	// æ³¨æ„ï¼šOptimizationSchedulerå·²ç§»è‡³ç‹¬ç«‹çš„investmentæœåŠ¡
	priceCache         *PriceCache                  // ä»·æ ¼ç¼“å­˜
	distributedManager *DistributedComputingManager // åˆ†å¸ƒå¼è®¡ç®—ç®¡ç†å™¨
	opportunityCache   map[string]time.Time         // æœºä¼šå‘ç°ç¼“å­˜ï¼Œé¿å…é‡å¤å‘ç°
	tradingPairsCache  *TradingPairsCache           // äº¤æ˜“å¯¹åˆ—è¡¨ç¼“å­˜

	// Data preprocessing and caching - æ•°æ®é¢„å¤„ç†å’Œç¼“å­˜
	dataCache         *BacktestDataCache // å›æµ‹æ•°æ®ç¼“å­˜
	dataUpdateService *DataUpdateService // æ•°æ®æ›´æ–°æœåŠ¡

	// Feature precomputation - ç‰¹å¾é¢„è®¡ç®—
	featurePrecomputeService *FeaturePrecomputeService // ç‰¹å¾é¢„è®¡ç®—æœåŠ¡

	// Technical indicators precomputation - æŠ€æœ¯æŒ‡æ ‡é¢„è®¡ç®—
	technicalIndicatorsPrecomputeService *TechnicalIndicatorsPrecomputeService // æŠ€æœ¯æŒ‡æ ‡é¢„è®¡ç®—æœåŠ¡

	// ML model pretraining - MLæ¨¡å‹é¢„è®­ç»ƒ
	mlPretrainingService *MLPretrainingService // MLæ¨¡å‹é¢„è®­ç»ƒæœåŠ¡

	// Analysis module - æ™ºèƒ½æŠ•ç ”æ¨¡å—
	strategyBacktestEngine *StrategyBacktestEngine // ç­–ç•¥å›æµ‹å¼•æ“
	coinSelectionAlgorithm *CoinSelectionAlgorithm // æ–°ä¸€ä»£é€‰å¸ç®—æ³•

	// æ³¨æ„ï¼šPerformanceTrackerå’ŒSmartSchedulerå·²ç§»è‡³ç‹¬ç«‹çš„investmentæœåŠ¡
	layeredCache   *LayeredCache   // åˆ†å±‚ç¼“å­˜ç³»ç»Ÿ
	dataPreloader  *DataPreloader  // æ•°æ®é¢„åŠ è½½æœåŠ¡
	priceMonitor   *PriceMonitor   // ä»·æ ¼ç›‘æ§æœåŠ¡
	orderScheduler *OrderScheduler // å®šæ—¶è®¢å•è°ƒåº¦å™¨

	// â­ å¹¶å‘å’Œèµ„æºç®¡ç†æ¨¡å—
	smartWorkerPool   *SmartWorkerPool       // æ™ºèƒ½å·¥ä½œè€…æ± 
	resourceManager   *ResourceManager       // èµ„æºç®¡ç†å™¨
	circuitBreakerMgr *CircuitBreakerManager // ç†”æ–­å™¨ç®¡ç†å™¨
	shutdownManager   *ShutdownManager       // å…³é—­ç®¡ç†å™¨
	resourceCleaner   *ResourceCleaner       // èµ„æºæ¸…ç†å™¨

	// æ•°æ®è´¨é‡ç›‘æ§
	dataQualityMonitor *DataQualityMonitor // æ•°æ®è´¨é‡ç›‘æ§å™¨

	// å…è´¹æ•°æ®æºå®¢æˆ·ç«¯
	coinGeckoClient *CoinGeckoClient // CoinGeckoå…è´¹APIå®¢æˆ·ç«¯
	newsAPIClient   *NewsAPIClient   // NewsAPIå…è´¹å®¢æˆ·ç«¯
	dataFusion      *DataFusion      // æ•°æ®èåˆå™¨
	dataValidator   *DataValidator   // æ•°æ®éªŒè¯å™¨

	// â­ ç‰¹å¾å·¥ç¨‹æ¨¡å—
	featureEngineering *FeatureEngineering // ç‰¹å¾å·¥ç¨‹æ ¸å¿ƒæ¨¡å—

	// â­ æœºå™¨å­¦ä¹ æ¨¡å—
	machineLearning *MachineLearning

	// â­ é£é™©ç®¡ç†æ¨¡å—
	riskManagement *RiskManagement // æœºå™¨å­¦ä¹ æ ¸å¿ƒæ¨¡å—

	// â­ æŒä»“å˜åŒ–æ£€æµ‹æœºåˆ¶
	positionSnapshots map[string]*PositionSnapshot // æŒä»“å¿«ç…§å­˜å‚¨
	lastPositionCheck time.Time                    // ä¸Šæ¬¡æŒä»“æ£€æŸ¥æ—¶é—´
	positionMutex     sync.RWMutex                 // æŒä»“æ•°æ®å¹¶å‘æ§åˆ¶

	// â­ æ™ºèƒ½é€šçŸ¥ç³»ç»Ÿ
	notificationService NotificationService // é€šçŸ¥æœåŠ¡

	// â­ æ“ä½œå†å²è¿½è¸ª
	auditLogger *AuditLogger // å®¡è®¡æ—¥å¿—è®°å½•å™¨

	// â­ å¼‚å¸¸æ£€æµ‹ä¸æ¢å¤
	healthChecker *SystemHealthChecker // ç³»ç»Ÿå¥åº·æ£€æŸ¥å™¨

	// é™çº§ç­–ç•¥
	fallbackStrategy *FallbackStrategy    // é™çº§ç­–ç•¥ç®¡ç†å™¨
	fallbackProvider FallbackDataProvider // é™çº§æ•°æ®æä¾›è€…
}

// SetDataSyncService è®¾ç½®æ•°æ®åŒæ­¥æœåŠ¡å®ä¾‹
func (s *Server) SetDataSyncService(service interface{}) {
	s.dataSyncService = service
}

// TradingPairsCache äº¤æ˜“å¯¹åˆ—è¡¨ç¼“å­˜
type TradingPairsCache struct {
	symbols       []string
	lastUpdate    time.Time
	cacheDuration time.Duration
	mu            sync.RWMutex
}

// NewTradingPairsCache åˆ›å»ºäº¤æ˜“å¯¹ç¼“å­˜
func NewTradingPairsCache(cacheDuration time.Duration) *TradingPairsCache {
	return &TradingPairsCache{
		cacheDuration: cacheDuration,
	}
}

// Get è·å–ç¼“å­˜çš„äº¤æ˜“å¯¹åˆ—è¡¨
func (c *TradingPairsCache) Get() ([]string, bool) {
	c.mu.RLock()
	defer c.mu.RUnlock()

	if time.Since(c.lastUpdate) < c.cacheDuration && len(c.symbols) > 0 {
		return c.symbols, true
	}
	return nil, false
}

// Set è®¾ç½®ç¼“å­˜çš„äº¤æ˜“å¯¹åˆ—è¡¨
func (c *TradingPairsCache) Set(symbols []string) {
	c.mu.Lock()
	defer c.mu.Unlock()

	c.symbols = make([]string, len(symbols))
	copy(c.symbols, symbols)
	c.lastUpdate = time.Now()
}

// New åˆ›å»º Server å®ä¾‹ï¼ˆä½¿ç”¨æ¥å£ï¼‰
// åˆå§‹åŒ–é¡ºåºï¼š
// 1. æ ¸å¿ƒåŸºç¡€æœåŠ¡ (æ•°æ®åº“ã€æ•°æ®ç®¡ç†)
// 2. å®æ—¶æœåŠ¡ (WebSocketã€å®šæ—¶ä»»åŠ¡)
// 3. AIåˆ†ææ¨¡å— (å¯é€‰çš„é«˜çº§åŠŸèƒ½)
// 4. å›æµ‹å¼•æ“ (ä¾èµ–åŸºç¡€æœåŠ¡ï¼Œå¯ä½¿ç”¨AIå¢å¼ºåŠŸèƒ½)
func New(db Database, cfg *config.Config) *Server {
	s := &Server{db: db, cfg: cfg}

	// ===== é˜¶æ®µ1: æ ¸å¿ƒåŸºç¡€æœåŠ¡ =====
	s.initPriceService()
	s.initDataManager()

	// åˆå§‹åŒ–ç­–ç•¥å¤„ç†å™¨
	s.strategyHandler = NewStrategyHandler(s)

	// åˆå§‹åŒ–ç­–ç•¥è·¯ç”±å™¨å’Œå·¥å‚
	s.strategyRouter = router.NewStrategyRouter()
	s.strategyFactory = factory.NewStrategyFactory(&factory.ExecutionDependencies{
		MarketDataProvider: s,
		OrderManager:       s,
		RiskManager:        s,
		ConfigProvider:     s,
	})

	// åˆå§‹åŒ–ç­–ç•¥æ‰«æå™¨æ³¨å†Œè¡¨
	log.Printf("ğŸ—ï¸ [INIT] åˆ›å»ºç­–ç•¥æ‰«æå™¨æ³¨å†Œè¡¨...")
	s.scannerRegistry = NewStrategyScannerRegistry()
	log.Printf("ğŸš€ [INIT] å¼€å§‹æ³¨å†Œç­–ç•¥æ‰«æå™¨...")
	if err := s.scannerRegistry.RegisterScanner(s); err != nil {
		log.Printf("âŒ [INIT] ç­–ç•¥æ‰«æå™¨æ³¨å†Œå¤±è´¥: %v", err)
		// ä¸è¿”å›é”™è¯¯ï¼Œå› ä¸ºå…¶ä»–æœåŠ¡å¯èƒ½ä»ç„¶å¯ä»¥å·¥ä½œ
		// ç­–ç•¥æ‰«æåŠŸèƒ½å°†ä¸å¯ç”¨ï¼Œä½†æœåŠ¡å™¨ä»å¯å¯åŠ¨
	} else {
		log.Printf("âœ… [INIT] ç­–ç•¥æ‰«æå™¨æ³¨å†ŒæˆåŠŸ")
	}

	// ç­–ç•¥æ‰§è¡Œå™¨ç°åœ¨ç›´æ¥ä½¿ç”¨æ–°çš„æ¥å£ï¼Œæ— éœ€æ³¨å†Œ

	// ===== é˜¶æ®µ2: å®æ—¶æœåŠ¡ =====
	s.initBinanceWSClient()
	s.initOrderStatusSync()         // åˆå§‹åŒ–è®¢å•çŠ¶æ€å®šæ—¶åŒæ­¥
	s.initPositionChangeDetection() // åˆå§‹åŒ–æŒä»“å˜åŒ–æ£€æµ‹æœºåˆ¶
	s.initNotificationService(cfg)  // åˆå§‹åŒ–æ™ºèƒ½é€šçŸ¥ç³»ç»Ÿ
	s.initAuditLogger()             // åˆå§‹åŒ–å®¡è®¡æ—¥å¿—è®°å½•å™¨
	s.initHealthChecker()           // åˆå§‹åŒ–ç³»ç»Ÿå¥åº·æ£€æŸ¥å™¨
	s.initTradingPairsCache()       // åˆå§‹åŒ–äº¤æ˜“å¯¹ç¼“å­˜

	// ===== é˜¶æ®µ3: AIåˆ†ææ¨¡å—ï¼ˆå¯é€‰ï¼‰ =====
	// æ ¹æ®é…ç½®å†³å®šæ˜¯å¦å¯ç”¨æ•°æ®åˆ†ææœåŠ¡
	if cfg.Services.EnableDataAnalysis {
		log.Printf("[INIT] æ•°æ®åˆ†ææœåŠ¡å·²å¯ç”¨ï¼Œå¼€å§‹åˆå§‹åŒ–AIåˆ†ææ¨¡å—...")
		// åŒ…å«å¤æ‚çš„AIç®—æ³•ã€ç‰¹å¾å·¥ç¨‹ã€é£é™©ç®¡ç†ç­‰é«˜çº§åŠŸèƒ½
		s.initAnalysisModule()
		log.Printf("[INIT] AIåˆ†ææ¨¡å—åˆå§‹åŒ–å®Œæˆï¼Œå›æµ‹å¼•æ“å°†ä½¿ç”¨å®Œæ•´åŠŸèƒ½")
	} else {
		log.Printf("[INIT] æ•°æ®åˆ†ææœåŠ¡å·²ç¦ç”¨ï¼Œè·³è¿‡AIåˆ†ææ¨¡å—åˆå§‹åŒ–")
		log.Printf("[INIT] å›æµ‹å¼•æ“å°†åœ¨åŸºç¡€æ¨¡å¼ä¸‹è¿è¡Œ")
	}

	// ===== é˜¶æ®µ4: å›æµ‹å¼•æ“ï¼ˆæ ¸å¿ƒæœåŠ¡æ¨¡å—ï¼‰ =====
	// å›æµ‹å¼•æ“æ”¾åœ¨æœ€åï¼Œç¡®ä¿èƒ½ä½¿ç”¨åˆ°AIåˆ†ææ¨¡å—æä¾›çš„å¢å¼ºåŠŸèƒ½
	// å¦‚æœAIåˆ†ææ¨¡å—è¢«ç¦ç”¨ï¼Œå›æµ‹å¼•æ“ä¹Ÿèƒ½æ­£å¸¸å·¥ä½œï¼ˆåŸºç¡€æ¨¡å¼ï¼‰
	s.initBacktestEngine()

	// ===== é˜¶æ®µ5: å®šæ—¶è®¢å•è°ƒåº¦å™¨ï¼ˆå¿…é¡»æœåŠ¡ï¼‰ =====
	// OrderSchedulerå¿…é¡»åˆå§‹åŒ–ï¼Œå› ä¸ºç­–ç•¥æ‰§è¡ŒåŠŸèƒ½æ˜¯æ ¸å¿ƒåŠŸèƒ½
	log.Printf("[INIT] åˆå§‹åŒ–å®šæ—¶è®¢å•è°ƒåº¦å™¨...")
	s.orderScheduler = NewOrderScheduler(s.db.DB(), s.cfg, s)
	s.orderScheduler.Start()
	log.Printf("[INIT] å®šæ—¶è®¢å•è°ƒåº¦å™¨åˆå§‹åŒ–å®Œæˆ - ç­–ç•¥å¯åŠ¨APIç°åœ¨å¯ä»¥ä½¿ç”¨ç«‹å³æ‰§è¡ŒåŠŸèƒ½")

	return s
}

// GetOrderScheduler è·å–è®¢å•è°ƒåº¦å™¨ï¼ˆç”¨äºæµ‹è¯•å’Œè°ƒè¯•ï¼‰
func (s *Server) GetOrderScheduler() *OrderScheduler {
	return s.orderScheduler
}

// initTradingPairsCache åˆå§‹åŒ–äº¤æ˜“å¯¹ç¼“å­˜
func (s *Server) initTradingPairsCache() {
	log.Printf("[INIT] åˆå§‹åŒ–äº¤æ˜“å¯¹åˆ—è¡¨ç¼“å­˜...")
	s.tradingPairsCache = NewTradingPairsCache(30 * time.Minute) // ç¼“å­˜30åˆ†é’Ÿ
}

// initBinanceWSClient åˆå§‹åŒ–å¸å®‰WebSocketå®¢æˆ·ç«¯
func (s *Server) initBinanceWSClient() {
	log.Printf("[INIT] åˆå§‹åŒ–å¸å®‰WebSocketå®¢æˆ·ç«¯...")

	s.binanceWSClient = NewBinanceWSClient()

	// åˆå§‹åŒ–å¸å®‰æœŸè´§å®¢æˆ·ç«¯
	log.Printf("[INIT] åˆå§‹åŒ–å¸å®‰æœŸè´§å®¢æˆ·ç«¯...")
	s.binanceFuturesClient = bf.New(s.cfg.Exchange.Binance.IsTestnet,
		s.cfg.Exchange.Binance.APIKey, s.cfg.Exchange.Binance.SecretKey)
	log.Printf("[INIT] å¸å®‰æœŸè´§å®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆ")

	// å°è¯•è¿æ¥åˆ°å¸å®‰WebSocket
	go func() {
		// é¦–å…ˆå°è¯•è¿æ¥å¸æœ¬ä½æœŸè´§WebSocket
		if err := s.binanceWSClient.Connect("coin_futures"); err != nil {
			log.Printf("[INIT] è¿æ¥å¸æœ¬ä½æœŸè´§WebSocketå¤±è´¥: %v", err)
			// å¦‚æœå¤±è´¥ï¼Œå°è¯•è¿æ¥USDTæœŸè´§
			if err := s.binanceWSClient.Connect("futures"); err != nil {
				log.Printf("[INIT] è¿æ¥USDTæœŸè´§WebSocketå¤±è´¥: %v", err)
				return
			}
		}

		log.Printf("[INIT] å¸å®‰WebSocketå®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆ")

		// è®¾ç½®æ•°æ®æ›´æ–°å›è°ƒï¼Œè‡ªåŠ¨æ¸…ç†ç›¸å…³ç¼“å­˜
		s.binanceWSClient.SetUpdateCallback(func() {
			// å½“WebSocketæ”¶åˆ°æ–°æ•°æ®æ—¶ï¼Œæ¸…ç†æ¶¨å¹…æ¦œç¼“å­˜ï¼Œè§¦å‘ä¸‹æ¬¡è¯·æ±‚é‡æ–°è®¡ç®—
			gainersCacheMu.Lock()
			// æ¸…ç†æ‰€æœ‰æ¶¨å¹…æ¦œç¼“å­˜ï¼Œå¼ºåˆ¶ä¸‹æ¬¡è¯·æ±‚ä½¿ç”¨æœ€æ–°WebSocketæ•°æ®
			gainersCache = make(map[string]cachedGainersData)
			gainersCacheMu.Unlock()
			//log.Printf("[BinanceWS] WebSocketæ•°æ®æ›´æ–°ï¼Œæ¸…ç†æ¶¨å¹…æ¦œç¼“å­˜")
		})

		// è®¢é˜…çƒ­é—¨äº¤æ˜“å¯¹çš„24hrç»Ÿè®¡æ•°æ®
		popularSymbols := []string{
			"BTC", "ETH", "BNB", "ADA", "XRP", "SOL", "DOT", "DOGE", "AVAX", "LTC",
		}

		if err := s.binanceWSClient.SubscribeTicker24h(popularSymbols, "futures"); err != nil {
			log.Printf("[INIT] è®¢é˜…24hrç»Ÿè®¡æ•°æ®å¤±è´¥: %v", err)
		}
	}()
}

// initOrderStatusSync åˆå§‹åŒ–è®¢å•çŠ¶æ€å®šæ—¶åŒæ­¥
func (s *Server) initOrderStatusSync() {
	log.Printf("[INIT] åˆå§‹åŒ–è®¢å•çŠ¶æ€å®šæ—¶åŒæ­¥...")

	// å¯åŠ¨å®šæ—¶åŒæ­¥goroutine
	go func() {
		ticker := time.NewTicker(30 * time.Second) // æ¯30ç§’åŒæ­¥ä¸€æ¬¡
		defer ticker.Stop()

		// é¦–æ¬¡å¯åŠ¨æ—¶ç­‰å¾…10ç§’å†æ‰§è¡Œï¼Œé¿å…å¯åŠ¨æ—¶è´Ÿè½½è¿‡é«˜
		time.Sleep(10 * time.Second)

		// å®šæ—¶æ‰§è¡ŒåŒæ­¥
		for {
			select {
			case <-ticker.C:
				log.Printf("[Order-Sync] å¼€å§‹å®šæ—¶è®¢å•çŠ¶æ€åŒæ­¥...")
				startTime := time.Now()

				if err := s.syncAllOrderStatus(); err != nil {
					log.Printf("[Order-Sync] å®šæ—¶åŒæ­¥å¤±è´¥: %v", err)
				} else {
					duration := time.Since(startTime)
					log.Printf("[Order-Sync] å®šæ—¶åŒæ­¥å®Œæˆï¼Œè€—æ—¶: %v", duration)
				}
			}
		}
	}()

	log.Printf("[INIT] è®¢å•çŠ¶æ€å®šæ—¶åŒæ­¥åˆå§‹åŒ–å®Œæˆï¼ˆæ¯30ç§’æ‰§è¡Œä¸€æ¬¡ï¼‰")
}

// initPositionChangeDetection åˆå§‹åŒ–æŒä»“å˜åŒ–æ£€æµ‹æœºåˆ¶
func (s *Server) initPositionChangeDetection() {
	log.Printf("[INIT] åˆå§‹åŒ–æŒä»“å˜åŒ–æ£€æµ‹æœºåˆ¶...")

	// åˆå§‹åŒ–æŒä»“å¿«ç…§å­˜å‚¨
	s.positionSnapshots = make(map[string]*PositionSnapshot)
	s.lastPositionCheck = time.Now()

	// å¯åŠ¨æŒä»“å˜åŒ–æ£€æµ‹goroutine
	go func() {
		ticker := time.NewTicker(15 * time.Second) // æ¯15ç§’æ£€æµ‹ä¸€æ¬¡æŒä»“å˜åŒ–
		defer ticker.Stop()

		// é¦–æ¬¡å¯åŠ¨æ—¶ç­‰å¾…5ç§’å†æ‰§è¡Œ
		time.Sleep(5 * time.Second)

		for {
			select {
			case <-ticker.C:
				if err := s.detectPositionChanges(); err != nil {
					log.Printf("[Position-Detect] æŒä»“å˜åŒ–æ£€æµ‹å¤±è´¥: %v", err)
				}
			}
		}
	}()

	log.Printf("[INIT] æŒä»“å˜åŒ–æ£€æµ‹æœºåˆ¶åˆå§‹åŒ–å®Œæˆï¼ˆæ¯15ç§’æ£€æµ‹ä¸€æ¬¡ï¼‰")
}

// detectPositionChanges æ£€æµ‹æŒä»“å˜åŒ–å¹¶å¤„ç†å¤–éƒ¨æ“ä½œ
func (s *Server) detectPositionChanges() error {
	// è·å–å½“å‰æ‰€æœ‰ç”¨æˆ·çš„æŒä»“ä¿¡æ¯
	currentPositions, err := s.getAllUserPositions()
	if err != nil {
		return fmt.Errorf("è·å–ç”¨æˆ·æŒä»“å¤±è´¥: %w", err)
	}

	// è·å–ä¸Šæ¬¡çš„æŒä»“å¿«ç…§
	lastSnapshots := s.getLastPositionSnapshots()

	// æ£€æµ‹æŒä»“å˜åŒ–
	changes := s.detectPositionChangesInternal(currentPositions, lastSnapshots)

	// å¤„ç†æ£€æµ‹åˆ°çš„å˜åŒ–
	for _, change := range changes {
		if err := s.handlePositionChange(change); err != nil {
			log.Printf("[Position-Detect] å¤„ç†æŒä»“å˜åŒ–å¤±è´¥ %s: %v", change.Symbol, err)
		}
	}

	// æ›´æ–°æŒä»“å¿«ç…§
	s.updatePositionSnapshots(currentPositions)

	s.positionMutex.Lock()
	s.lastPositionCheck = time.Now()
	s.positionMutex.Unlock()

	return nil
}

// detectAndProcessExternalOperations æ£€æµ‹å’Œå¤„ç†å¤–éƒ¨æ“ä½œ
func (s *Server) detectAndProcessExternalOperations(client *bf.Client) (processedCount, errorCount int) {
	log.Printf("[Order-Sync] å¼€å§‹æ£€æµ‹å¤–éƒ¨æ“ä½œ...")

	// æŸ¥è¯¢æœ€è¿‘å¯èƒ½å—å¤–éƒ¨æ“ä½œå½±å“çš„è®¢å•
	// åŒ…æ‹¬çŠ¶æ€å˜ä¸ºfilledæˆ–cancelledçš„è®¢å•ï¼Œä»¥åŠæˆäº¤æ•°é‡å‘ç”Ÿå˜åŒ–çš„è®¢å•
	var affectedOrders []pdb.ScheduledOrder
	err := s.db.DB().Model(&pdb.ScheduledOrder{}).
		Where("status IN (?) AND client_order_id != '' AND exchange = ? AND updated_at > ?",
			[]string{"filled", "cancelled", "failed"}, "binance_futures", time.Now().Add(-1*time.Hour)).
		Find(&affectedOrders).Error

	if err != nil {
		log.Printf("[Order-Sync] æŸ¥è¯¢å—å½±å“è®¢å•å¤±è´¥: %v", err)
		return 0, 1
	}

	if len(affectedOrders) == 0 {
		log.Printf("[Order-Sync] æ²¡æœ‰éœ€è¦æ£€æŸ¥å¤–éƒ¨æ“ä½œçš„è®¢å•")
		return 0, 0
	}

	log.Printf("[Order-Sync] æ£€æŸ¥ %d ä¸ªè®¢å•çš„å¤–éƒ¨æ“ä½œå¯èƒ½æ€§", len(affectedOrders))

	for _, order := range affectedOrders {
		if err := s.analyzeOrderForExternalOperation(&order, client); err != nil {
			log.Printf("[Order-Sync] åˆ†æè®¢å• %d å¤–éƒ¨æ“ä½œå¤±è´¥: %v", order.ID, err)
			errorCount++
		} else {
			processedCount++
		}
	}

	return processedCount, errorCount
}

// analyzeOrderForExternalOperation åˆ†æè®¢å•æ˜¯å¦å—åˆ°å¤–éƒ¨æ“ä½œå½±å“
func (s *Server) analyzeOrderForExternalOperation(order *pdb.ScheduledOrder, client *bf.Client) error {
	// è·å–è®¢å•çš„æœ€æ–°çŠ¶æ€
	orderStatus, err := client.QueryOrder(order.Symbol, order.ClientOrderId)
	if err != nil {
		// å¦‚æœæ— æ³•æŸ¥è¯¢è®¢å•çŠ¶æ€ï¼Œå¯èƒ½è®¢å•å·²è¢«åˆ é™¤æˆ–APIé”™è¯¯
		if strings.Contains(err.Error(), "order not found") {
			log.Printf("[Order-Sync] è®¢å• %s åœ¨äº¤æ˜“æ‰€ä¸å­˜åœ¨ï¼Œå¯èƒ½å·²è¢«å¤–éƒ¨åˆ é™¤", order.ClientOrderId)
			return s.handleOrderExternallyDeleted(order)
		}
		return fmt.Errorf("æŸ¥è¯¢è®¢å•çŠ¶æ€å¤±è´¥: %w", err)
	}

	// æ£€æŸ¥è®¢å•çŠ¶æ€æ˜¯å¦ä¸æ•°æ®åº“ä¸€è‡´
	statusChanged := s.hasOrderStatusChanged(order, orderStatus)
	executedQtyChanged := s.hasExecutedQuantityChanged(order, orderStatus)

	if !statusChanged && !executedQtyChanged {
		// è®¢å•çŠ¶æ€æ­£å¸¸ï¼Œæ— éœ€å¤„ç†
		return nil
	}

	// æ£€æµ‹åˆ°çŠ¶æ€å˜åŒ–ï¼Œåˆ†ææ˜¯å¦ä¸ºå¤–éƒ¨æ“ä½œ
	externalOpType := s.determineExternalOperationType(order, orderStatus, statusChanged, executedQtyChanged)

	if externalOpType != "" {
		log.Printf("[Order-Sync] æ£€æµ‹åˆ°å¤–éƒ¨æ“ä½œ: è®¢å• %d (%s) - %s",
			order.ID, order.ClientOrderId, externalOpType)

		// åˆ›å»ºå¤–éƒ¨æ“ä½œè®°å½•
		externalOp := &pdb.ExternalOperation{
			Symbol:        order.Symbol,
			OperationType: externalOpType,
			OldAmount:     order.ExecutedQty,
			NewAmount:     orderStatus.ExecutedQty,
			Confidence:    0.9, // è®¢å•çŠ¶æ€å˜åŒ–é€šå¸¸å¾ˆç¡®å®š
			DetectedAt:    time.Now(),
			Status:        "processed",
			UserID:        order.UserID,
			Notes:         fmt.Sprintf("è®¢å•çŠ¶æ€åŒæ­¥æ£€æµ‹: %s -> %s", order.Status, s.mapExchangeStatus(orderStatus.Status)),
		}

		if err := s.db.DB().Create(externalOp).Error; err != nil {
			return fmt.Errorf("åˆ›å»ºå¤–éƒ¨æ“ä½œè®°å½•å¤±è´¥: %w", err)
		}

		// æ›´æ–°è®¢å•çŠ¶æ€ä»¥åæ˜ å¤–éƒ¨æ“ä½œ
		if err := s.updateOrderStatusFromExternalOperation(order, orderStatus); err != nil {
			log.Printf("[Order-Sync] æ›´æ–°è®¢å•çŠ¶æ€å¤±è´¥: %v", err)
		}

		// é€šçŸ¥ç”¨æˆ·
		s.notifyUserExternalOperation(externalOp)
	}

	return nil
}

// hasOrderStatusChanged æ£€æŸ¥è®¢å•çŠ¶æ€æ˜¯å¦å‘ç”Ÿå˜åŒ–
func (s *Server) hasOrderStatusChanged(order *pdb.ScheduledOrder, orderStatus *bf.QueryOrderResp) bool {
	currentStatus := s.mapExchangeStatus(orderStatus.Status)
	return order.Status != currentStatus
}

// hasExecutedQuantityChanged æ£€æŸ¥æˆäº¤æ•°é‡æ˜¯å¦å‘ç”Ÿå˜åŒ–
func (s *Server) hasExecutedQuantityChanged(order *pdb.ScheduledOrder, orderStatus *bf.QueryOrderResp) bool {
	return order.ExecutedQty != orderStatus.ExecutedQty && orderStatus.ExecutedQty != ""
}

// determineExternalOperationType ç¡®å®šå¤–éƒ¨æ“ä½œç±»å‹
func (s *Server) determineExternalOperationType(order *pdb.ScheduledOrder, orderStatus *bf.QueryOrderResp, statusChanged, qtyChanged bool) string {
	currentStatus := s.mapExchangeStatus(orderStatus.Status)

	// è®¢å•è¢«å–æ¶ˆ
	if statusChanged && currentStatus == "cancelled" && order.Status == "processing" {
		return "external_cancel"
	}

	// è®¢å•è¢«ä¿®æ”¹ï¼ˆæ•°é‡å˜åŒ–ï¼‰
	if qtyChanged && !statusChanged {
		if orderStatus.ExecutedQty > order.ExecutedQty {
			return "external_modify_increase"
		} else {
			return "external_modify_decrease"
		}
	}

	// è®¢å•éƒ¨åˆ†æˆäº¤åè¢«å–æ¶ˆ
	if statusChanged && currentStatus == "cancelled" && order.Status == "filled" && orderStatus.ExecutedQty != order.ExecutedQty {
		return "external_partial_fill_cancel"
	}

	return "" // ä¸æ˜¯å¤–éƒ¨æ“ä½œ
}

// handleOrderExternallyDeleted å¤„ç†è®¢å•è¢«å¤–éƒ¨åˆ é™¤çš„æƒ…å†µ
func (s *Server) handleOrderExternallyDeleted(order *pdb.ScheduledOrder) error {
	log.Printf("[Order-Sync] å¤„ç†å¤–éƒ¨åˆ é™¤çš„è®¢å•: %d (%s)", order.ID, order.ClientOrderId)

	// åˆ›å»ºå¤–éƒ¨æ“ä½œè®°å½•
	externalOp := &pdb.ExternalOperation{
		Symbol:        order.Symbol,
		OperationType: "external_order_deleted",
		OldAmount:     order.ExecutedQty,
		NewAmount:     "0",
		Confidence:    0.95, // è®¢å•ä¸å­˜åœ¨é€šå¸¸å¾ˆç¡®å®š
		DetectedAt:    time.Now(),
		Status:        "processed",
		UserID:        order.UserID,
		Notes:         "è®¢å•åœ¨äº¤æ˜“æ‰€ä¸å­˜åœ¨ï¼Œå¯èƒ½å·²è¢«å¤–éƒ¨åˆ é™¤",
	}

	if err := s.db.DB().Create(externalOp).Error; err != nil {
		return fmt.Errorf("åˆ›å»ºå¤–éƒ¨åˆ é™¤æ“ä½œè®°å½•å¤±è´¥: %w", err)
	}

	// æ›´æ–°è®¢å•çŠ¶æ€
	updateData := map[string]interface{}{
		"status":     "failed",
		"result":     "è®¢å•åœ¨äº¤æ˜“æ‰€ä¸å­˜åœ¨ï¼Œå¯èƒ½å·²è¢«å¤–éƒ¨åˆ é™¤",
		"updated_at": time.Now(),
	}

	if err := s.db.DB().Model(order).Updates(updateData).Error; err != nil {
		return fmt.Errorf("æ›´æ–°è®¢å•çŠ¶æ€å¤±è´¥: %w", err)
	}

	// é€šçŸ¥ç”¨æˆ·
	s.notifyUserExternalOperation(externalOp)

	return nil
}

// updateOrderStatusFromExternalOperation æ ¹æ®å¤–éƒ¨æ“ä½œæ›´æ–°è®¢å•çŠ¶æ€
func (s *Server) updateOrderStatusFromExternalOperation(order *pdb.ScheduledOrder, orderStatus *bf.QueryOrderResp) error {
	updateData := map[string]interface{}{
		"status":            s.mapExchangeStatus(orderStatus.Status),
		"executed_quantity": orderStatus.ExecutedQty,
		"avg_price":         orderStatus.AvgPrice,
		"updated_at":        time.Now(),
	}

	// å¦‚æœè®¢å•æœ‰äº¤æ˜“æ‰€è®¢å•IDï¼Œä¹Ÿæ›´æ–°
	if orderStatus.OrderId > 0 {
		updateData["exchange_order_id"] = strconv.FormatInt(orderStatus.OrderId, 10)
	}

	return s.db.DB().Model(order).Updates(updateData).Error
}

// mapExchangeStatus å°†äº¤æ˜“æ‰€çŠ¶æ€æ˜ å°„ä¸ºç³»ç»ŸçŠ¶æ€
func (s *Server) mapExchangeStatus(exchangeStatus string) string {
	switch exchangeStatus {
	case "FILLED":
		return "filled"
	case "CANCELED", "PENDING_CANCEL":
		return "cancelled"
	case "REJECTED", "EXPIRED":
		return "failed"
	case "PARTIALLY_FILLED":
		return "filled" // éƒ¨åˆ†æˆäº¤ä»æ ‡è®°ä¸ºfilled
	case "NEW":
		return "processing"
	default:
		return "processing"
	}
}

// getAllUserPositions è·å–æ‰€æœ‰ç”¨æˆ·çš„æŒä»“ä¿¡æ¯
func (s *Server) getAllUserPositions() (map[uint]map[string]*PositionSnapshot, error) {
	// æŸ¥è¯¢æ‰€æœ‰ç”¨æˆ·ï¼ˆAPIå¯†é’¥ä»é…ç½®æ–‡ä»¶è¯»å–ï¼Œä¸éœ€è¦æ•°æ®åº“å­—æ®µï¼‰
	var users []struct {
		ID       uint   `json:"id"`
		Username string `json:"username"`
	}

	err := s.db.DB().Table("users").
		Select("id, username").
		Find(&users).Error

	if err != nil {
		return nil, fmt.Errorf("æŸ¥è¯¢ç”¨æˆ·åˆ—è¡¨å¤±è´¥: %w", err)
	}

	allPositions := make(map[uint]map[string]*PositionSnapshot)

	for _, user := range users {
		// ä¸ºæ¯ä¸ªç”¨æˆ·åˆ›å»ºå¸å®‰å®¢æˆ·ç«¯
		useTestnet := s.cfg.Exchange.Binance.IsTestnet
		client := bf.New(useTestnet, s.cfg.Exchange.Binance.APIKey, s.cfg.Exchange.Binance.SecretKey)

		// æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨çš„æ˜¯å…¨å±€APIå¯†é’¥ï¼Œå®é™…åº”è¯¥ä½¿ç”¨æ¯ä¸ªç”¨æˆ·çš„APIå¯†é’¥
		// TODO: ä»ç”¨æˆ·é…ç½®ä¸­è·å–æ¯ä¸ªç”¨æˆ·çš„APIå¯†é’¥
		positions, err := client.GetPositions()
		if err != nil {
			log.Printf("[Position-Detect] è·å–ç”¨æˆ· %d æŒä»“å¤±è´¥: %v", user.ID, err)
			continue
		}

		userPositions := make(map[string]*PositionSnapshot)
		for _, pos := range positions {
			// åªå¤„ç†æœ‰æŒä»“çš„äº¤æ˜“å¯¹
			if amt, _ := strconv.ParseFloat(pos.PositionAmt, 64); amt != 0 {
				userPositions[pos.Symbol] = &PositionSnapshot{
					Symbol:       pos.Symbol,
					PositionAmt:  pos.PositionAmt,
					EntryPrice:   pos.EntryPrice,
					MarkPrice:    pos.MarkPrice,
					UpdateTime:   pos.UpdateTime,
					SnapshotTime: time.Now(),
					UserID:       user.ID,
				}
			}
		}

		if len(userPositions) > 0 {
			allPositions[user.ID] = userPositions
		}
	}

	return allPositions, nil
}

// getLastPositionSnapshots è·å–ä¸Šæ¬¡çš„æŒä»“å¿«ç…§
func (s *Server) getLastPositionSnapshots() map[string]*PositionSnapshot {
	s.positionMutex.RLock()
	defer s.positionMutex.RUnlock()

	snapshots := make(map[string]*PositionSnapshot)
	for symbol, snapshot := range s.positionSnapshots {
		snapshots[symbol] = snapshot
	}
	return snapshots
}

// detectPositionChangesInternal æ£€æµ‹æŒä»“å˜åŒ–çš„æ ¸å¿ƒé€»è¾‘
func (s *Server) detectPositionChangesInternal(currentPositions map[uint]map[string]*PositionSnapshot, lastSnapshots map[string]*PositionSnapshot) []DetectedChange {
	var changes []DetectedChange

	// ç”¨äºè·Ÿè¸ªå·²å¤„ç†çš„æŒä»“ï¼Œé¿å…é‡å¤æ£€æµ‹
	processedSymbols := make(map[string]bool)

	// æ£€æµ‹å½“å‰æŒä»“çš„å˜åŒ–
	for userID, userPositions := range currentPositions {
		for symbol, current := range userPositions {
			key := fmt.Sprintf("%d_%s", userID, symbol)
			processedSymbols[key] = true

			previous, existed := lastSnapshots[key]

			if !existed {
				// æ–°æŒä»“å‡ºç° - å¯èƒ½å¤–éƒ¨å¼€ä»“
				change := DetectedChange{
					Symbol:     symbol,
					Type:       "new",
					OldAmt:     "0",
					NewAmt:     current.PositionAmt,
					Confidence: s.calculateChangeConfidence(current, nil, "new"),
					Timestamp:  time.Now(),
				}
				if change.Confidence > 0.7 { // åªå¤„ç†é«˜ç½®ä¿¡åº¦çš„å˜åŒ–
					changes = append(changes, change)
				}
			} else if previous.PositionAmt != current.PositionAmt {
				// æŒä»“æ•°é‡å˜åŒ– - å¯èƒ½éƒ¨åˆ†å¹³ä»“
				change := DetectedChange{
					Symbol:     symbol,
					Type:       "changed",
					OldAmt:     previous.PositionAmt,
					NewAmt:     current.PositionAmt,
					Confidence: s.calculateChangeConfidence(current, previous, "changed"),
					Timestamp:  time.Now(),
				}
				if change.Confidence > 0.8 {
					changes = append(changes, change)
				}
			}
		}
	}

	// æ£€æµ‹æ¶ˆå¤±çš„æŒä»“
	for key, previous := range lastSnapshots {
		if !processedSymbols[key] {
			// æŒä»“æ¶ˆå¤± - å®Œå…¨å¹³ä»“
			change := DetectedChange{
				Symbol:     previous.Symbol,
				Type:       "closed",
				OldAmt:     previous.PositionAmt,
				NewAmt:     "0",
				Confidence: 0.95, // æŒä»“æ¶ˆå¤±é€šå¸¸å¾ˆç¡®å®š
				Timestamp:  time.Now(),
			}
			changes = append(changes, change)
		}
	}

	return changes
}

// calculateChangeConfidence è®¡ç®—æŒä»“å˜åŒ–çš„ç½®ä¿¡åº¦
func (s *Server) calculateChangeConfidence(current, previous *PositionSnapshot, changeType string) float64 {
	confidence := 0.5 // åŸºç¡€ç½®ä¿¡åº¦

	switch changeType {
	case "new":
		// æ–°æŒä»“çš„ç½®ä¿¡åº¦è®¡ç®—
		if amt, _ := strconv.ParseFloat(current.PositionAmt, 64); amt > 0.1 {
			confidence += 0.3 // æœ‰æ„ä¹‰çš„æŒä»“é‡
		}
		if current.UpdateTime > 0 {
			confidence += 0.2 // æœ‰æ›´æ–°æ—¶é—´æˆ³
		}

	case "changed":
		// æŒä»“å˜åŒ–çš„ç½®ä¿¡åº¦è®¡ç®—
		oldAmt, _ := strconv.ParseFloat(previous.PositionAmt, 64)
		newAmt, _ := strconv.ParseFloat(current.PositionAmt, 64)
		changeRatio := math.Abs(newAmt-oldAmt) / math.Abs(oldAmt)

		if changeRatio > 0.1 { // å˜åŒ–è¶…è¿‡10%
			confidence += 0.4
		} else if changeRatio > 0.01 { // å˜åŒ–è¶…è¿‡1%
			confidence += 0.2
		}

		if current.UpdateTime != previous.UpdateTime {
			confidence += 0.2 // æ›´æ–°æ—¶é—´ä¸åŒ
		}

	case "closed":
		confidence = 0.95 // æŒä»“æ¶ˆå¤±é€šå¸¸å¾ˆç¡®å®š
	}

	// æ—¶é—´çª—å£æ£€æŸ¥ - åªåœ¨æ´»è·ƒæ—¶é—´å†…æ£€æµ‹å˜åŒ–
	now := time.Now()
	if now.Hour() >= 8 && now.Hour() <= 20 { // å·¥ä½œæ—¶é—´å†…
		confidence += 0.1
	}

	return math.Min(confidence, 1.0)
}

// handlePositionChange å¤„ç†æ£€æµ‹åˆ°çš„æŒä»“å˜åŒ–
func (s *Server) handlePositionChange(change DetectedChange) error {
	log.Printf("[Position-Detect] æ£€æµ‹åˆ°æŒä»“å˜åŒ–: %s %s %s -> %s (ç½®ä¿¡åº¦: %.2f)",
		change.Symbol, change.Type, change.OldAmt, change.NewAmt, change.Confidence)

	// è®°å½•æŒä»“å˜åŒ–åˆ°å®¡è®¡æ—¥å¿—
	oldPosition := &PositionSnapshot{
		Symbol:      change.Symbol,
		PositionAmt: change.OldAmt,
	}
	newPosition := &PositionSnapshot{
		Symbol:      change.Symbol,
		PositionAmt: change.NewAmt,
	}

	s.logPositionOperation(0, change.Symbol, "position_change_detected",
		fmt.Sprintf("æ£€æµ‹åˆ°æŒä»“å˜åŒ–: %s -> %s", change.OldAmt, change.NewAmt),
		oldPosition, newPosition, "system", "info")

	switch change.Type {
	case "new":
		return s.handleNewPosition(change)
	case "changed":
		return s.handlePositionQuantityChange(change)
	case "closed":
		return s.handlePositionClosed(change)
	default:
		log.Printf("[Position-Detect] æœªçŸ¥çš„å˜åŒ–ç±»å‹: %s", change.Type)
	}

	return nil
}

// handleNewPosition å¤„ç†æ–°æŒä»“å‡ºç°
func (s *Server) handleNewPosition(change DetectedChange) error {
	log.Printf("[Position-Detect] æ–°æŒä»“å‡ºç°: %s æ•°é‡=%s", change.Symbol, change.NewAmt)

	// è¿™é‡Œå¯ä»¥æ·»åŠ é€»è¾‘æ¥æ£€æŸ¥æ˜¯å¦æ˜¯ç³»ç»Ÿçš„è®¢å•å¯¼è‡´çš„
	// å¦‚æœä¸æ˜¯ï¼Œå¯èƒ½æ˜¯ç”¨æˆ·åœ¨å®˜ç½‘æ‰‹åŠ¨å¼€ä»“

	return s.createExternalOperationRecord(change, "external_open")
}

// handlePositionQuantityChange å¤„ç†æŒä»“æ•°é‡å˜åŒ–
func (s *Server) handlePositionQuantityChange(change DetectedChange) error {
	log.Printf("[Position-Detect] æŒä»“æ•°é‡å˜åŒ–: %s %s -> %s", change.Symbol, change.OldAmt, change.NewAmt)

	oldAmt, _ := strconv.ParseFloat(change.OldAmt, 64)
	newAmt, _ := strconv.ParseFloat(change.NewAmt, 64)

	if math.Abs(newAmt) < math.Abs(oldAmt) {
		// æŒä»“å‡å°‘ - å¯èƒ½æ˜¯éƒ¨åˆ†å¹³ä»“
		return s.createExternalOperationRecord(change, "external_partial_close")
	} else {
		// æŒä»“å¢åŠ  - å¯èƒ½æ˜¯åŠ ä»“
		return s.createExternalOperationRecord(change, "external_add_position")
	}
}

// handlePositionClosed å¤„ç†æŒä»“å®Œå…¨å…³é—­
func (s *Server) handlePositionClosed(change DetectedChange) error {
	log.Printf("[Position-Detect] æŒä»“å®Œå…¨å…³é—­: %s", change.Symbol)

	return s.createExternalOperationRecord(change, "external_full_close")
}

// createExternalOperationRecord åˆ›å»ºå¤–éƒ¨æ“ä½œè®°å½•
func (s *Server) createExternalOperationRecord(change DetectedChange, operationType string) error {
	// åˆ›å»ºå¤–éƒ¨æ“ä½œè®°å½•åˆ°æ•°æ®åº“
	externalOp := &pdb.ExternalOperation{
		Symbol:        change.Symbol,
		OperationType: operationType,
		OldAmount:     change.OldAmt,
		NewAmount:     change.NewAmt,
		Confidence:    change.Confidence,
		DetectedAt:    change.Timestamp,
		Status:        "detected",
	}

	if err := s.db.DB().Create(externalOp).Error; err != nil {
		return fmt.Errorf("åˆ›å»ºå¤–éƒ¨æ“ä½œè®°å½•å¤±è´¥: %w", err)
	}

	// è®°å½•å¤–éƒ¨æ“ä½œåˆ°å®¡è®¡æ—¥å¿—
	s.logSystemOperation("external_operation_detected",
		fmt.Sprintf("æ£€æµ‹åˆ°å¤–éƒ¨æ“ä½œ: %s %s %s -> %s", change.Symbol, operationType, change.OldAmt, change.NewAmt),
		"info",
		map[string]interface{}{
			"external_operation_id": externalOp.ID,
			"symbol":                change.Symbol,
			"operation_type":        operationType,
			"old_amount":            change.OldAmt,
			"new_amount":            change.NewAmt,
			"confidence":            change.Confidence,
		},
		"")

	// æŸ¥æ‰¾ç›¸å…³çš„å¼€ä»“è®¢å•ï¼Œå°è¯•å»ºç«‹å…³è”
	if operationType == "external_full_close" || operationType == "external_partial_close" {
		if err := s.linkExternalCloseToEntryOrder(externalOp); err != nil {
			log.Printf("[Position-Detect] å…³è”å¤–éƒ¨å¹³ä»“è®¢å•å¤±è´¥: %v", err)
		}
	}

	// å‘é€ç”¨æˆ·é€šçŸ¥
	s.notifyUserExternalOperation(externalOp)

	log.Printf("[Position-Detect] å¤–éƒ¨æ“ä½œè®°å½•åˆ›å»ºæˆåŠŸ: %s %s", change.Symbol, operationType)
	return nil
}

// handleBracketExternalClose å¤„ç†Bracketè®¢å•çš„å¤–éƒ¨å¹³ä»“
func (s *Server) handleBracketExternalClose(entryOrder pdb.ScheduledOrder, externalOp *pdb.ExternalOperation) error {
	log.Printf("[Bracket-External] å¤„ç†Bracketè®¢å• %d çš„å¤–éƒ¨å¹³ä»“", entryOrder.ID)

	// æŸ¥æ‰¾å¯¹åº”çš„BracketLink
	var bracketLink pdb.BracketLink
	err := s.db.DB().Where("entry_client_id = ?", entryOrder.ClientOrderId).First(&bracketLink).Error
	if err != nil {
		return fmt.Errorf("æŸ¥æ‰¾BracketLinkå¤±è´¥: %w", err)
	}

	log.Printf("[Bracket-External] å¤„ç†Bracketè®¢å• %s çš„å¤–éƒ¨å¹³ä»“ (çŠ¶æ€: %s)", bracketLink.GroupID, bracketLink.Status)
	// æ— è®ºBracketçŠ¶æ€å¦‚ä½•ï¼Œéƒ½è¦å°è¯•å–æ¶ˆå¯èƒ½ä»æ´»è·ƒçš„æ¡ä»¶å§”æ‰˜
	// å› ä¸ºå¯èƒ½å­˜åœ¨Bracketå…³é—­ä½†æ¡ä»¶å§”æ‰˜æœªè¢«æ­£ç¡®å–æ¶ˆçš„æƒ…å†µ

	// ä½¿ç”¨é…ç½®çš„ç¯å¢ƒè®¾ç½®è·å–äº¤æ˜“æ‰€å®¢æˆ·ç«¯
	useTestnet := s.cfg.Exchange.Binance.IsTestnet
	client := bf.New(useTestnet, s.cfg.Exchange.Binance.APIKey, s.cfg.Exchange.Binance.SecretKey)

	// å–æ¶ˆæ´»è·ƒçš„æ¡ä»¶è®¢å•
	cancelledCount := 0

	log.Printf("[Bracket-External] å¼€å§‹æ£€æŸ¥æ¡ä»¶å§”æ‰˜ - TP: %s, SL: %s", bracketLink.TPClientID, bracketLink.SLClientID)

	// å–æ¶ˆæ­¢ç›ˆè®¢å•
	if bracketLink.TPClientID != "" {
		log.Printf("[Bracket-External] å°è¯•å–æ¶ˆæ­¢ç›ˆè®¢å• %s", bracketLink.TPClientID)
		if err := s.cancelConditionalOrderIfNeeded(client, externalOp.Symbol, bracketLink.TPClientID, "TP"); err != nil {
			log.Printf("[Bracket-External] å–æ¶ˆæ­¢ç›ˆè®¢å•å¤±è´¥ %s: %v", bracketLink.TPClientID, err)
		} else {
			cancelledCount++
			log.Printf("[Bracket-External] âœ… æˆåŠŸå–æ¶ˆæ­¢ç›ˆè®¢å• %s", bracketLink.TPClientID)
		}
	} else {
		log.Printf("[Bracket-External] æ­¢ç›ˆè®¢å•ClientIDä¸ºç©ºï¼Œè·³è¿‡")
	}

	// å–æ¶ˆæ­¢æŸè®¢å•
	if bracketLink.SLClientID != "" {
		log.Printf("[Bracket-External] å°è¯•å–æ¶ˆæ­¢æŸè®¢å• %s", bracketLink.SLClientID)
		if err := s.cancelConditionalOrderIfNeeded(client, externalOp.Symbol, bracketLink.SLClientID, "SL"); err != nil {
			log.Printf("[Bracket-External] å–æ¶ˆæ­¢æŸè®¢å•å¤±è´¥ %s: %v", bracketLink.SLClientID, err)
		} else {
			cancelledCount++
			log.Printf("[Bracket-External] âœ… æˆåŠŸå–æ¶ˆæ­¢æŸè®¢å• %s", bracketLink.SLClientID)
		}
	} else {
		log.Printf("[Bracket-External] æ­¢æŸè®¢å•ClientIDä¸ºç©ºï¼Œè·³è¿‡")
	}

	// æ›´æ–°BracketçŠ¶æ€ä¸ºclosed
	if err := s.db.DB().Model(&pdb.BracketLink{}).Where("id = ?", bracketLink.ID).Update("status", "closed").Error; err != nil {
		log.Printf("[Bracket-External] æ›´æ–°BracketçŠ¶æ€å¤±è´¥ %d: %v", bracketLink.ID, err)
		return fmt.Errorf("æ›´æ–°BracketçŠ¶æ€å¤±è´¥: %w", err)
	}

	// ğŸ”§ ä¿®å¤ï¼šå¼€ä»“è®¢å•çŠ¶æ€ä¿æŒä¸ºfilledï¼ˆå·²æˆäº¤ï¼‰ï¼Œé€šè¿‡å…³è”çš„å¹³ä»“è®¢å•æ¥è¡¨ç¤º"å·²ç»“æŸ"
	// ä¸éœ€è¦æ›´æ–°å¼€ä»“è®¢å•çŠ¶æ€ï¼Œä¿æŒfilledçŠ¶æ€ï¼Œè®©å‰ç«¯é€šè¿‡related_orders.has_closeæ¥æ˜¾ç¤º"å·²ç»“æŸ"

	// ğŸ”§ æ–°å¢ï¼šåˆ›å»ºå¤–éƒ¨å¹³ä»“æ“ä½œè®°å½•ï¼Œå…³è”åˆ°å¼€ä»“è®¢å•
	// æ ¹æ®åŸæŒä»“æ–¹å‘ç¡®å®šå¹³ä»“æ–¹å‘å’Œå¹³ä»“æ•°é‡
	oldAmt, _ := strconv.ParseFloat(externalOp.OldAmount, 64)
	newAmt, _ := strconv.ParseFloat(externalOp.NewAmount, 64)
	closeQuantity := fmt.Sprintf("%.8f", math.Abs(oldAmt-newAmt)) // å¹³ä»“æ•°é‡ä¸ºå˜åŒ–çš„ç»å¯¹å€¼

	closeSide := "SELL" // é»˜è®¤å–å‡ºå¹³å¤š
	if oldAmt < 0 {
		closeSide = "BUY" // ä¹°å…¥å¹³ç©º
	}

	now := time.Now()
	externalCloseOrder := pdb.ScheduledOrder{
		UserID:          entryOrder.UserID,
		Exchange:        entryOrder.Exchange,
		Testnet:         entryOrder.Testnet,
		Symbol:          externalOp.Symbol,
		Side:            closeSide, // æ ¹æ®åŸæŒä»“æ–¹å‘ç¡®å®šå¹³ä»“æ–¹å‘
		OrderType:       "MARKET",
		Quantity:        closeQuantity,
		Price:           "",
		Leverage:        entryOrder.Leverage,
		ReduceOnly:      true, // è¿™æ˜¯å¹³ä»“è®¢å•
		StrategyID:      entryOrder.StrategyID,
		ExecutionID:     entryOrder.ExecutionID,
		BracketEnabled:  false, // å¤–éƒ¨å¹³ä»“ä¸æ˜¯Bracketè®¢å•
		TPPercent:       0,
		SLPercent:       0,
		TPPrice:         "",
		SLPrice:         "",
		WorkingType:     "",
		TriggerTime:     now,
		Status:          "completed", // å¤–éƒ¨æ“ä½œå·²å®Œæˆ
		Result:          fmt.Sprintf("å¤–éƒ¨å¹³ä»“æ“ä½œ: %s", externalOp.OperationType),
		ClientOrderId:   fmt.Sprintf("external-close-%d-%d", entryOrder.ID, now.Unix()),
		ExchangeOrderId: "",
		ExecutedQty:     closeQuantity,
		AvgPrice:        "0",           // å¤–éƒ¨æ“ä½œæ²¡æœ‰å…·ä½“ä»·æ ¼ä¿¡æ¯
		ParentOrderId:   entryOrder.ID, // å…³è”åˆ°å¼€ä»“è®¢å•
		CloseOrderIds:   "",
		StrategyType:    "external_operation",
		GridLevel:       0,
		CreatedAt:       now,
		UpdatedAt:       now,
	}

	if err := s.db.DB().Create(&externalCloseOrder).Error; err != nil {
		log.Printf("[Bracket-External] åˆ›å»ºå¤–éƒ¨å¹³ä»“è®¢å•è®°å½•å¤±è´¥: %v", err)
		// ä¸è¿”å›é”™è¯¯ï¼Œå› ä¸ºä¸»è¦é€»è¾‘å·²å®Œæˆ
	} else {
		log.Printf("[Bracket-External] âœ… åˆ›å»ºå¤–éƒ¨å¹³ä»“è®¢å•è®°å½•: ID=%d", externalCloseOrder.ID)

		// æ›´æ–°å¼€ä»“è®¢å•çš„close_order_idså­—æ®µ
		if err := s.updateOrderAssociations(&entryOrder, externalCloseOrder.ID); err != nil {
			log.Printf("[Bracket-External] æ›´æ–°å¼€ä»“è®¢å•çš„close_order_idså¤±è´¥: %v", err)
		}
	}

	log.Printf("[Bracket-External] Bracketè®¢å• %s å¤–éƒ¨å¹³ä»“å¤„ç†å®Œæˆï¼Œå–æ¶ˆäº† %d ä¸ªæ¡ä»¶è®¢å•",
		bracketLink.GroupID, cancelledCount)

	return nil
}

// linkExternalCloseToEntryOrder å°†å¤–éƒ¨å¹³ä»“æ“ä½œå…³è”åˆ°å¼€ä»“è®¢å•
func (s *Server) linkExternalCloseToEntryOrder(externalOp *pdb.ExternalOperation) error {
	// æŸ¥æ‰¾è¯¥äº¤æ˜“å¯¹çš„æ´»è·ƒå¼€ä»“è®¢å•
	var entryOrders []pdb.ScheduledOrder
	err := s.db.DB().Where("symbol = ? AND status = ? AND reduce_only = ? AND exchange = ?",
		externalOp.Symbol, "filled", false, "binance_futures").Find(&entryOrders).Error

	if err != nil {
		return fmt.Errorf("æŸ¥æ‰¾å¼€ä»“è®¢å•å¤±è´¥: %w", err)
	}

	if len(entryOrders) == 0 {
		log.Printf("[Position-Detect] æœªæ‰¾åˆ°ç›¸å…³çš„å¼€ä»“è®¢å•: %s", externalOp.Symbol)
		return nil
	}

	// ä¸ºæ¯ä¸ªå¼€ä»“è®¢å•åˆ›å»ºå¹³ä»“è®°å½•
	for _, entryOrder := range entryOrders {
		// ğŸ”§ ä¿®å¤ï¼šæ£€æŸ¥å¼€ä»“è®¢å•æ˜¯å¦å±äºBracketè®¢å•
		if entryOrder.BracketEnabled {
			log.Printf("[Position-Detect] å¼€ä»“è®¢å• %d å±äºBracketè®¢å•ï¼Œè·³è¿‡åˆ›å»ºå¤–éƒ¨å¹³ä»“è®°å½•ï¼Œç«‹å³å¤„ç†Bracketå…³é—­",
				entryOrder.ID)

			// ğŸ”§ æ–°å¢ï¼šç«‹å³å¤„ç†Bracketè®¢å•çš„å¤–éƒ¨å¹³ä»“
			if err := s.handleBracketExternalClose(entryOrder, externalOp); err != nil {
				log.Printf("[Position-Detect] å¤„ç†Bracketå¤–éƒ¨å¹³ä»“å¤±è´¥ %d: %v", entryOrder.ID, err)
			}
			continue
		}

		// æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰ç›¸å…³çš„å¹³ä»“è®¢å•ï¼Œé¿å…é‡å¤åˆ›å»º
		var existingCloseOrders []pdb.ScheduledOrder
		err := s.db.DB().Where("parent_order_id = ? AND reduce_only = ? AND status IN (?)",
			entryOrder.ID, true, []string{"pending", "processing", "sent", "filled", "completed"}).Find(&existingCloseOrders).Error

		if err != nil {
			log.Printf("[Position-Detect] æ£€æŸ¥ç°æœ‰å¹³ä»“è®¢å•å¤±è´¥: %v", err)
			continue
		}

		if len(existingCloseOrders) > 0 {
			log.Printf("[Position-Detect] å¼€ä»“è®¢å• %d å·²æœ‰ %d ä¸ªå¹³ä»“è®¢å•ï¼Œè·³è¿‡åˆ›å»ºå¤–éƒ¨å¹³ä»“è®¢å•",
				entryOrder.ID, len(existingCloseOrders))
			continue
		}
		// æ ¹æ®å¼€ä»“è®¢å•çš„æ–¹å‘ç¡®å®šå¹³ä»“æ–¹å‘
		closeSide := "BUY" // é»˜è®¤ä¹°å…¥å¹³ç©º
		if entryOrder.Side == "BUY" {
			closeSide = "SELL" // å–å‡ºå¹³å¤š
		}

		closeOrder := &pdb.ScheduledOrder{
			UserID:        entryOrder.UserID,
			Exchange:      entryOrder.Exchange,
			Testnet:       entryOrder.Testnet,
			Symbol:        entryOrder.Symbol,
			Side:          closeSide, // æ ¹æ®å¼€ä»“æ–¹å‘ç¡®å®šå¹³ä»“æ–¹å‘
			OrderType:     "MARKET",
			Quantity:      externalOp.NewAmount,
			Price:         "",
			Leverage:      entryOrder.Leverage,
			ReduceOnly:    true,
			TriggerTime:   externalOp.DetectedAt,
			Status:        "filled", // å¤–éƒ¨æ“ä½œå·²å®Œæˆ
			ParentOrderId: entryOrder.ID,
			ExecutedQty:   externalOp.NewAmount,
			AvgPrice:      "0", // æ— æ³•è·å–å®é™…ä»·æ ¼
			ClientOrderId: func() string {
				// ç”Ÿæˆå®‰å…¨çš„external_close ClientOrderIdï¼Œç¡®ä¿ä¸è¶…è¿‡36å­—ç¬¦
				// æˆªå–IDçš„å7ä½æ•°ï¼Œç¡®ä¿æ€»é•¿åº¦ä¸è¶…è¿‡36å­—ç¬¦
				safeEntryID := entryOrder.ID % 10000000   // 7ä½æ•°
				safeExternalID := externalOp.ID % 1000000 // 6ä½æ•°
				return fmt.Sprintf("EC_%d_%d", safeEntryID, safeExternalID)
			}(),
			ExchangeOrderId: fmt.Sprintf("external_%d", externalOp.ID),
		}

		if err := s.db.DB().Create(closeOrder).Error; err != nil {
			log.Printf("[Position-Detect] åˆ›å»ºå¤–éƒ¨å¹³ä»“è®¢å•å¤±è´¥: %v", err)
			continue
		}

		// æ›´æ–°å¼€ä»“è®¢å•çš„å…³è”å­—æ®µ
		if err := s.updateOrderAssociations(&entryOrder, closeOrder.ID); err != nil {
			log.Printf("[Position-Detect] æ›´æ–°è®¢å•å…³è”å¤±è´¥: %v", err)
		}

		log.Printf("[Position-Detect] å¤–éƒ¨å¹³ä»“è®¢å•å…³è”æˆåŠŸ: å¼€ä»“#%d -> å¹³ä»“#%d", entryOrder.ID, closeOrder.ID)
	}

	return nil
}

// Notification é€šçŸ¥ç»“æ„ä½“
type Notification struct {
	UserID    uint                   `json:"user_id"`
	Type      string                 `json:"type"`     // é€šçŸ¥ç±»å‹: external_operation, order_update, system_alert
	Title     string                 `json:"title"`    // é€šçŸ¥æ ‡é¢˜
	Message   string                 `json:"message"`  // é€šçŸ¥å†…å®¹
	Data      map[string]interface{} `json:"data"`     // é™„åŠ æ•°æ®
	Priority  string                 `json:"priority"` // ä¼˜å…ˆçº§: low, normal, high, urgent
	CreatedAt time.Time              `json:"created_at"`
}

// NotificationService é€šçŸ¥æœåŠ¡æ¥å£
type NotificationService interface {
	Send(notification *Notification) error
	SendToUser(userID uint, notification *Notification) error
	Broadcast(notification *Notification) error
}

// SendToUser å‘é€é€šçŸ¥ç»™æŒ‡å®šç”¨æˆ·
func (c *CompositeNotificationService) SendToUser(userID uint, notification *Notification) error {
	notification.UserID = userID
	return c.Send(notification)
}

// Broadcast å¹¿æ’­é€šçŸ¥ç»™æ‰€æœ‰ç”¨æˆ·
func (c *CompositeNotificationService) Broadcast(notification *Notification) error {
	// TODO: å®ç°å¹¿æ’­é€»è¾‘ï¼Œè·å–æ‰€æœ‰ç”¨æˆ·å¹¶å‘é€é€šçŸ¥
	log.Printf("[Notification] å¹¿æ’­é€šçŸ¥: %s", notification.Title)
	// è¿™é‡Œåº”è¯¥æŸ¥è¯¢æ‰€æœ‰ç”¨æˆ·å¹¶é€ä¸ªå‘é€
	return nil
}

// WebSocketNotificationService WebSocketé€šçŸ¥æœåŠ¡
type WebSocketNotificationService struct {
	// è¿™é‡Œå¯ä»¥é›†æˆWebSocketè¿æ¥ç®¡ç†
}

// EmailNotificationService é‚®ä»¶é€šçŸ¥æœåŠ¡
type EmailNotificationService struct {
	smtpServer string
	smtpPort   int
	username   string
	password   string
	fromEmail  string
}

// SMSNotificationService çŸ­ä¿¡é€šçŸ¥æœåŠ¡
type SMSNotificationService struct {
	apiKey    string
	apiSecret string
	sender    string
}

// CompositeNotificationService å¤åˆé€šçŸ¥æœåŠ¡
type CompositeNotificationService struct {
	webSocketSvc *WebSocketNotificationService
	emailSvc     *EmailNotificationService
	smsSvc       *SMSNotificationService
}

// NewCompositeNotificationService åˆ›å»ºå¤åˆé€šçŸ¥æœåŠ¡
func NewCompositeNotificationService(cfg *config.Config) *CompositeNotificationService {
	return &CompositeNotificationService{
		webSocketSvc: &WebSocketNotificationService{},
		emailSvc: &EmailNotificationService{
			smtpServer: cfg.Notification.SMTP.Server,
			smtpPort:   cfg.Notification.SMTP.Port,
			username:   cfg.Notification.SMTP.Username,
			password:   cfg.Notification.SMTP.Password,
			fromEmail:  cfg.Notification.SMTP.FromEmail,
		},
		smsSvc: &SMSNotificationService{
			apiKey:    cfg.Notification.SMS.APIKey,
			apiSecret: cfg.Notification.SMS.APISecret,
			sender:    cfg.Notification.SMS.Sender,
		},
	}
}

// Send å‘é€é€šçŸ¥
func (c *CompositeNotificationService) Send(notification *Notification) error {
	var errors []error

	// 1. WebSocketå®æ—¶é€šçŸ¥ï¼ˆä¸»è¦æ¸ é“ï¼‰
	if err := c.webSocketSvc.Send(notification); err != nil {
		log.Printf("[Notification] WebSocketé€šçŸ¥å¤±è´¥: %v", err)
		errors = append(errors, fmt.Errorf("websocket: %w", err))
	}

	// 2. æ ¹æ®ä¼˜å…ˆçº§å’Œç±»å‹å†³å®šæ˜¯å¦å‘é€å…¶ä»–é€šçŸ¥
	switch notification.Priority {
	case "urgent", "high":
		// ç´§æ€¥å’Œé«˜ä¼˜å…ˆçº§é€šçŸ¥å‘é€é‚®ä»¶å’ŒçŸ­ä¿¡
		if err := c.emailSvc.Send(notification); err != nil {
			log.Printf("[Notification] é‚®ä»¶é€šçŸ¥å¤±è´¥: %v", err)
			errors = append(errors, fmt.Errorf("email: %w", err))
		}

		if notification.Type == "external_operation" {
			// å¤–éƒ¨æ“ä½œç‰¹åˆ«é‡è¦ï¼Œå‘é€çŸ­ä¿¡
			if err := c.smsSvc.Send(notification); err != nil {
				log.Printf("[Notification] çŸ­ä¿¡é€šçŸ¥å¤±è´¥: %v", err)
				errors = append(errors, fmt.Errorf("sms: %w", err))
			}
		}

	case "normal":
		// æ™®é€šä¼˜å…ˆçº§åªå‘é€é‚®ä»¶
		if err := c.emailSvc.Send(notification); err != nil {
			log.Printf("[Notification] é‚®ä»¶é€šçŸ¥å¤±è´¥: %v", err)
			errors = append(errors, fmt.Errorf("email: %w", err))
		}

	case "low":
		// ä½ä¼˜å…ˆçº§åªé€šè¿‡WebSocket
		// ä¸å‘é€å…¶ä»–é€šçŸ¥
	}

	if len(errors) > 0 {
		return fmt.Errorf("é€šçŸ¥å‘é€å¤±è´¥: %v", errors)
	}

	log.Printf("[Notification] é€šçŸ¥å‘é€æˆåŠŸ: %s -> %s", notification.Type, notification.Title)
	return nil
}

// Send å‘é€WebSocketé€šçŸ¥
func (w *WebSocketNotificationService) Send(notification *Notification) error {
	// TODO: å®ç°WebSocketé€šçŸ¥é€»è¾‘
	// è¿™é‡Œåº”è¯¥å‘ç”¨æˆ·çš„WebSocketè¿æ¥å‘é€å®æ—¶é€šçŸ¥
	log.Printf("[WebSocket] å‘é€é€šçŸ¥åˆ°ç”¨æˆ· %d: %s", notification.UserID, notification.Title)
	return nil
}

// Send å‘é€é‚®ä»¶é€šçŸ¥
func (e *EmailNotificationService) Send(notification *Notification) error {
	if e.smtpServer == "" {
		log.Printf("[Email] SMTPæœªé…ç½®ï¼Œè·³è¿‡é‚®ä»¶é€šçŸ¥")
		return nil
	}

	// TODO: å®ç°é‚®ä»¶å‘é€é€»è¾‘
	log.Printf("[Email] å‘é€é‚®ä»¶åˆ°ç”¨æˆ· %d: %s", notification.UserID, notification.Title)
	return nil
}

// Send å‘é€çŸ­ä¿¡é€šçŸ¥
func (s *SMSNotificationService) Send(notification *Notification) error {
	if s.apiKey == "" {
		log.Printf("[SMS] SMSæœªé…ç½®ï¼Œè·³è¿‡çŸ­ä¿¡é€šçŸ¥")
		return nil
	}

	// TODO: å®ç°çŸ­ä¿¡å‘é€é€»è¾‘
	log.Printf("[SMS] å‘é€çŸ­ä¿¡åˆ°ç”¨æˆ· %d: %s", notification.UserID, notification.Title)
	return nil
}

// notifyUserExternalOperation é€šçŸ¥ç”¨æˆ·å¤–éƒ¨æ“ä½œ
func (s *Server) notifyUserExternalOperation(externalOp *pdb.ExternalOperation) {
	log.Printf("[Notification] æ£€æµ‹åˆ°å¤–éƒ¨æ“ä½œ: %s %s (ç½®ä¿¡åº¦: %.2f)",
		externalOp.Symbol, externalOp.OperationType, externalOp.Confidence)

	// åˆ›å»ºé€šçŸ¥
	notification := &Notification{
		UserID: externalOp.UserID,
		Type:   "external_operation",
		Data: map[string]interface{}{
			"external_operation_id": externalOp.ID,
			"symbol":                externalOp.Symbol,
			"operation_type":        externalOp.OperationType,
			"old_amount":            externalOp.OldAmount,
			"new_amount":            externalOp.NewAmount,
			"confidence":            externalOp.Confidence,
		},
		CreatedAt: time.Now(),
	}

	// æ ¹æ®æ“ä½œç±»å‹è®¾ç½®é€šçŸ¥å†…å®¹å’Œä¼˜å…ˆçº§
	switch externalOp.OperationType {
	case "external_full_close":
		notification.Title = "æ£€æµ‹åˆ°å¤–éƒ¨å¹³ä»“æ“ä½œ"
		notification.Message = fmt.Sprintf("ç³»ç»Ÿæ£€æµ‹åˆ°æ‚¨åœ¨å¸å®‰å®˜ç½‘å¯¹ %s è¿›è¡Œäº†å¹³ä»“æ“ä½œã€‚åŸæŒä»“: %s, å½“å‰æŒä»“: %s",
			externalOp.Symbol, externalOp.OldAmount, externalOp.NewAmount)
		notification.Priority = "high"

	case "external_partial_close":
		notification.Title = "æ£€æµ‹åˆ°å¤–éƒ¨éƒ¨åˆ†å¹³ä»“æ“ä½œ"
		notification.Message = fmt.Sprintf("ç³»ç»Ÿæ£€æµ‹åˆ°æ‚¨åœ¨å¸å®‰å®˜ç½‘å¯¹ %s è¿›è¡Œäº†éƒ¨åˆ†å¹³ä»“æ“ä½œã€‚æŒä»“ä» %s å‡å°‘åˆ° %s",
			externalOp.Symbol, externalOp.OldAmount, externalOp.NewAmount)
		notification.Priority = "normal"

	case "external_add_position":
		notification.Title = "æ£€æµ‹åˆ°å¤–éƒ¨åŠ ä»“æ“ä½œ"
		notification.Message = fmt.Sprintf("ç³»ç»Ÿæ£€æµ‹åˆ°æ‚¨åœ¨å¸å®‰å®˜ç½‘å¯¹ %s è¿›è¡Œäº†åŠ ä»“æ“ä½œã€‚æŒä»“ä» %s å¢åŠ åˆ° %s",
			externalOp.Symbol, externalOp.OldAmount, externalOp.NewAmount)
		notification.Priority = "normal"

	case "external_open":
		notification.Title = "æ£€æµ‹åˆ°å¤–éƒ¨å¼€ä»“æ“ä½œ"
		notification.Message = fmt.Sprintf("ç³»ç»Ÿæ£€æµ‹åˆ°æ‚¨åœ¨å¸å®‰å®˜ç½‘å¯¹ %s è¿›è¡Œäº†å¼€ä»“æ“ä½œã€‚å½“å‰æŒä»“: %s",
			externalOp.Symbol, externalOp.NewAmount)
		notification.Priority = "high"

	case "external_cancel":
		notification.Title = "æ£€æµ‹åˆ°å¤–éƒ¨å–æ¶ˆè®¢å•æ“ä½œ"
		notification.Message = fmt.Sprintf("ç³»ç»Ÿæ£€æµ‹åˆ°æ‚¨åœ¨å¸å®‰å®˜ç½‘å–æ¶ˆäº† %s çš„è®¢å•", externalOp.Symbol)
		notification.Priority = "normal"

	case "external_modify_increase":
		notification.Title = "æ£€æµ‹åˆ°å¤–éƒ¨å¢åŠ è®¢å•æ•°é‡æ“ä½œ"
		notification.Message = fmt.Sprintf("ç³»ç»Ÿæ£€æµ‹åˆ°æ‚¨åœ¨å¸å®‰å®˜ç½‘å¢åŠ äº† %s è®¢å•çš„æ•°é‡", externalOp.Symbol)
		notification.Priority = "low"

	case "external_modify_decrease":
		notification.Title = "æ£€æµ‹åˆ°å¤–éƒ¨å‡å°‘è®¢å•æ•°é‡æ“ä½œ"
		notification.Message = fmt.Sprintf("ç³»ç»Ÿæ£€æµ‹åˆ°æ‚¨åœ¨å¸å®‰å®˜ç½‘å‡å°‘äº† %s è®¢å•çš„æ•°é‡", externalOp.Symbol)
		notification.Priority = "low"

	case "external_order_deleted":
		notification.Title = "æ£€æµ‹åˆ°å¤–éƒ¨åˆ é™¤è®¢å•æ“ä½œ"
		notification.Message = fmt.Sprintf("ç³»ç»Ÿæ£€æµ‹åˆ°æ‚¨åœ¨å¸å®‰å®˜ç½‘åˆ é™¤äº† %s çš„è®¢å•ï¼Œè¯¥è®¢å•å¯èƒ½å·²è¢«æ‰§è¡Œæˆ–å–æ¶ˆ", externalOp.Symbol)
		notification.Priority = "urgent"

	default:
		notification.Title = "æ£€æµ‹åˆ°å¤–éƒ¨æ“ä½œ"
		notification.Message = fmt.Sprintf("ç³»ç»Ÿæ£€æµ‹åˆ°æ‚¨åœ¨å¸å®‰å®˜ç½‘å¯¹ %s è¿›è¡Œäº†æ“ä½œ: %s",
			externalOp.Symbol, externalOp.OperationType)
		notification.Priority = "normal"
	}

	// å‘é€é€šçŸ¥
	if s.notificationService != nil {
		if err := s.notificationService.Send(notification); err != nil {
			log.Printf("[Notification] å‘é€é€šçŸ¥å¤±è´¥: %v", err)
		}
	} else {
		log.Printf("[Notification] é€šçŸ¥æœåŠ¡æœªåˆå§‹åŒ–ï¼Œä½¿ç”¨é»˜è®¤æ—¥å¿—é€šçŸ¥: %s", notification.Message)
	}

	// åŒæ—¶ä¿å­˜åˆ°æ•°æ®åº“çš„ç³»ç»Ÿæ¶ˆæ¯è¡¨ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
	s.saveNotificationToDatabase(notification)
}

// saveNotificationToDatabase ä¿å­˜é€šçŸ¥åˆ°æ•°æ®åº“
func (s *Server) saveNotificationToDatabase(notification *Notification) {
	// TODO: å®ç°ä¿å­˜åˆ°ç”¨æˆ·é€šçŸ¥è¡¨çš„é€»è¾‘
	// è¿™é‡Œå¯ä»¥åˆ›å»ºä¸€ä¸ª user_notifications è¡¨æ¥å­˜å‚¨ç”¨æˆ·çš„é€šçŸ¥å†å²

	log.Printf("[Notification] ä¿å­˜é€šçŸ¥åˆ°æ•°æ®åº“: ç”¨æˆ·%d, ç±»å‹%s, ä¼˜å…ˆçº§%s",
		notification.UserID, notification.Type, notification.Priority)
}

// initNotificationService åˆå§‹åŒ–é€šçŸ¥æœåŠ¡
func (s *Server) initNotificationService(cfg *config.Config) {
	if !cfg.Notification.Enabled {
		log.Printf("[INIT] é€šçŸ¥æœåŠ¡å·²ç¦ç”¨ï¼ˆé…ç½®ä¸­ notification.enabled = falseï¼‰")
		s.notificationService = nil
		return
	}

	log.Printf("[INIT] åˆå§‹åŒ–é€šçŸ¥æœåŠ¡...")
	s.notificationService = NewCompositeNotificationService(cfg)
	log.Printf("[INIT] é€šçŸ¥æœåŠ¡åˆå§‹åŒ–å®Œæˆ")
}

// initAuditLogger åˆå§‹åŒ–å®¡è®¡æ—¥å¿—è®°å½•å™¨
func (s *Server) initAuditLogger() {
	log.Printf("[INIT] åˆå§‹åŒ–å®¡è®¡æ—¥å¿—è®°å½•å™¨...")

	s.auditLogger = NewAuditLogger(s.db.DB())
	log.Printf("[INIT] å®¡è®¡æ—¥å¿—è®°å½•å™¨åˆå§‹åŒ–å®Œæˆ")
}

// initHealthChecker åˆå§‹åŒ–ç³»ç»Ÿå¥åº·æ£€æŸ¥å™¨
func (s *Server) initHealthChecker() {
	log.Printf("[INIT] åˆå§‹åŒ–ç³»ç»Ÿå¥åº·æ£€æŸ¥å™¨...")

	s.healthChecker = NewSystemHealthChecker(s.db.DB())

	// å¯åŠ¨å®šæœŸå¥åº·æ£€æŸ¥
	go func() {
		ticker := time.NewTicker(5 * time.Minute) // æ¯5åˆ†é’Ÿè¿›è¡Œä¸€æ¬¡å¥åº·æ£€æŸ¥
		defer ticker.Stop()

		// é¦–æ¬¡å¯åŠ¨æ—¶ç­‰å¾…1åˆ†é’Ÿå†æ‰§è¡Œ
		time.Sleep(1 * time.Minute)

		for {
			select {
			case <-ticker.C:
				if err := s.performHealthCheck(); err != nil {
					log.Printf("[Health-Check] å®šæœŸå¥åº·æ£€æŸ¥å¤±è´¥: %v", err)
				}
			}
		}
	}()

	log.Printf("[INIT] ç³»ç»Ÿå¥åº·æ£€æŸ¥å™¨åˆå§‹åŒ–å®Œæˆï¼ˆæ¯5åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡ï¼‰")
}

// smartNotifyOrderUpdate æ™ºèƒ½é€šçŸ¥è®¢å•çŠ¶æ€æ›´æ–°
func (s *Server) smartNotifyOrderUpdate(order *pdb.ScheduledOrder, oldStatus, newStatus string) {
	// åªå¯¹é‡è¦çš„çŠ¶æ€å˜åŒ–å‘é€é€šçŸ¥
	importantChanges := map[string][]string{
		"pending":    {"processing", "filled", "failed", "cancelled"},
		"processing": {"filled", "failed", "cancelled"},
		"sent":       {"filled", "failed", "cancelled"},
	}

	shouldNotify := false
	if allowedChanges, exists := importantChanges[oldStatus]; exists {
		for _, change := range allowedChanges {
			if change == newStatus {
				shouldNotify = true
				break
			}
		}
	}

	if !shouldNotify {
		return
	}

	notification := &Notification{
		UserID: order.UserID,
		Type:   "order_update",
		Title:  "è®¢å•çŠ¶æ€æ›´æ–°",
		Message: fmt.Sprintf("æ‚¨çš„è®¢å• #%d (%s) çŠ¶æ€ä» %s å˜ä¸º %s",
			order.ID, order.Symbol, s.translateStatus(oldStatus), s.translateStatus(newStatus)),
		Data: map[string]interface{}{
			"order_id":     order.ID,
			"symbol":       order.Symbol,
			"old_status":   oldStatus,
			"new_status":   newStatus,
			"executed_qty": order.ExecutedQty,
			"avg_price":    order.AvgPrice,
		},
		Priority:  s.calculateOrderNotificationPriority(oldStatus, newStatus),
		CreatedAt: time.Now(),
	}

	if s.notificationService != nil {
		s.notificationService.Send(notification)
	}
}

// calculateOrderNotificationPriority è®¡ç®—è®¢å•é€šçŸ¥ä¼˜å…ˆçº§
func (s *Server) calculateOrderNotificationPriority(oldStatus, newStatus string) string {
	if newStatus == "filled" {
		return "normal" // æˆäº¤é€šçŸ¥
	} else if newStatus == "failed" {
		return "high" // å¤±è´¥é€šçŸ¥æ¯”è¾ƒé‡è¦
	} else if newStatus == "cancelled" {
		return "low" // å–æ¶ˆé€šçŸ¥ä¼˜å…ˆçº§è¾ƒä½
	}
	return "normal"
}

// translateStatus ç¿»è¯‘çŠ¶æ€ä¸ºä¸­æ–‡
func (s *Server) translateStatus(status string) string {
	statusMap := map[string]string{
		"pending":    "ç­‰å¾…æ‰§è¡Œ",
		"processing": "æ‰§è¡Œä¸­",
		"sent":       "å·²å‘é€",
		"filled":     "å·²æˆäº¤",
		"completed":  "å·²å®Œæˆ",
		"cancelled":  "å·²å–æ¶ˆ",
		"failed":     "å¤±è´¥",
	}

	if translated, exists := statusMap[status]; exists {
		return translated
	}
	return status
}

// updatePositionSnapshots æ›´æ–°æŒä»“å¿«ç…§
func (s *Server) updatePositionSnapshots(currentPositions map[uint]map[string]*PositionSnapshot) {
	s.positionMutex.Lock()
	defer s.positionMutex.Unlock()

	// æ¸…ç©ºæ—§çš„å¿«ç…§
	s.positionSnapshots = make(map[string]*PositionSnapshot)

	// æ·»åŠ æ–°çš„å¿«ç…§
	for userID, userPositions := range currentPositions {
		for symbol, snapshot := range userPositions {
			key := fmt.Sprintf("%d_%s", userID, symbol)
			s.positionSnapshots[key] = snapshot
		}
	}

	log.Printf("[Position-Detect] æŒä»“å¿«ç…§å·²æ›´æ–°ï¼Œå…± %d ä¸ªæŒä»“", len(s.positionSnapshots))
}

// SystemHealthChecker ç³»ç»Ÿå¥åº·æ£€æŸ¥å™¨
type SystemHealthChecker struct {
	db              *gorm.DB
	lastHealthCheck time.Time
	healthMetrics   map[string]interface{}
	alertCooldowns  map[string]time.Time
	mu              sync.RWMutex
}

// NewSystemHealthChecker åˆ›å»ºç³»ç»Ÿå¥åº·æ£€æŸ¥å™¨
func NewSystemHealthChecker(db *gorm.DB) *SystemHealthChecker {
	return &SystemHealthChecker{
		db:             db,
		healthMetrics:  make(map[string]interface{}),
		alertCooldowns: make(map[string]time.Time),
	}
}

// performHealthCheck æ‰§è¡Œç³»ç»Ÿå¥åº·æ£€æŸ¥
func (s *Server) performHealthCheck() error {
	if s.healthChecker == nil {
		return nil
	}

	log.Printf("[Health-Check] å¼€å§‹æ‰§è¡Œç³»ç»Ÿå¥åº·æ£€æŸ¥...")

	// 1. æ•°æ®åº“è¿æ¥æ£€æŸ¥
	if err := s.checkDatabaseHealth(); err != nil {
		s.handleHealthAlert("database_connection", "æ•°æ®åº“è¿æ¥å¼‚å¸¸", err)
		return err
	}

	// 2. è®¢å•åŒæ­¥çŠ¶æ€æ£€æŸ¥
	if err := s.checkOrderSyncHealth(); err != nil {
		s.handleHealthAlert("order_sync", "è®¢å•åŒæ­¥å¼‚å¸¸", err)
	}

	// 3. æŒä»“æ£€æµ‹çŠ¶æ€æ£€æŸ¥
	if err := s.checkPositionDetectionHealth(); err != nil {
		s.handleHealthAlert("position_detection", "æŒä»“æ£€æµ‹å¼‚å¸¸", err)
	}

	// 4. é€šçŸ¥æœåŠ¡çŠ¶æ€æ£€æŸ¥
	if err := s.checkNotificationHealth(); err != nil {
		s.handleHealthAlert("notification_service", "é€šçŸ¥æœåŠ¡å¼‚å¸¸", err)
	}

	// 5. å†…å­˜å’Œæ€§èƒ½æ£€æŸ¥
	if err := s.checkSystemPerformance(); err != nil {
		s.handleHealthAlert("system_performance", "ç³»ç»Ÿæ€§èƒ½å¼‚å¸¸", err)
	}

	s.healthChecker.mu.Lock()
	s.healthChecker.lastHealthCheck = time.Now()
	s.healthChecker.mu.Unlock()

	log.Printf("[Health-Check] ç³»ç»Ÿå¥åº·æ£€æŸ¥å®Œæˆ")
	return nil
}

// checkDatabaseHealth æ£€æŸ¥æ•°æ®åº“å¥åº·çŠ¶æ€
func (s *Server) checkDatabaseHealth() error {
	// æ£€æŸ¥æ•°æ®åº“è¿æ¥
	if err := s.db.DB().Exec("SELECT 1").Error; err != nil {
		return fmt.Errorf("æ•°æ®åº“è¿æ¥å¤±è´¥: %w", err)
	}

	// æ£€æŸ¥å…³é”®è¡¨çš„è®°å½•æ•°
	var orderCount, externalOpCount int64
	s.db.DB().Model(&pdb.ScheduledOrder{}).Count(&orderCount)
	s.db.DB().Model(&pdb.ExternalOperation{}).Count(&externalOpCount)

	// æ›´æ–°å¥åº·æŒ‡æ ‡
	s.healthChecker.mu.Lock()
	s.healthChecker.healthMetrics["order_count"] = orderCount
	s.healthChecker.healthMetrics["external_operation_count"] = externalOpCount
	s.healthChecker.healthMetrics["database_status"] = "healthy"
	s.healthChecker.mu.Unlock()

	log.Printf("[Health-Check] æ•°æ®åº“å¥åº·æ£€æŸ¥é€šè¿‡ - è®¢å•æ•°: %d, å¤–éƒ¨æ“ä½œæ•°: %d", orderCount, externalOpCount)
	return nil
}

// checkOrderSyncHealth æ£€æŸ¥è®¢å•åŒæ­¥å¥åº·çŠ¶æ€
func (s *Server) checkOrderSyncHealth() error {
	// æ£€æŸ¥æœ€è¿‘çš„è®¢å•åŒæ­¥æ´»åŠ¨
	var recentSyncs int64
	oneHourAgo := time.Now().Add(-time.Hour)
	s.db.DB().Model(&pdb.OperationLog{}).
		Where("entity_type = ? AND action = ? AND created_at > ?",
			"order", "status_update", oneHourAgo).
		Count(&recentSyncs)

	if recentSyncs == 0 {
		return fmt.Errorf("è¿‡å»1å°æ—¶å†…æ²¡æœ‰è®¢å•åŒæ­¥æ´»åŠ¨")
	}

	s.healthChecker.mu.Lock()
	s.healthChecker.healthMetrics["recent_order_syncs"] = recentSyncs
	s.healthChecker.healthMetrics["order_sync_status"] = "active"
	s.healthChecker.mu.Unlock()

	log.Printf("[Health-Check] è®¢å•åŒæ­¥å¥åº·æ£€æŸ¥é€šè¿‡ - æœ€è¿‘åŒæ­¥æ•°: %d", recentSyncs)
	return nil
}

// checkPositionDetectionHealth æ£€æŸ¥æŒä»“æ£€æµ‹å¥åº·çŠ¶æ€
func (s *Server) checkPositionDetectionHealth() error {
	// æ£€æŸ¥æœ€è¿‘çš„æŒä»“æ£€æµ‹æ´»åŠ¨
	var recentDetections int64
	oneHourAgo := time.Now().Add(-time.Hour)
	s.db.DB().Model(&pdb.OperationLog{}).
		Where("entity_type = ? AND action = ? AND created_at > ?",
			"position", "position_change_detected", oneHourAgo).
		Count(&recentDetections)

	// æ£€æŸ¥æŒä»“å¿«ç…§æ˜¯å¦æ­£å¸¸æ›´æ–°
	s.positionMutex.RLock()
	lastCheck := s.lastPositionCheck
	s.positionMutex.RUnlock()

	timeSinceLastCheck := time.Since(lastCheck)
	if timeSinceLastCheck > 20*time.Minute {
		return fmt.Errorf("æŒä»“æ£€æµ‹å·²åœæ­¢ %v", timeSinceLastCheck)
	}

	s.healthChecker.mu.Lock()
	s.healthChecker.healthMetrics["recent_position_detections"] = recentDetections
	s.healthChecker.healthMetrics["position_detection_status"] = "active"
	s.healthChecker.healthMetrics["last_position_check"] = lastCheck
	s.healthChecker.mu.Unlock()

	log.Printf("[Health-Check] æŒä»“æ£€æµ‹å¥åº·æ£€æŸ¥é€šè¿‡ - æœ€è¿‘æ£€æµ‹æ•°: %d", recentDetections)
	return nil
}

// checkNotificationHealth æ£€æŸ¥é€šçŸ¥æœåŠ¡å¥åº·çŠ¶æ€
func (s *Server) checkNotificationHealth() error {
	if s.notificationService == nil {
		return fmt.Errorf("é€šçŸ¥æœåŠ¡æœªåˆå§‹åŒ–")
	}

	// æ£€æŸ¥æœ€è¿‘çš„é€šçŸ¥å‘é€æƒ…å†µ
	var recentNotifications int64
	oneHourAgo := time.Now().Add(-time.Hour)
	s.db.DB().Model(&pdb.OperationLog{}).
		Where("action = ? AND created_at > ?", "notification_sent", oneHourAgo).
		Count(&recentNotifications)

	s.healthChecker.mu.Lock()
	s.healthChecker.healthMetrics["notification_service_status"] = "healthy"
	s.healthChecker.healthMetrics["recent_notifications"] = recentNotifications
	s.healthChecker.mu.Unlock()

	log.Printf("[Health-Check] é€šçŸ¥æœåŠ¡å¥åº·æ£€æŸ¥é€šè¿‡")
	return nil
}

// checkSystemPerformance æ£€æŸ¥ç³»ç»Ÿæ€§èƒ½
func (s *Server) checkSystemPerformance() error {
	// æ£€æŸ¥å†…å­˜ä½¿ç”¨æƒ…å†µï¼ˆè¿™é‡Œæ˜¯ç®€åŒ–çš„æ£€æŸ¥ï¼‰
	var memStats runtime.MemStats
	runtime.ReadMemStats(&memStats)

	memUsageMB := memStats.Alloc / 1024 / 1024
	if memUsageMB > 1000 { // è¶…è¿‡1GB
		return fmt.Errorf("å†…å­˜ä½¿ç”¨è¿‡é«˜: %d MB", memUsageMB)
	}

	// æ£€æŸ¥goroutineæ•°é‡
	goroutineCount := runtime.NumGoroutine()
	if goroutineCount > 1000 {
		return fmt.Errorf("goroutineæ•°é‡å¼‚å¸¸: %d", goroutineCount)
	}

	s.healthChecker.mu.Lock()
	s.healthChecker.healthMetrics["memory_usage_mb"] = memUsageMB
	s.healthChecker.healthMetrics["goroutine_count"] = goroutineCount
	s.healthChecker.healthMetrics["performance_status"] = "good"
	s.healthChecker.mu.Unlock()

	log.Printf("[Health-Check] ç³»ç»Ÿæ€§èƒ½æ£€æŸ¥é€šè¿‡ - å†…å­˜: %d MB, Goroutines: %d", memUsageMB, goroutineCount)
	return nil
}

// handleHealthAlert å¤„ç†å¥åº·å‘Šè­¦
func (s *Server) handleHealthAlert(alertType, message string, err error) {
	// æ£€æŸ¥å‘Šè­¦å†·å´æ—¶é—´ï¼Œé¿å…é¢‘ç¹å‘Šè­¦
	s.healthChecker.mu.RLock()
	lastAlert, exists := s.healthChecker.alertCooldowns[alertType]
	s.healthChecker.mu.RUnlock()

	now := time.Now()
	if exists && now.Sub(lastAlert) < 30*time.Minute {
		// å†·å´æ—¶é—´å†…ï¼Œè·³è¿‡å‘Šè­¦
		return
	}

	// è®°å½•å‘Šè­¦
	log.Printf("[Health-Alert] %s: %s - %v", alertType, message, err)

	// æ›´æ–°å†·å´æ—¶é—´
	s.healthChecker.mu.Lock()
	s.healthChecker.alertCooldowns[alertType] = now
	s.healthChecker.mu.Unlock()

	// è®°å½•åˆ°å®¡è®¡æ—¥å¿—
	s.logSystemOperation("health_alert",
		fmt.Sprintf("ç³»ç»Ÿå¥åº·å‘Šè­¦: %s - %s", alertType, message),
		"error",
		map[string]interface{}{
			"alert_type": alertType,
			"message":    message,
			"error":      err.Error(),
		},
		err.Error())

	// å‘é€ç´§æ€¥é€šçŸ¥ï¼ˆå¦‚æœæ˜¯ä¸¥é‡é”™è¯¯ï¼‰
	if alertType == "database_connection" || strings.Contains(message, "åœæ­¢") {
		s.sendUrgentHealthAlert(alertType, message, err)
	}

	// å°è¯•è‡ªåŠ¨æ¢å¤
	if err := s.attemptAutoRecovery(alertType); err != nil {
		log.Printf("[Health-Recovery] è‡ªåŠ¨æ¢å¤å¤±è´¥ %s: %v", alertType, err)
	}
}

// sendUrgentHealthAlert å‘é€ç´§æ€¥å¥åº·å‘Šè­¦
func (s *Server) sendUrgentHealthAlert(alertType, message string, err error) {
	if s.notificationService == nil {
		return
	}

	alert := &Notification{
		UserID:  0, // ç³»ç»Ÿå‘Šè­¦
		Type:    "system_health_alert",
		Title:   "ç³»ç»Ÿå¥åº·å‘Šè­¦",
		Message: fmt.Sprintf("ç´§æ€¥å‘Šè­¦: %s - %s", alertType, message),
		Data: map[string]interface{}{
			"alert_type": alertType,
			"message":    message,
			"error":      err.Error(),
			"timestamp":  time.Now(),
		},
		Priority:  "urgent",
		CreatedAt: time.Now(),
	}

	if s.notificationService != nil {
		s.notificationService.Broadcast(alert)
	}
}

// attemptAutoRecovery å°è¯•è‡ªåŠ¨æ¢å¤
func (s *Server) attemptAutoRecovery(alertType string) error {
	switch alertType {
	case "database_connection":
		// å°è¯•é‡æ–°è¿æ¥æ•°æ®åº“
		log.Printf("[Health-Recovery] å°è¯•é‡æ–°è¿æ¥æ•°æ®åº“...")
		if err := s.db.DB().Exec("SELECT 1").Error; err == nil {
			log.Printf("[Health-Recovery] æ•°æ®åº“é‡è¿æˆåŠŸ")
			return nil
		}

	case "position_detection":
		// é‡å¯æŒä»“æ£€æµ‹
		log.Printf("[Health-Recovery] å°è¯•é‡å¯æŒä»“æ£€æµ‹...")
		// è¿™é‡Œå¯ä»¥é‡æ–°åˆå§‹åŒ–æŒä»“æ£€æµ‹æœºåˆ¶

	case "order_sync":
		// é‡å¯è®¢å•åŒæ­¥
		log.Printf("[Health-Recovery] å°è¯•é‡å¯è®¢å•åŒæ­¥...")
		// è¿™é‡Œå¯ä»¥é‡æ–°åˆå§‹åŒ–è®¢å•åŒæ­¥

	default:
		return fmt.Errorf("ä¸æ”¯æŒçš„å‘Šè­¦ç±»å‹è‡ªåŠ¨æ¢å¤: %s", alertType)
	}

	return fmt.Errorf("è‡ªåŠ¨æ¢å¤å¤±è´¥")
}

// getHealthStatus è·å–ç³»ç»Ÿå¥åº·çŠ¶æ€
func (s *Server) getHealthStatus() map[string]interface{} {
	s.healthChecker.mu.RLock()
	defer s.healthChecker.mu.RUnlock()

	status := map[string]interface{}{
		"overall_status": "healthy",
		"last_check":     s.healthChecker.lastHealthCheck,
		"metrics":        make(map[string]interface{}),
		"alerts":         make(map[string]interface{}),
	}

	// å¤åˆ¶æŒ‡æ ‡
	for k, v := range s.healthChecker.healthMetrics {
		status["metrics"].(map[string]interface{})[k] = v
	}

	// æ£€æŸ¥æ˜¯å¦æœ‰æ´»è·ƒå‘Šè­¦
	hasActiveAlerts := false
	for alertType, lastAlert := range s.healthChecker.alertCooldowns {
		if time.Since(lastAlert) < time.Hour {
			hasActiveAlerts = true
			status["alerts"].(map[string]interface{})[alertType] = map[string]interface{}{
				"last_alert": lastAlert,
				"active":     true,
			}
		}
	}

	if hasActiveAlerts {
		status["overall_status"] = "warning"
	}

	return status
}

// AuditLogger å®¡è®¡æ—¥å¿—è®°å½•å™¨
type AuditLogger struct {
	db *gorm.DB
}

// NewAuditLogger åˆ›å»ºå®¡è®¡æ—¥å¿—è®°å½•å™¨
func NewAuditLogger(db *gorm.DB) *AuditLogger {
	return &AuditLogger{db: db}
}

// LogOperation è®°å½•æ“ä½œæ—¥å¿—
func (a *AuditLogger) LogOperation(logEntry *pdb.OperationLog) error {
	return a.db.Create(logEntry).Error
}

// LogAuditTrail è®°å½•å®¡è®¡è¿½è¸ª
func (a *AuditLogger) LogAuditTrail(trail *pdb.AuditTrail) error {
	return a.db.Create(trail).Error
}

// logOrderOperation è®°å½•è®¢å•æ“ä½œ
func (s *Server) logOrderOperation(order *pdb.ScheduledOrder, action, description string, oldValue, newValue interface{}, source, level string, errorMsg string) {
	if s.auditLogger == nil {
		return
	}

	// åºåˆ—åŒ–æ—§å€¼å’Œæ–°å€¼
	oldValueStr := ""
	newValueStr := ""

	if oldValue != nil {
		if oldBytes, err := json.Marshal(oldValue); err == nil {
			oldValueStr = string(oldBytes)
		}
	}

	if newValue != nil {
		if newBytes, err := json.Marshal(newValue); err == nil {
			newValueStr = string(newBytes)
		}
	}

	logEntry := &pdb.OperationLog{
		UserID:      order.UserID,
		EntityType:  "order",
		EntityID:    order.ID,
		Action:      action,
		Description: description,
		OldValue:    oldValueStr,
		NewValue:    newValueStr,
		Source:      source,
		Level:       level,
		ErrorMsg:    errorMsg,
		ProcessedAt: &time.Time{}, // ç«‹å³è®¾ç½®ä¸ºå¤„ç†å®Œæˆ
	}
	logEntry.ProcessedAt = &logEntry.CreatedAt

	if err := s.auditLogger.LogOperation(logEntry); err != nil {
		log.Printf("[Audit] è®°å½•è®¢å•æ“ä½œæ—¥å¿—å¤±è´¥: %v", err)
	}
}

// logPositionOperation è®°å½•æŒä»“æ“ä½œ
func (s *Server) logPositionOperation(userID uint, symbol, action, description string, oldPosition, newPosition *PositionSnapshot, source, level string) {
	if s.auditLogger == nil {
		return
	}

	logEntry := &pdb.OperationLog{
		UserID:      userID,
		EntityType:  "position",
		Action:      action,
		Description: description,
		Source:      source,
		Level:       level,
	}

	// è®°å½•æŒä»“å˜åŒ–
	if oldPosition != nil {
		if oldBytes, err := json.Marshal(oldPosition); err == nil {
			logEntry.OldValue = string(oldBytes)
		}
	}

	if newPosition != nil {
		if newBytes, err := json.Marshal(newPosition); err == nil {
			logEntry.NewValue = string(newBytes)
		}
		logEntry.EntityID = 0 // æŒä»“æ²¡æœ‰å›ºå®šIDï¼Œç”¨symbolä½œä¸ºæ ‡è¯†
	}

	// æ·»åŠ å…ƒæ•°æ®
	metadata := map[string]interface{}{
		"symbol": symbol,
	}
	if metadataBytes, err := json.Marshal(metadata); err == nil {
		logEntry.Metadata = string(metadataBytes)
	}

	logEntry.ProcessedAt = &time.Time{}
	logEntry.ProcessedAt = &logEntry.CreatedAt

	if err := s.auditLogger.LogOperation(logEntry); err != nil {
		log.Printf("[Audit] è®°å½•æŒä»“æ“ä½œæ—¥å¿—å¤±è´¥: %v", err)
	}
}

// logSystemOperation è®°å½•ç³»ç»Ÿæ“ä½œ
func (s *Server) logSystemOperation(action, description, level string, metadata interface{}, errorMsg string) {
	if s.auditLogger == nil {
		return
	}

	logEntry := &pdb.OperationLog{
		UserID:      0, // ç³»ç»Ÿæ“ä½œ
		EntityType:  "system",
		EntityID:    0,
		Action:      action,
		Description: description,
		Source:      "system",
		Level:       level,
		ErrorMsg:    errorMsg,
	}

	if metadata != nil {
		if metadataBytes, err := json.Marshal(metadata); err == nil {
			logEntry.Metadata = string(metadataBytes)
		}
	}

	logEntry.ProcessedAt = &time.Time{}
	logEntry.ProcessedAt = &logEntry.CreatedAt

	if err := s.auditLogger.LogOperation(logEntry); err != nil {
		log.Printf("[Audit] è®°å½•ç³»ç»Ÿæ“ä½œæ—¥å¿—å¤±è´¥: %v", err)
	}
}

// logAuditTrail è®°å½•å®¡è®¡è¿½è¸ª
func (s *Server) logAuditTrail(sessionID string, userID uint, action, resourceType, resourceID, details string, oldState, newState interface{}, success bool, errorDetails string) {
	if s.auditLogger == nil {
		return
	}

	trail := &pdb.AuditTrail{
		SessionID:    sessionID,
		UserID:       userID,
		Action:       action,
		ResourceType: resourceType,
		ResourceID:   resourceID,
		Details:      details,
		Success:      success,
		ErrorDetails: errorDetails,
		Timestamp:    time.Now(),
	}

	if oldState != nil {
		if oldBytes, err := json.Marshal(oldState); err == nil {
			trail.OldState = string(oldBytes)
		}
	}

	if newState != nil {
		if newBytes, err := json.Marshal(newState); err == nil {
			trail.NewState = string(newBytes)
		}
	}

	if err := s.auditLogger.LogAuditTrail(trail); err != nil {
		log.Printf("[Audit] è®°å½•å®¡è®¡è¿½è¸ªå¤±è´¥: %v", err)
	}
}

// maintainDatabaseRelationships ç»´æŠ¤æ•°æ®åº“å…³è”å…³ç³»çš„ä¸€è‡´æ€§
func (s *Server) maintainDatabaseRelationships() error {
	log.Printf("[DB-Maintenance] å¼€å§‹æ•°æ®åº“å…³è”å…³ç³»ç»´æŠ¤...")

	// 1. æ¸…ç†å¤±æ•ˆçš„è®¢å•å¼•ç”¨
	if err := s.cleanupInvalidOrderReferences(); err != nil {
		log.Printf("[DB-Maintenance] æ¸…ç†å¤±æ•ˆè®¢å•å¼•ç”¨å¤±è´¥: %v", err)
	}

	// 2. ä¿®å¤ä¸å®Œæ•´çš„å…³è”å…³ç³»
	if err := s.repairIncompleteRelationships(); err != nil {
		log.Printf("[DB-Maintenance] ä¿®å¤ä¸å®Œæ•´å…³è”å…³ç³»å¤±è´¥: %v", err)
	}

	// 3. éªŒè¯å…³è”å…³ç³»çš„ä¸€è‡´æ€§
	if err := s.validateRelationshipConsistency(); err != nil {
		log.Printf("[DB-Maintenance] éªŒè¯å…³è”å…³ç³»ä¸€è‡´æ€§å¤±è´¥: %v", err)
	}

	// 4. æ¸…ç†å­¤ç«‹çš„å¤–éƒ¨æ“ä½œè®°å½•
	if err := s.cleanupOrphanedExternalOperations(); err != nil {
		log.Printf("[DB-Maintenance] æ¸…ç†å­¤ç«‹å¤–éƒ¨æ“ä½œè®°å½•å¤±è´¥: %v", err)
	}

	log.Printf("[DB-Maintenance] æ•°æ®åº“å…³è”å…³ç³»ç»´æŠ¤å®Œæˆ")
	return nil
}

// cleanupInvalidOrderReferences æ¸…ç†å¤±æ•ˆçš„è®¢å•å¼•ç”¨
func (s *Server) cleanupInvalidOrderReferences() error {
	log.Printf("[DB-Maintenance] æ¸…ç†å¤±æ•ˆçš„è®¢å•å¼•ç”¨...")

	// æŸ¥æ‰¾æ‰€æœ‰æœ‰parent_order_idçš„è®¢å•
	var childOrders []pdb.ScheduledOrder
	err := s.db.DB().Where("parent_order_id > 0").Find(&childOrders).Error
	if err != nil {
		return fmt.Errorf("æŸ¥è¯¢å­è®¢å•å¤±è´¥: %w", err)
	}

	cleanedCount := 0
	for _, childOrder := range childOrders {
		// æ£€æŸ¥çˆ¶è®¢å•æ˜¯å¦å­˜åœ¨
		var parentExists int64
		s.db.DB().Model(&pdb.ScheduledOrder{}).Where("id = ?", childOrder.ParentOrderId).Count(&parentExists)

		if parentExists == 0 {
			// çˆ¶è®¢å•ä¸å­˜åœ¨ï¼Œæ¸…ç†å¼•ç”¨
			err := s.db.DB().Model(&childOrder).Update("parent_order_id", 0).Error
			if err != nil {
				log.Printf("[DB-Maintenance] æ¸…ç†å¤±æ•ˆçˆ¶è®¢å•å¼•ç”¨å¤±è´¥ (è®¢å•%d): %v", childOrder.ID, err)
			} else {
				cleanedCount++
				log.Printf("[DB-Maintenance] æ¸…ç†å¤±æ•ˆçˆ¶è®¢å•å¼•ç”¨: å­è®¢å•%d -> çˆ¶è®¢å•%d (å·²ä¸å­˜åœ¨)",
					childOrder.ID, childOrder.ParentOrderId)
			}
		}
	}

	// æ¸…ç†close_order_idsä¸­çš„å¤±æ•ˆå¼•ç”¨
	var parentOrders []pdb.ScheduledOrder
	err = s.db.DB().Where("close_order_ids != ''").Find(&parentOrders).Error
	if err != nil {
		return fmt.Errorf("æŸ¥è¯¢çˆ¶è®¢å•å¤±è´¥: %w", err)
	}

	for _, parentOrder := range parentOrders {
		closeOrderIds := strings.Split(parentOrder.CloseOrderIds, ",")
		var validCloseOrderIds []string

		for _, idStr := range closeOrderIds {
			if id, parseErr := strconv.ParseUint(strings.TrimSpace(idStr), 10, 32); parseErr == nil {
				// æ£€æŸ¥å­è®¢å•æ˜¯å¦å­˜åœ¨
				var childExists int64
				s.db.DB().Model(&pdb.ScheduledOrder{}).Where("id = ?", uint(id)).Count(&childExists)

				if childExists > 0 {
					validCloseOrderIds = append(validCloseOrderIds, strings.TrimSpace(idStr))
				} else {
					log.Printf("[DB-Maintenance] å‘ç°å¤±æ•ˆçš„close_order_id: çˆ¶è®¢å•%d -> å­è®¢å•%d (å·²ä¸å­˜åœ¨)",
						parentOrder.ID, uint(id))
				}
			}
		}

		// å¦‚æœclose_order_idsæœ‰å˜åŒ–ï¼Œæ›´æ–°æ•°æ®åº“
		newCloseOrderIds := strings.Join(validCloseOrderIds, ",")
		if newCloseOrderIds != parentOrder.CloseOrderIds {
			err := s.db.DB().Model(&parentOrder).Update("close_order_ids", newCloseOrderIds).Error
			if err != nil {
				log.Printf("[DB-Maintenance] æ›´æ–°close_order_idså¤±è´¥ (è®¢å•%d): %v", parentOrder.ID, err)
			} else {
				cleanedCount++
				log.Printf("[DB-Maintenance] ä¿®å¤close_order_ids: è®¢å•%d", parentOrder.ID)
			}
		}
	}

	log.Printf("[DB-Maintenance] æ¸…ç†å¤±æ•ˆè®¢å•å¼•ç”¨å®Œæˆï¼Œå…±æ¸…ç† %d å¤„å¤±æ•ˆå¼•ç”¨", cleanedCount)
	return nil
}

// repairIncompleteRelationships ä¿®å¤ä¸å®Œæ•´çš„å…³è”å…³ç³»
func (s *Server) repairIncompleteRelationships() error {
	log.Printf("[DB-Maintenance] ä¿®å¤ä¸å®Œæ•´çš„å…³è”å…³ç³»...")

	// 1. ä¸ºæ²¡æœ‰parent_order_idçš„å¹³ä»“è®¢å•æŸ¥æ‰¾å¯èƒ½çš„çˆ¶è®¢å•
	var reduceOrders []pdb.ScheduledOrder
	err := s.db.DB().Where("reduce_only = ? AND parent_order_id = ?", true, 0).Find(&reduceOrders).Error
	if err != nil {
		return fmt.Errorf("æŸ¥è¯¢å¹³ä»“è®¢å•å¤±è´¥: %w", err)
	}

	repairedCount := 0
	for _, reduceOrder := range reduceOrders {
		// æŸ¥æ‰¾å¯èƒ½çš„çˆ¶è®¢å•ï¼ˆåŒäº¤æ˜“å¯¹ã€åŒç”¨æˆ·çš„å¼€ä»“è®¢å•ï¼‰
		var possibleParents []pdb.ScheduledOrder
		err := s.db.DB().Where("user_id = ? AND symbol = ? AND reduce_only = ? AND status = ?",
			reduceOrder.UserID, reduceOrder.Symbol, false, "filled").
			Order("trigger_time DESC").Find(&possibleParents).Error

		if err == nil && len(possibleParents) > 0 {
			// é€‰æ‹©æœ€å¯èƒ½çš„çˆ¶è®¢å•ï¼ˆæ—¶é—´æœ€è¿‘çš„ï¼‰
			parentOrder := possibleParents[0]

			// æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰å…³è”
			closeOrderIds := strings.Split(parentOrder.CloseOrderIds, ",")
			alreadyAssociated := false
			for _, idStr := range closeOrderIds {
				if id, parseErr := strconv.ParseUint(strings.TrimSpace(idStr), 10, 32); parseErr == nil && uint(id) == reduceOrder.ID {
					alreadyAssociated = true
					break
				}
			}

			if !alreadyAssociated {
				// å»ºç«‹å…³è”å…³ç³»
				err := s.updateOrderAssociations(&parentOrder, reduceOrder.ID)
				if err != nil {
					log.Printf("[DB-Maintenance] å»ºç«‹å…³è”å…³ç³»å¤±è´¥ (çˆ¶%d -> å­%d): %v", parentOrder.ID, reduceOrder.ID, err)
				} else {
					repairedCount++
					log.Printf("[DB-Maintenance] ä¿®å¤å…³è”å…³ç³»: çˆ¶è®¢å•%d -> å¹³ä»“è®¢å•%d", parentOrder.ID, reduceOrder.ID)
				}
			}
		}
	}

	log.Printf("[DB-Maintenance] ä¿®å¤ä¸å®Œæ•´å…³è”å…³ç³»å®Œæˆï¼Œå…±ä¿®å¤ %d å¤„å…³è”å…³ç³»", repairedCount)
	return nil
}

// validateRelationshipConsistency éªŒè¯å…³è”å…³ç³»çš„ä¸€è‡´æ€§
func (s *Server) validateRelationshipConsistency() error {
	log.Printf("[DB-Maintenance] éªŒè¯å…³è”å…³ç³»ä¸€è‡´æ€§...")

	// 1. éªŒè¯åŒå‘å…³è”çš„ä¸€è‡´æ€§
	var parentOrders []pdb.ScheduledOrder
	err := s.db.DB().Where("close_order_ids != ''").Find(&parentOrders).Error
	if err != nil {
		return fmt.Errorf("æŸ¥è¯¢çˆ¶è®¢å•å¤±è´¥: %w", err)
	}

	inconsistencyCount := 0
	for _, parentOrder := range parentOrders {
		closeOrderIds := strings.Split(parentOrder.CloseOrderIds, ",")

		for _, idStr := range closeOrderIds {
			if id, parseErr := strconv.ParseUint(strings.TrimSpace(idStr), 10, 32); parseErr == nil {
				var childOrder pdb.ScheduledOrder
				err := s.db.DB().Where("id = ?", uint(id)).First(&childOrder).Error
				if err != nil {
					log.Printf("[DB-Maintenance] å‘ç°ä¸ä¸€è‡´: çˆ¶è®¢å•%då¼•ç”¨ä¸å­˜åœ¨çš„å­è®¢å•%d", parentOrder.ID, uint(id))
					inconsistencyCount++
					continue
				}

				// éªŒè¯åå‘å…³è”
				if childOrder.ParentOrderId != parentOrder.ID {
					log.Printf("[DB-Maintenance] å‘ç°ä¸ä¸€è‡´: çˆ¶è®¢å•%då¼•ç”¨å­è®¢å•%dï¼Œä½†å­è®¢å•çš„parent_order_idæ˜¯%d",
						parentOrder.ID, childOrder.ID, childOrder.ParentOrderId)
					inconsistencyCount++

					// ä¿®å¤åå‘å…³è”
					err := s.db.DB().Model(&childOrder).Update("parent_order_id", parentOrder.ID).Error
					if err != nil {
						log.Printf("[DB-Maintenance] ä¿®å¤åå‘å…³è”å¤±è´¥: %v", err)
					}
				}
			}
		}
	}

	// 2. éªŒè¯BracketLinkçš„ä¸€è‡´æ€§
	var bracketLinks []pdb.BracketLink
	err = s.db.DB().Where("status = ?", "active").Find(&bracketLinks).Error
	if err != nil {
		return fmt.Errorf("æŸ¥è¯¢BracketLinkå¤±è´¥: %w", err)
	}

	for _, bracketLink := range bracketLinks {
		// éªŒè¯å¼€ä»“è®¢å•æ˜¯å¦å­˜åœ¨
		var entryOrder pdb.ScheduledOrder
		err := s.db.DB().Where("client_order_id = ?", bracketLink.EntryClientID).First(&entryOrder).Error
		if err != nil {
			log.Printf("[DB-Maintenance] BracketLink %d çš„å¼€ä»“è®¢å•ä¸å­˜åœ¨ï¼Œæ ‡è®°ä¸ºorphaned", bracketLink.ID)
			s.db.DB().Model(&pdb.BracketLink{}).Where("id = ?", bracketLink.ID).Update("status", "orphaned")
			inconsistencyCount++
		}
	}

	log.Printf("[DB-Maintenance] éªŒè¯å…³è”å…³ç³»ä¸€è‡´æ€§å®Œæˆï¼Œå‘ç° %d å¤„ä¸ä¸€è‡´", inconsistencyCount)
	return nil
}

// cleanupOrphanedExternalOperations æ¸…ç†å­¤ç«‹çš„å¤–éƒ¨æ“ä½œè®°å½•
func (s *Server) cleanupOrphanedExternalOperations() error {
	log.Printf("[DB-Maintenance] æ¸…ç†å­¤ç«‹çš„å¤–éƒ¨æ“ä½œè®°å½•...")

	// æŸ¥è¯¢æ‰€æœ‰å¤–éƒ¨æ“ä½œè®°å½•
	var externalOps []pdb.ExternalOperation
	err := s.db.DB().Find(&externalOps).Error
	if err != nil {
		return fmt.Errorf("æŸ¥è¯¢å¤–éƒ¨æ“ä½œè®°å½•å¤±è´¥: %w", err)
	}

	cleanedCount := 0
	for _, extOp := range externalOps {
		// æ£€æŸ¥å…³è”çš„è®¢å•æ˜¯å¦è¿˜å­˜åœ¨
		if extOp.UserID > 0 {
			var userExists int64
			s.db.DB().Model(&pdb.ScheduledOrder{}).Where("user_id = ?", extOp.UserID).Count(&userExists)
			if userExists == 0 {
				// ç”¨æˆ·å·²ä¸å­˜åœ¨ï¼Œåˆ é™¤å¤–éƒ¨æ“ä½œè®°å½•
				err := s.db.DB().Delete(&extOp).Error
				if err != nil {
					log.Printf("[DB-Maintenance] åˆ é™¤å­¤ç«‹å¤–éƒ¨æ“ä½œè®°å½•å¤±è´¥ (ID=%d): %v", extOp.ID, err)
				} else {
					cleanedCount++
					log.Printf("[DB-Maintenance] åˆ é™¤å­¤ç«‹å¤–éƒ¨æ“ä½œè®°å½•: ID=%d (ç”¨æˆ·%dä¸å­˜åœ¨)", extOp.ID, extOp.UserID)
				}
			}
		}
	}

	log.Printf("[DB-Maintenance] æ¸…ç†å­¤ç«‹å¤–éƒ¨æ“ä½œè®°å½•å®Œæˆï¼Œå…±æ¸…ç† %d æ¡è®°å½•", cleanedCount)
	return nil
}

// enhancedUpdateOrderAssociations å¢å¼ºç‰ˆè®¢å•å…³è”å…³ç³»æ›´æ–°
func (s *Server) enhancedUpdateOrderAssociations(order *pdb.ScheduledOrder, relatedOrderID uint, relationshipType string) error {
	switch relationshipType {
	case "parent_to_close":
		// å¼€ä»“è®¢å•å…³è”å¹³ä»“è®¢å•
		return s.updateOrderAssociations(order, relatedOrderID)

	case "close_to_parent":
		// å¹³ä»“è®¢å•å…³è”å¼€ä»“è®¢å•
		return s.db.DB().Model(&pdb.ScheduledOrder{}).Where("id = ?", relatedOrderID).Update("parent_order_id", order.ID).Error

	case "bracket_entry":
		// Bracketå¼€ä»“è®¢å•å…³è”
		return s.updateBracketEntryAssociation(order, relatedOrderID)

	default:
		return fmt.Errorf("æœªçŸ¥çš„å…³è”å…³ç³»ç±»å‹: %s", relationshipType)
	}
}

// updateBracketEntryAssociation æ›´æ–°Bracketå¼€ä»“è®¢å•å…³è”
func (s *Server) updateBracketEntryAssociation(entryOrder *pdb.ScheduledOrder, bracketLinkID uint) error {
	// è¿™é‡Œå¯ä»¥æ·»åŠ Bracketè®¢å•çš„ç‰¹æ®Šå…³è”é€»è¾‘
	// ä¾‹å¦‚æ›´æ–°BracketLinkçš„çŠ¶æ€æˆ–å…³è”ä¿¡æ¯
	return nil
}

// fixOrderStatusInconsistency ä¿®å¤è®¢å•çŠ¶æ€ä¸ä¸€è‡´é—®é¢˜
func (s *Server) fixOrderStatusInconsistency(client *bf.Client) error {
	log.Printf("[Order-Sync] å¼€å§‹æ£€æŸ¥è®¢å•çŠ¶æ€ä¸€è‡´æ€§...")

	// æŸ¥è¯¢å¯èƒ½å­˜åœ¨çŠ¶æ€ä¸ä¸€è‡´çš„æ¡ä»¶è®¢å•
	var inconsistentOrders []pdb.ScheduledOrder
	err := s.db.DB().Model(&pdb.ScheduledOrder{}).
		Where("status IN (?) AND order_type IN (?) AND exchange = ? AND client_order_id != ''",
			[]string{"success", "processing"},
			[]string{"TAKE_PROFIT_MARKET", "STOP_MARKET"},
			"binance_futures").
		Find(&inconsistentOrders).Error

	if err != nil {
		return fmt.Errorf("æŸ¥è¯¢å¯èƒ½ä¸ä¸€è‡´çš„è®¢å•å¤±è´¥: %w", err)
	}

	if len(inconsistentOrders) == 0 {
		log.Printf("[Order-Sync] æ²¡æœ‰å‘ç°çŠ¶æ€ä¸ä¸€è‡´çš„è®¢å•")
		return nil
	}

	log.Printf("[Order-Sync] å‘ç° %d ä¸ªå¯èƒ½çŠ¶æ€ä¸ä¸€è‡´çš„æ¡ä»¶è®¢å•ï¼Œå¼€å§‹æ£€æŸ¥", len(inconsistentOrders))

	fixedCount := 0
	for _, order := range inconsistentOrders {
		// æŸ¥è¯¢äº¤æ˜“æ‰€çš„å®é™…çŠ¶æ€
		algoStatus, algoErr := client.QueryAlgoOrder(order.Symbol, order.ClientOrderId)
		if algoErr != nil {
			log.Printf("[Order-Sync] æŸ¥è¯¢è®¢å• %s çŠ¶æ€å¤±è´¥ï¼Œè·³è¿‡: %v", order.ClientOrderId, algoErr)
			continue
		}

		// å¦‚æœäº¤æ˜“æ‰€çŠ¶æ€ä¸ºFINISHEDï¼Œä½†æœ¬åœ°çŠ¶æ€è¿˜æ˜¯æ´»è·ƒçš„ï¼Œä¿®å¤çŠ¶æ€
		if algoStatus.Status == "FINISHED" && (order.Status == "success" || order.Status == "processing") {
			log.Printf("[Order-Sync] å‘ç°çŠ¶æ€ä¸ä¸€è‡´ - æœ¬åœ°:%s, äº¤æ˜“æ‰€:FINISHEDï¼Œä¿®å¤è®¢å• %s",
				order.Status, order.ClientOrderId)

			err := s.updateAlgoOrderStatus(order.ClientOrderId, "filled", algoStatus)
			if err != nil {
				log.Printf("[Order-Sync] ä¿®å¤è®¢å• %s çŠ¶æ€å¤±è´¥: %v", order.ClientOrderId, err)
			} else {
				log.Printf("[Order-Sync] âœ… æˆåŠŸä¿®å¤è®¢å• %s çŠ¶æ€ä¸ºfilled", order.ClientOrderId)
				fixedCount++
			}
		}
	}

	log.Printf("[Order-Sync] çŠ¶æ€ä¸€è‡´æ€§æ£€æŸ¥å®Œæˆï¼Œä¿®å¤äº† %d ä¸ªè®¢å•", fixedCount)
	return nil
}

// syncAllOrderStatus åŒæ­¥æ‰€æœ‰æ´»è·ƒè®¢å•çš„çŠ¶æ€
func (s *Server) syncAllOrderStatus() error {
	// æŸ¥è¯¢éœ€è¦åŒæ­¥çš„è®¢å•ï¼šçŠ¶æ€ä¸ºsuccessã€processingçš„è®¢å•
	// ä¸åŒæ­¥filledçŠ¶æ€çš„è®¢å•ï¼Œå› ä¸ºå®ƒä»¬å·²ç»å®Œæˆ
	// success: å·²å‘é€åˆ°äº¤æ˜“æ‰€ï¼Œç­‰å¾…ç¡®è®¤
	// processing: æ­£åœ¨å¤„ç†ä¸­
	// filled: å·²å®Œæˆï¼Œä¸éœ€è¦ç»§ç»­åŒæ­¥
	var orders []pdb.ScheduledOrder
	err := s.db.DB().Model(&pdb.ScheduledOrder{}).
		Where("status IN (?) AND client_order_id != '' AND exchange = 'binance_futures'",
			[]string{"success", "processing"}).
		Find(&orders).Error

	if err != nil {
		return fmt.Errorf("æŸ¥è¯¢å¾…åŒæ­¥è®¢å•å¤±è´¥: %w", err)
	}

	if len(orders) == 0 {
		log.Printf("[Order-Sync] æ²¡æœ‰éœ€è¦åŒæ­¥çš„è®¢å•")
		return nil
	}

	log.Printf("[Order-Sync] å‘ç° %d ä¸ªå¾…åŒæ­¥è®¢å•", len(orders))

	// ä½¿ç”¨é…ç½®çš„ç¯å¢ƒåˆ›å»ºå¸å®‰å®¢æˆ·ç«¯
	useTestnet := s.cfg.Exchange.Binance.IsTestnet
	client := bf.New(useTestnet, s.cfg.Exchange.Binance.APIKey, s.cfg.Exchange.Binance.SecretKey)

	syncedCount := 0
	errorCount := 0

	// åŒæ­¥æ¯ä¸ªè®¢å•
	for _, order := range orders {

		// æ ¹æ®è®¢å•ç±»å‹é€‰æ‹©æ­£ç¡®çš„æŸ¥è¯¢API
		var status string
		var executedQty string
		var avgPrice string
		var orderId int64

		if order.OrderType == "TAKE_PROFIT_MARKET" || order.OrderType == "STOP_MARKET" {
			// æ¡ä»¶è®¢å•ä½¿ç”¨Algoè®¢å•æŸ¥è¯¢
			algoStatus, algoErr := client.QueryAlgoOrder(order.Symbol, order.ClientOrderId)
			if algoErr != nil {
				log.Printf("[Order-Sync] æŸ¥è¯¢Algoè®¢å• %s çŠ¶æ€å¤±è´¥: %v", order.ClientOrderId, algoErr)
				errorCount++
				continue
			}

			// ğŸš€ ä¼˜åŒ–ï¼šå¦‚æœAlgoè®¢å•å·²å®Œæˆ(FINISHED)ï¼Œç«‹å³æ›´æ–°æœ¬åœ°çŠ¶æ€ï¼Œé¿å…é‡å¤æŸ¥è¯¢
			if algoStatus.Status == "FINISHED" {
				log.Printf("[Order-Sync] Algoè®¢å• %s å·²å®Œæˆï¼Œç«‹å³æ›´æ–°çŠ¶æ€ä¸ºfilled", order.ClientOrderId)
				err := s.db.DB().Model(&pdb.ScheduledOrder{}).Where("id = ?", order.ID).Updates(map[string]interface{}{
					"status":       "filled",
					"executed_qty": algoStatus.ExecutedQty,
					"avg_price":    algoStatus.AvgPrice,
					"result":       "æ¡ä»¶è®¢å•æ‰§è¡ŒæˆåŠŸ",
				}).Error
				if err != nil {
					log.Printf("[Order-Sync] æ›´æ–°Algoè®¢å• %s çŠ¶æ€å¤±è´¥: %v", order.ClientOrderId, err)
					errorCount++
				} else {
					log.Printf("[Order-Sync] âœ… Algoè®¢å• %s çŠ¶æ€å·²æ›´æ–°ä¸ºfilled", order.ClientOrderId)
					syncedCount++
				}
				continue // å·²å®Œæˆè®¢å•ä¸å†è¿›è¡Œåç»­å¤„ç†
			}

			status = algoStatus.Status
			executedQty = algoStatus.ExecutedQty
			avgPrice = algoStatus.AvgPrice
			orderId = algoStatus.AlgoId // Algoè®¢å•ä½¿ç”¨AlgoId
		} else {
			// æ™®é€šè®¢å•ä½¿ç”¨æ™®é€šæŸ¥è¯¢
			orderStatus, queryErr := client.QueryOrder(order.Symbol, order.ClientOrderId)
			if queryErr != nil {
				log.Printf("[Order-Sync] æŸ¥è¯¢è®¢å• %s çŠ¶æ€å¤±è´¥: %v", order.ClientOrderId, queryErr)
				errorCount++
				continue
			}
			status = orderStatus.Status
			executedQty = orderStatus.ExecutedQty
			avgPrice = orderStatus.AvgPrice
			orderId = orderStatus.OrderId
		}

		// æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°
		shouldUpdate := false
		updateData := make(map[string]interface{})

		// æ›´æ–°äº¤æ˜“æ‰€è®¢å•IDï¼ˆå¦‚æœè¿˜æ²¡æœ‰ï¼‰
		if order.ExchangeOrderId == "" && orderId > 0 {
			updateData["exchange_order_id"] = strconv.FormatInt(orderId, 10)
			shouldUpdate = true
		}

		// æ›´æ–°æˆäº¤æ•°é‡ï¼ˆå¦‚æœè¿˜æ²¡æœ‰æˆ–æœ‰æ›´æ–°ï¼‰
		if executedQty != "" && executedQty != "0" {
			if order.ExecutedQty == "" || (order.ExecutedQty != executedQty) {
				updateData["executed_quantity"] = executedQty
				shouldUpdate = true
			}
		}

		// æ›´æ–°å¹³å‡ä»·æ ¼ï¼ˆå¦‚æœè¿˜æ²¡æœ‰æˆ–æœ‰æ›´æ–°ï¼‰
		if avgPrice != "" && avgPrice != "0" {
			if order.AvgPrice == "" || (order.AvgPrice != avgPrice) {
				updateData["avg_price"] = avgPrice
				shouldUpdate = true
			}
		}

		// æ›´æ–°è®¢å•çŠ¶æ€
		newStatus := ""
		switch status {
		case "FILLED", "EXECUTED":
			if order.Status != "filled" {
				newStatus = "filled"
			}
		case "CANCELED", "PENDING_CANCEL":
			if order.Status != "canceled" {
				newStatus = "canceled"
			}
		case "REJECTED", "EXPIRED":
			if order.Status != "failed" {
				newStatus = "failed"
			}
		case "PARTIALLY_FILLED":
			// éƒ¨åˆ†æˆäº¤ï¼Œä¿æŒç°æœ‰çŠ¶æ€ä½†æ›´æ–°æˆäº¤ä¿¡æ¯
		case "NEW":
			// æ–°è®¢å•ï¼Œä¿æŒç°æœ‰çŠ¶æ€
		}

		if newStatus != "" {
			updateData["status"] = newStatus
			shouldUpdate = true
		}

		// æ‰§è¡Œæ›´æ–°
		if shouldUpdate {
			err := s.db.DB().Model(&pdb.ScheduledOrder{}).Where("id = ?", order.ID).Updates(updateData).Error
			if err != nil {
				log.Printf("[Order-Sync] æ›´æ–°è®¢å• %d çŠ¶æ€å¤±è´¥: %v", order.ID, err)
				errorCount++
			} else {
				log.Printf("[Order-Sync] è®¢å• %d çŠ¶æ€å·²æ›´æ–°: %s -> %s", order.ID, order.Status, newStatus)

				// è®°å½•è®¢å•çŠ¶æ€æ›´æ–°åˆ°å®¡è®¡æ—¥å¿—
				s.logOrderOperation(&order, "status_update",
					fmt.Sprintf("è®¢å•çŠ¶æ€ä» %s æ›´æ–°ä¸º %s", order.Status, newStatus),
					map[string]string{"status": order.Status},
					map[string]string{"status": newStatus},
					"system", "info", "")

				syncedCount++
			}
		}
	}

	log.Printf("[Order-Sync] å¸¸è§„è®¢å•åŒæ­¥å®Œæˆ: %d ä¸ªæˆåŠŸ, %d ä¸ªå¤±è´¥", syncedCount, errorCount)

	// ğŸš€ ä¼˜åŒ–ï¼šæ‰§è¡ŒçŠ¶æ€ä¸€è‡´æ€§æ£€æŸ¥ï¼Œä¿®å¤å¯èƒ½çš„çŠ¶æ€ä¸ä¸€è‡´é—®é¢˜
	if err := s.fixOrderStatusInconsistency(client); err != nil {
		log.Printf("[Order-Sync] çŠ¶æ€ä¸€è‡´æ€§æ£€æŸ¥å¤±è´¥: %v", err)
	}

	// åŒæ­¥Bracketè®¢å•çš„TP/SLçŠ¶æ€
	bracketSyncedCount, bracketErrorCount := s.syncBracketOrders(client)
	log.Printf("[Order-Sync] Bracketè®¢å•åŒæ­¥å®Œæˆ: %d ä¸ªæˆåŠŸ, %d ä¸ªå¤±è´¥", bracketSyncedCount, bracketErrorCount)

	// æ‰§è¡Œå¤–éƒ¨æ“ä½œæ£€æµ‹å’Œå¤„ç†
	externalOpsCount, externalOpsErrors := s.detectAndProcessExternalOperations(client)
	log.Printf("[Order-Sync] å¤–éƒ¨æ“ä½œæ£€æµ‹å®Œæˆ: %d ä¸ªæ“ä½œ, %d ä¸ªé”™è¯¯", externalOpsCount, externalOpsErrors)

	// æ‰§è¡Œæ•°æ®åº“å…³è”å…³ç³»ç»´æŠ¤
	if err := s.maintainDatabaseRelationships(); err != nil {
		log.Printf("[Order-Sync] æ•°æ®åº“å…³è”å…³ç³»ç»´æŠ¤å¤±è´¥: %v", err)
	} else {
		log.Printf("[Order-Sync] æ•°æ®åº“å…³è”å…³ç³»ç»´æŠ¤å®Œæˆ")
	}

	return nil
}

// syncBracketOrders åŒæ­¥Bracketè®¢å•çš„TP/SLæ¡ä»¶è®¢å•çŠ¶æ€
func (s *Server) syncBracketOrders(client *bf.Client) (syncedCount, errorCount int) {
	// æŸ¥è¯¢æ‰€æœ‰æ´»è·ƒçš„Bracketè®¢å•ï¼ˆæ’é™¤orphanedçŠ¶æ€çš„è®°å½•ï¼‰
	var bracketLinks []pdb.BracketLink
	err := s.db.DB().Where("status = ? AND status != ?", "active", "orphaned").Find(&bracketLinks).Error
	if err != nil {
		log.Printf("[Order-Sync] æŸ¥è¯¢æ´»è·ƒBracketè®¢å•å¤±è´¥: %v", err)
		return 0, 1
	}

	if len(bracketLinks) == 0 {
		log.Printf("[Order-Sync] æ²¡æœ‰éœ€è¦åŒæ­¥çš„Bracketè®¢å•")
		return 0, 0
	}

	log.Printf("[Order-Sync] å‘ç° %d ä¸ªæ´»è·ƒBracketè®¢å•éœ€è¦åŒæ­¥", len(bracketLinks))

	// ç»Ÿè®¡ä¿¡æ¯
	tpTriggeredCount := 0
	slTriggeredCount := 0

	for _, bracketLink := range bracketLinks {
		// è·å–å¯¹åº”çš„å¼€ä»“è®¢å•ä¿¡æ¯ï¼Œç¡®å®šæ˜¯æµ‹è¯•ç½‘è¿˜æ˜¯æ­£å¼ç½‘
		var entryOrder pdb.ScheduledOrder
		err := s.db.DB().Where("client_order_id = ?", bracketLink.EntryClientID).First(&entryOrder).Error
		if err != nil {
			log.Printf("[Order-Sync] âŒ Bracketè®¢å• %s çš„å¼€ä»“è®¢å•ä¸å­˜åœ¨ (ClientID: %s)ï¼Œæ ‡è®°ä¸ºæ— æ•ˆçŠ¶æ€",
				bracketLink.GroupID, bracketLink.EntryClientID)

			// å°†ä¸ä¸€è‡´çš„BracketLinkæ ‡è®°ä¸ºæ— æ•ˆçŠ¶æ€ï¼Œé¿å…é‡å¤æŠ¥é”™
			err := s.db.DB().Model(&pdb.BracketLink{}).Where("id = ?", bracketLink.ID).
				Update("status", "orphaned").Error
			if err != nil {
				log.Printf("[Order-Sync] æ›´æ–°BracketLink %d çŠ¶æ€å¤±è´¥: %v", bracketLink.ID, err)
			} else {
				log.Printf("[Order-Sync] BracketLink %d å·²æ ‡è®°ä¸º orphaned çŠ¶æ€", bracketLink.ID)
			}

			errorCount++
			continue
		}

		// éªŒè¯å¼€ä»“è®¢å•çŠ¶æ€
		if entryOrder.Status != "filled" {
			log.Printf("[Order-Sync] è·³è¿‡Bracketè®¢å• %sï¼Œå¼€ä»“è®¢å•çŠ¶æ€ä¸º: %s", bracketLink.GroupID, entryOrder.Status)
			continue
		}

		// å¼€ä»“è®¢å•å·²æ‰§è¡Œï¼Œç°åœ¨æ£€æŸ¥TP/SLæ¡ä»¶è®¢å•çš„çŠ¶æ€
		// æ­£ç¡®çš„Bracketé€»è¾‘ï¼šå¼€ä»“æˆåŠŸåï¼ŒTP/SLåº”è¯¥ä¿æŒæ´»è·ƒï¼Œç›´åˆ°å…¶ä¸­ä¸€ä¸ªè¢«è§¦å‘
		log.Printf("[Order-Sync] Bracketè®¢å• %s å¼€ä»“å·²æ‰§è¡Œï¼Œæ£€æŸ¥TP/SLçŠ¶æ€", bracketLink.GroupID)

		// æ£€æŸ¥TPè®¢å•çŠ¶æ€
		tpTriggered := false
		slTriggered := false

		// æŸ¥è¯¢TPè®¢å•çŠ¶æ€ï¼ˆä¼˜å…ˆå°è¯•Algoè®¢å•ï¼Œç„¶åä¼ ç»Ÿè®¢å•ï¼‰
		if bracketLink.TPClientID != "" {
			var err error

			// é¦–å…ˆå°è¯•æŸ¥è¯¢Algoè®¢å•ï¼ˆæ–°ç‰ˆæ­¢ç›ˆæ­¢æŸè®¢å•ï¼‰
			if algoStatus, algoErr := client.QueryAlgoOrder(bracketLink.Symbol, bracketLink.TPClientID); algoErr == nil {
				log.Printf("[Order-Sync] TP Algoè®¢å• %s çŠ¶æ€: %s", bracketLink.TPClientID, algoStatus.Status)
				if algoStatus.Status == "TRIGGERED" || algoStatus.Status == "FILLED" || algoStatus.Status == "FINISHED" || algoStatus.Status == "success" {
					tpTriggered = true
					log.Printf("[Order-Sync] âœ… TP Algoè®¢å• %s å·²è§¦å‘ï¼Œæˆäº¤ä»·: %s, æ•°é‡: %s",
						bracketLink.TPClientID, algoStatus.AvgPrice, algoStatus.ExecutedQty)

					// ğŸš€ ä¼˜åŒ–ï¼šå¦‚æœTPè®¢å•å·²å®Œæˆ(FINISHED)ï¼Œç«‹å³æ›´æ–°æœ¬åœ°è®¢å•çŠ¶æ€ï¼Œé¿å…åç»­é‡å¤æŸ¥è¯¢
					if algoStatus.Status == "FINISHED" {
						err := s.updateAlgoOrderStatus(bracketLink.TPClientID, "filled", algoStatus)
						if err != nil {
							log.Printf("[Order-Sync] æ›´æ–°TPè®¢å• %s çŠ¶æ€å¤±è´¥: %v", bracketLink.TPClientID, err)
						}
					}
				}
			} else {
				// Algoè®¢å•æŸ¥è¯¢å¤±è´¥ï¼Œå°è¯•ä¼ ç»Ÿè®¢å•æŸ¥è¯¢
				log.Printf("[Order-Sync] TP Algoè®¢å•æŸ¥è¯¢å¤±è´¥ï¼Œå°è¯•ä¼ ç»Ÿè®¢å•: %v", algoErr)
				if tradStatus, tradErr := client.QueryOrder(bracketLink.Symbol, bracketLink.TPClientID); tradErr == nil {
					log.Printf("[Order-Sync] TPä¼ ç»Ÿè®¢å• %s çŠ¶æ€: %s", bracketLink.TPClientID, tradStatus.Status)
					if tradStatus.Status == "FILLED" {
						tpTriggered = true
						log.Printf("[Order-Sync] âœ… TPä¼ ç»Ÿè®¢å• %s å·²æˆäº¤ï¼Œæˆäº¤ä»·: %s, æ•°é‡: %s",
							bracketLink.TPClientID, tradStatus.AvgPrice, tradStatus.ExecutedQty)
					}
				} else {
					err = fmt.Errorf("Algoè®¢å•æŸ¥è¯¢å¤±è´¥: %v, ä¼ ç»Ÿè®¢å•æŸ¥è¯¢å¤±è´¥: %v", algoErr, tradErr)
				}
			}

			if err != nil {
				log.Printf("[Order-Sync] æŸ¥è¯¢TPè®¢å• %s çŠ¶æ€å¤±è´¥: %v", bracketLink.TPClientID, err)
				errorCount++
			}
		}

		// æŸ¥è¯¢SLè®¢å•çŠ¶æ€ï¼ˆä¼˜å…ˆå°è¯•Algoè®¢å•ï¼Œç„¶åä¼ ç»Ÿè®¢å•ï¼‰
		if bracketLink.SLClientID != "" {
			var err error

			// é¦–å…ˆå°è¯•æŸ¥è¯¢Algoè®¢å•ï¼ˆæ–°ç‰ˆæ­¢ç›ˆæ­¢æŸè®¢å•ï¼‰
			if algoStatus, algoErr := client.QueryAlgoOrder(bracketLink.Symbol, bracketLink.SLClientID); algoErr == nil {
				log.Printf("[Order-Sync] SL Algoè®¢å• %s çŠ¶æ€: %s", bracketLink.SLClientID, algoStatus.Status)
				if algoStatus.Status == "TRIGGERED" || algoStatus.Status == "FILLED" || algoStatus.Status == "FINISHED" || algoStatus.Status == "success" {
					slTriggered = true
					log.Printf("[Order-Sync] âœ… SL Algoè®¢å• %s å·²è§¦å‘ï¼Œæˆäº¤ä»·: %s, æ•°é‡: %s",
						bracketLink.SLClientID, algoStatus.AvgPrice, algoStatus.ExecutedQty)

					// ğŸš€ ä¼˜åŒ–ï¼šå¦‚æœSLè®¢å•å·²å®Œæˆ(FINISHED)ï¼Œç«‹å³æ›´æ–°æœ¬åœ°è®¢å•çŠ¶æ€ï¼Œé¿å…åç»­é‡å¤æŸ¥è¯¢
					if algoStatus.Status == "FINISHED" {
						err := s.updateAlgoOrderStatus(bracketLink.SLClientID, "filled", algoStatus)
						if err != nil {
							log.Printf("[Order-Sync] æ›´æ–°SLè®¢å• %s çŠ¶æ€å¤±è´¥: %v", bracketLink.SLClientID, err)
						}
					}
				}
			} else {
				// Algoè®¢å•æŸ¥è¯¢å¤±è´¥ï¼Œå°è¯•ä¼ ç»Ÿè®¢å•æŸ¥è¯¢
				log.Printf("[Order-Sync] SL Algoè®¢å•æŸ¥è¯¢å¤±è´¥ï¼Œå°è¯•ä¼ ç»Ÿè®¢å•: %v", algoErr)
				if tradStatus, tradErr := client.QueryOrder(bracketLink.Symbol, bracketLink.SLClientID); tradErr == nil {
					log.Printf("[Order-Sync] SLä¼ ç»Ÿè®¢å• %s çŠ¶æ€: %s", bracketLink.SLClientID, tradStatus.Status)
					if tradStatus.Status == "FILLED" {
						slTriggered = true
						log.Printf("[Order-Sync] âœ… SLä¼ ç»Ÿè®¢å• %s å·²æˆäº¤ï¼Œæˆäº¤ä»·: %s, æ•°é‡: %s",
							bracketLink.SLClientID, tradStatus.AvgPrice, tradStatus.ExecutedQty)
					}
				} else {
					err = fmt.Errorf("Algoè®¢å•æŸ¥è¯¢å¤±è´¥: %v, ä¼ ç»Ÿè®¢å•æŸ¥è¯¢å¤±è´¥: %v", algoErr, tradErr)
				}
			}

			if err != nil {
				log.Printf("[Order-Sync] æŸ¥è¯¢SLè®¢å• %s çŠ¶æ€å¤±è´¥: %v", bracketLink.SLClientID, err)
				errorCount++
			}
		}

		// å¦‚æœTPæˆ–SLè¢«è§¦å‘ï¼Œåˆ›å»ºå¹³ä»“è®¢å•è®°å½•å¹¶æ›´æ–°BracketLinkçŠ¶æ€
		if tpTriggered || slTriggered {
			if tpTriggered {
				tpTriggeredCount++
			}
			if slTriggered {
				slTriggeredCount++
			}

			err := s.handleBracketOrderClosure(bracketLink, entryOrder, tpTriggered, slTriggered)
			if err != nil {
				log.Printf("[Order-Sync] å¤„ç†Bracketè®¢å•å…³é—­å¤±è´¥ %s: %v", bracketLink.GroupID, err)
				errorCount++
			} else {
				log.Printf("[Order-Sync] Bracketè®¢å• %s å·²å…³é—­ (TP:%v, SL:%v)", bracketLink.GroupID, tpTriggered, slTriggered)
				syncedCount++
			}
		}
	}

	log.Printf("[Order-Sync] BracketåŒæ­¥ç»Ÿè®¡: æ€»è®¢å•=%d, æ­¢ç›ˆè§¦å‘=%d, æ­¢æŸè§¦å‘=%d, æˆåŠŸåŒæ­¥=%d, åŒæ­¥å¤±è´¥=%d",
		len(bracketLinks), tpTriggeredCount, slTriggeredCount, syncedCount, errorCount)

	return syncedCount, errorCount
}

// updateAlgoOrderStatus æ›´æ–°Algoè®¢å•çŠ¶æ€çš„è¾…åŠ©æ–¹æ³•
func (s *Server) updateAlgoOrderStatus(clientOrderId string, status string, algoStatus *bf.AlgoOrderResp) error {
	updates := map[string]interface{}{
		"status": status,
		"result": "æ¡ä»¶è®¢å•æ‰§è¡ŒæˆåŠŸ",
	}

	if algoStatus != nil {
		if algoStatus.ExecutedQty != "" {
			updates["executed_qty"] = algoStatus.ExecutedQty
		}
		if algoStatus.AvgPrice != "" {
			updates["avg_price"] = algoStatus.AvgPrice
		}
	}

	return s.db.DB().Model(&pdb.ScheduledOrder{}).Where("client_order_id = ?", clientOrderId).Updates(updates).Error
}

// cancelConditionalOrderIfNeeded æ£€æŸ¥å¹¶å–æ¶ˆæ¡ä»¶è®¢å•ï¼ˆå¦‚æœè¿˜æ²¡æ‰§è¡Œï¼‰
func (s *Server) cancelConditionalOrderIfNeeded(client *bf.Client, symbol, clientOrderId, orderType string) error {
	// é¦–å…ˆæŸ¥è¯¢è®¢å•çŠ¶æ€
	algoStatus, algoErr := client.QueryAlgoOrder(symbol, clientOrderId)
	if algoErr != nil {
		log.Printf("[Order-Sync] âŒ æŸ¥è¯¢Algoè®¢å•çŠ¶æ€å¤±è´¥ %s: %v", clientOrderId, algoErr)
		// å¦‚æœæŸ¥è¯¢å¤±è´¥ï¼Œå¯èƒ½æ˜¯ç½‘ç»œé—®é¢˜ï¼Œä¸è¦æ€¥äºå–æ¶ˆï¼Œæ ‡è®°ä¸ºéœ€è¦é‡è¯•
		return fmt.Errorf("æŸ¥è¯¢Algoè®¢å•çŠ¶æ€å¤±è´¥: %v", algoErr)
	}

	// å¦‚æœè®¢å•å·²ç»æ‰§è¡Œï¼Œè·³è¿‡å–æ¶ˆ
	if algoStatus.Status == "EXECUTED" || algoStatus.Status == "FINISHED" || algoStatus.Status == "TRIGGERED" {
		log.Printf("[Order-Sync] %sè®¢å• %s å·²æ‰§è¡Œ (çŠ¶æ€: %s)ï¼Œè·³è¿‡å–æ¶ˆ", orderType, clientOrderId, algoStatus.Status)
		return nil
	}

	// å¦‚æœè®¢å•è¿˜æ²¡æ‰§è¡Œï¼Œå°è¯•å–æ¶ˆï¼ˆæ·»åŠ é‡è¯•æœºåˆ¶ï¼‰
	log.Printf("[Order-Sync] å–æ¶ˆ%sè®¢å• %s (å½“å‰çŠ¶æ€: %s)", orderType, clientOrderId, algoStatus.Status)

	maxRetries := 3
	for attempt := 1; attempt <= maxRetries; attempt++ {
		cancelCode, cancelBody, cancelErr := client.CancelAlgoOrder(symbol, clientOrderId)

		if cancelErr != nil {
			log.Printf("[Order-Sync] âŒ å–æ¶ˆè®¢å•å¤±è´¥ (å°è¯• %d/%d) %s: %v", attempt, maxRetries, clientOrderId, cancelErr)
			if attempt == maxRetries {
				// æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥äº†ï¼Œä¸è¦æ›´æ–°æ•°æ®åº“çŠ¶æ€ï¼Œä¿æŒåŸçŠ¶æ€ä»¥ä¾¿åç»­é‡è¯•
				log.Printf("[Order-Sync] âš ï¸ å–æ¶ˆè®¢å•å¤±è´¥ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° %s", clientOrderId)
				return fmt.Errorf("å–æ¶ˆè®¢å•å¤±è´¥ï¼Œå·²é‡è¯• %d æ¬¡: %v", maxRetries, cancelErr)
			}
			continue // ç»§ç»­é‡è¯•
		}

		if cancelCode >= 400 {
			cancelResp := string(cancelBody)
			log.Printf("[Order-Sync] å–æ¶ˆè®¢å•å“åº” (å°è¯• %d/%d): code=%d, body=%s", attempt, maxRetries, cancelCode, cancelResp)

			// æ£€æŸ¥æ˜¯å¦æ˜¯"è®¢å•ä¸å­˜åœ¨"æˆ–"è®¢å•å·²æ‰§è¡Œ"ç­‰é”™è¯¯ï¼Œè¿™äº›æƒ…å†µä¸‹è®¢å•å¯èƒ½å·²ç»è¢«å–æ¶ˆæˆ–æ‰§è¡Œ
			if strings.Contains(cancelResp, "Order does not exist") ||
				strings.Contains(cancelResp, "Order has been executed") ||
				strings.Contains(cancelResp, "Order has been canceled") ||
				strings.Contains(cancelResp, "Unknown order sent") {

				// ç‰¹æ®Šå¤„ç†"Unknown order sent"é”™è¯¯
				if strings.Contains(cancelResp, "Unknown order sent") {
					log.Printf("[Order-Sync] %sè®¢å• %s è¿”å›'Unknown order sent'ï¼Œé‡æ–°æŸ¥è¯¢çŠ¶æ€ç¡®è®¤", orderType, clientOrderId)
					// é‡æ–°æŸ¥è¯¢è®¢å•çŠ¶æ€
					if latestStatus, queryErr := client.QueryAlgoOrder(symbol, clientOrderId); queryErr == nil {
						log.Printf("[Order-Sync] é‡æ–°æŸ¥è¯¢ç»“æœ - %sè®¢å• %s çŠ¶æ€: %s", orderType, clientOrderId, latestStatus.Status)
						if latestStatus.Status == "FINISHED" || latestStatus.Status == "EXECUTED" {
							// è®¢å•å®é™…ä¸Šå·²ç»æ‰§è¡Œäº†
							status := "filled"
							err := s.db.DB().Model(&pdb.ScheduledOrder{}).Where("client_order_id = ?", clientOrderId).
								Update("status", status).Error
							if err != nil {
								log.Printf("[Order-Sync] æ›´æ–°è®¢å•çŠ¶æ€å¤±è´¥ %s: %v", clientOrderId, err)
							} else {
								log.Printf("[Order-Sync] ç¡®è®¤%sè®¢å• %s å·²æ‰§è¡Œï¼Œæ›´æ–°çŠ¶æ€ä¸º %s", orderType, clientOrderId, status)
							}
							return nil
						} else if latestStatus.Status == "CANCELLED" || latestStatus.Status == "EXPIRED" {
							// è®¢å•å·²è¢«å–æ¶ˆæˆ–è¿‡æœŸ
							status := "cancelled"
							err := s.db.DB().Model(&pdb.ScheduledOrder{}).Where("client_order_id = ?", clientOrderId).
								Update("status", status).Error
							if err != nil {
								log.Printf("[Order-Sync] æ›´æ–°è®¢å•çŠ¶æ€å¤±è´¥ %s: %v", clientOrderId, err)
							} else {
								log.Printf("[Order-Sync] ç¡®è®¤%sè®¢å• %s å·²å–æ¶ˆï¼Œæ›´æ–°çŠ¶æ€ä¸º %s", orderType, clientOrderId, status)
							}
							return nil
						} else if latestStatus.Status == "NEW" || latestStatus.Status == "PARTIALLY_FILLED" {
							// è®¢å•ä»ç„¶æ´»è·ƒï¼Œç»§ç»­é‡è¯•å–æ¶ˆæ“ä½œ
							log.Printf("[Order-Sync] %sè®¢å• %s çŠ¶æ€ä¸º %sï¼Œä»å¤„äºæ´»è·ƒçŠ¶æ€ï¼Œç»§ç»­é‡è¯•å–æ¶ˆ", orderType, clientOrderId, latestStatus.Status)
							// ä¸æ›´æ–°æ•°æ®åº“ï¼Œç»§ç»­é‡è¯•
						} else {
							// å…¶ä»–æœªçŸ¥çŠ¶æ€ï¼Œè·³è¿‡å¤„ç†
							log.Printf("[Order-Sync] %sè®¢å• %s çŠ¶æ€ä¸º %sï¼ŒæœªçŸ¥çŠ¶æ€ï¼Œè·³è¿‡å¤„ç†", orderType, clientOrderId, latestStatus.Status)
							return nil
						}
					} else {
						log.Printf("[Order-Sync] é‡æ–°æŸ¥è¯¢%sè®¢å• %s å¤±è´¥: %vï¼Œå°†é‡è¯•å–æ¶ˆ", orderType, clientOrderId, queryErr)
						// æŸ¥è¯¢å¤±è´¥ï¼Œç»§ç»­é‡è¯•å–æ¶ˆæ“ä½œ
					}
				} else {
					// å…¶ä»–æ˜ç¡®çš„é”™è¯¯ä¿¡æ¯ï¼Œå¯ä»¥å®‰å…¨æ›´æ–°çŠ¶æ€
					log.Printf("[Order-Sync] %sè®¢å• %s å·²è¢«å¤„ç† (å“åº”: %s)", orderType, clientOrderId, cancelResp)
					// æ›´æ–°æ•°æ®åº“çŠ¶æ€
					status := "cancelled"
					if strings.Contains(cancelResp, "Order has been executed") {
						status = "filled"
					}
					err := s.db.DB().Model(&pdb.ScheduledOrder{}).Where("client_order_id = ?", clientOrderId).
						Update("status", status).Error
					if err != nil {
						log.Printf("[Order-Sync] æ›´æ–°è®¢å•çŠ¶æ€å¤±è´¥ %s: %v", clientOrderId, err)
					} else {
						log.Printf("[Order-Sync] æˆåŠŸæ›´æ–°è®¢å• %s çŠ¶æ€ä¸º %s", clientOrderId, status)
					}
					return nil
				}
			}

			// å…¶ä»–é”™è¯¯ï¼Œç»§ç»­é‡è¯•
			log.Printf("[Order-Sync] å–æ¶ˆè®¢å•å“åº”é”™è¯¯ (å°è¯• %d/%d): code=%d, body=%s", attempt, maxRetries, cancelCode, cancelResp)
			if attempt == maxRetries {
				return fmt.Errorf("å–æ¶ˆè®¢å•å“åº”é”™è¯¯ï¼Œå·²é‡è¯• %d æ¬¡: code=%d, body=%s", maxRetries, cancelCode, cancelResp)
			}
			continue // ç»§ç»­é‡è¯•
		}

		// å–æ¶ˆæˆåŠŸï¼Œæ›´æ–°æ•°æ®åº“çŠ¶æ€
		err := s.db.DB().Model(&pdb.ScheduledOrder{}).Where("client_order_id = ?", clientOrderId).
			Update("status", "cancelled").Error
		if err != nil {
			log.Printf("[Order-Sync] æ›´æ–°æ•°æ®åº“çŠ¶æ€å¤±è´¥ %s: %v", clientOrderId, err)
			return fmt.Errorf("æ›´æ–°æ•°æ®åº“çŠ¶æ€å¤±è´¥: %v", err)
		}

		log.Printf("[Order-Sync] âœ… æˆåŠŸå–æ¶ˆ%sè®¢å• %s", orderType, clientOrderId)
		return nil
	}

	return fmt.Errorf("å–æ¶ˆè®¢å•æ„å¤–å¤±è´¥")
}

// handleBracketOrderClosure å¤„ç†Bracketè®¢å•å…³é—­é€»è¾‘
func (s *Server) handleBracketOrderClosure(bracketLink pdb.BracketLink, entryOrder pdb.ScheduledOrder, tpTriggered, slTriggered bool) error {
	// å¼€å¯äº‹åŠ¡
	tx := s.db.DB().Begin()
	defer func() {
		if r := recover(); r != nil {
			tx.Rollback()
		}
	}()

	// ä½¿ç”¨é…ç½®çš„ç¯å¢ƒè®¾ç½®è·å–è®¢å•è¯¦æƒ…
	useTestnet := s.cfg.Exchange.Binance.IsTestnet
	client := bf.New(useTestnet, s.cfg.Exchange.Binance.APIKey, s.cfg.Exchange.Binance.SecretKey)

	// ğŸ”§ ä¿®å¤ï¼šå–æ¶ˆå¦ä¸€æ–¹å‘çš„æ¡ä»¶è®¢å•ï¼Œé¿å…é‡å¤è§¦å‘
	if tpTriggered && bracketLink.SLClientID != "" {
		// æ­¢ç›ˆè§¦å‘ï¼Œå–æ¶ˆæ­¢æŸè®¢å•
		log.Printf("[Bracket-Closure] æ­¢ç›ˆå·²è§¦å‘ï¼Œå–æ¶ˆæ­¢æŸè®¢å• %s", bracketLink.SLClientID)
		if err := s.cancelConditionalOrderIfNeeded(client, bracketLink.Symbol, bracketLink.SLClientID, "SL"); err != nil {
			log.Printf("[Bracket-Closure] å–æ¶ˆæ­¢æŸè®¢å•å¤±è´¥ %s: %v", bracketLink.SLClientID, err)
			// ä¸å› å–æ¶ˆå¤±è´¥è€Œä¸­æ–­æ•´ä¸ªæµç¨‹ï¼Œåªè®°å½•é”™è¯¯
		}
	} else if slTriggered && bracketLink.TPClientID != "" {
		// æ­¢æŸè§¦å‘ï¼Œå–æ¶ˆæ­¢ç›ˆè®¢å•
		log.Printf("[Bracket-Closure] æ­¢æŸå·²è§¦å‘ï¼Œå–æ¶ˆæ­¢ç›ˆè®¢å• %s", bracketLink.TPClientID)
		if err := s.cancelConditionalOrderIfNeeded(client, bracketLink.Symbol, bracketLink.TPClientID, "TP"); err != nil {
			log.Printf("[Bracket-Closure] å–æ¶ˆæ­¢ç›ˆè®¢å•å¤±è´¥ %s: %v", bracketLink.TPClientID, err)
			// ä¸å› å–æ¶ˆå¤±è´¥è€Œä¸­æ–­æ•´ä¸ªæµç¨‹ï¼Œåªè®°å½•é”™è¯¯
		}
	}

	// è·å–å®é™…æˆäº¤ä¿¡æ¯
	var executedQty, avgPrice string
	var triggeredOrderId string

	if tpTriggered {
		// ä»TPè®¢å•è·å–æˆäº¤ä¿¡æ¯
		tpStatus, err := client.QueryOrder(bracketLink.Symbol, bracketLink.TPClientID)
		if err == nil && tpStatus.Status == "FILLED" {
			executedQty = tpStatus.ExecutedQty
			avgPrice = tpStatus.AvgPrice
			triggeredOrderId = strconv.FormatInt(tpStatus.OrderId, 10)
		}
	} else if slTriggered {
		// ä»SLè®¢å•è·å–æˆäº¤ä¿¡æ¯
		slStatus, err := client.QueryOrder(bracketLink.Symbol, bracketLink.SLClientID)
		if err == nil && slStatus.Status == "FILLED" {
			executedQty = slStatus.ExecutedQty
			avgPrice = slStatus.AvgPrice
			triggeredOrderId = strconv.FormatInt(slStatus.OrderId, 10)
		}
	}

	// å¦‚æœæ— æ³•è·å–æˆäº¤ä¿¡æ¯ï¼Œä½¿ç”¨å¼€ä»“è®¢å•çš„æ•°é‡ä½œä¸ºé»˜è®¤å€¼
	if executedQty == "" {
		executedQty = entryOrder.AdjustedQuantity
	}
	if avgPrice == "" {
		// è·å–å½“å‰å¸‚åœºä»·æ ¼ä½œä¸ºè¿‘ä¼¼å€¼
		currentPrice, err := client.GetMarkPrice(bracketLink.Symbol)
		if err == nil && currentPrice > 0 {
			avgPrice = fmt.Sprintf("%.8f", currentPrice)
		} else {
			avgPrice = "0" // æ— æ³•è·å–ä»·æ ¼
		}
	}

	// åˆ›å»ºå¹³ä»“è®¢å•è®°å½•
	closeOrder := &pdb.ScheduledOrder{
		UserID:          entryOrder.UserID,
		Exchange:        entryOrder.Exchange,
		Testnet:         entryOrder.Testnet,
		Symbol:          bracketLink.Symbol,
		Side:            s.getCloseSide(entryOrder.Side), // æ ¹æ®å¼€ä»“æ–¹å‘ç¡®å®šå¹³ä»“æ–¹å‘
		OrderType:       "MARKET",
		Quantity:        executedQty, // ä½¿ç”¨å®é™…æˆäº¤æ•°é‡
		Leverage:        entryOrder.Leverage,
		ReduceOnly:      true, // å¹³ä»“è®¢å•å¿…é¡»æ˜¯reduce-only
		StrategyID:      entryOrder.StrategyID,
		ExecutionID:     entryOrder.ExecutionID,
		ParentOrderId:   entryOrder.ID, // å…³è”åˆ°å¼€ä»“è®¢å•
		Status:          "filled",      // æ ‡è®°ä¸ºå·²æˆäº¤
		BracketEnabled:  false,         // å¹³ä»“è®¢å•ä¸éœ€è¦bracket
		WorkingType:     entryOrder.WorkingType,
		TriggerTime:     time.Now(),
		ClientOrderId:   "",               // æ¡ä»¶è®¢å•æ²¡æœ‰æœ¬åœ°clientOrderId
		ExchangeOrderId: triggeredOrderId, // ä½¿ç”¨å®é™…çš„äº¤æ˜“æ‰€è®¢å•ID
		ExecutedQty:     executedQty,
		AvgPrice:        avgPrice,
		Result:          s.getCloseResult(tpTriggered, slTriggered),
	}

	// åˆ›å»ºå¹³ä»“è®¢å•
	if err := tx.Create(closeOrder).Error; err != nil {
		tx.Rollback()
		return fmt.Errorf("åˆ›å»ºå¹³ä»“è®¢å•å¤±è´¥: %w", err)
	}

	// æ›´æ–°BracketLinkçŠ¶æ€ä¸ºclosed
	if err := tx.Model(&pdb.BracketLink{}).Where("id = ?", bracketLink.ID).Update("status", "closed").Error; err != nil {
		tx.Rollback()
		return fmt.Errorf("æ›´æ–°BracketLinkçŠ¶æ€å¤±è´¥: %w", err)
	}

	// æ›´æ–°å¼€ä»“è®¢å•çš„close_order_idså­—æ®µ
	closeOrderIds := entryOrder.CloseOrderIds
	if closeOrderIds != "" {
		closeOrderIds += ","
	}
	closeOrderIds += strconv.FormatUint(uint64(closeOrder.ID), 10)

	if err := tx.Model(&pdb.ScheduledOrder{}).Where("id = ?", entryOrder.ID).Update("close_order_ids", closeOrderIds).Error; err != nil {
		tx.Rollback()
		return fmt.Errorf("æ›´æ–°å¼€ä»“è®¢å•close_order_idså¤±è´¥: %w", err)
	}

	// æäº¤äº‹åŠ¡
	if err := tx.Commit().Error; err != nil {
		return fmt.Errorf("æäº¤äº‹åŠ¡å¤±è´¥: %w", err)
	}

	log.Printf("[Order-Sync] Bracketè®¢å• %s å…³é—­å¤„ç†å®Œæˆï¼Œåˆ›å»ºå¹³ä»“è®¢å• %d", bracketLink.GroupID, closeOrder.ID)
	return nil
}

// getCloseSide æ ¹æ®å¼€ä»“æ–¹å‘è¿”å›å¹³ä»“æ–¹å‘
func (s *Server) getCloseSide(entrySide string) string {
	switch entrySide {
	case "BUY":
		return "SELL"
	case "SELL":
		return "BUY"
	default:
		return "SELL" // é»˜è®¤è¿”å›SELL
	}
}

// getCloseResult æ ¹æ®è§¦å‘ç±»å‹è¿”å›ç»“æœæè¿°
func (s *Server) getCloseResult(tpTriggered, slTriggered bool) string {
	if tpTriggered {
		return "æ­¢ç›ˆè§¦å‘"
	} else if slTriggered {
		return "æ­¢æŸè§¦å‘"
	}
	return "æ¡ä»¶å¹³ä»“"
}

// initBacktestEngine åˆå§‹åŒ–å›æµ‹å¼•æ“ï¼ˆæ ¸å¿ƒæœåŠ¡æ¨¡å—ï¼‰
func (s *Server) initBacktestEngine() {
	log.Printf("[INIT] åˆå§‹åŒ–å›æµ‹å¼•æ“ï¼ˆæ ¸å¿ƒæœåŠ¡ï¼‰...")

	// ç¡®ä¿å¿…è¦çš„ä¾èµ–å·²åˆå§‹åŒ–
	if s.db == nil {
		log.Printf("[ERROR] æ•°æ®åº“æœªåˆå§‹åŒ–ï¼Œæ— æ³•å¯åŠ¨å›æµ‹å¼•æ“")
		return
	}
	if s.dataManager == nil {
		log.Printf("[ERROR] æ•°æ®ç®¡ç†å™¨æœªåˆå§‹åŒ–ï¼Œæ— æ³•å¯åŠ¨å›æµ‹å¼•æ“")
		return
	}

	// æ£€æŸ¥AIåˆ†ææ¨¡å—æ˜¯å¦å·²å¯ç”¨
	aiEnabled := s.machineLearning != nil && s.coinSelectionAlgorithm != nil
	if aiEnabled {
		log.Printf("[INIT] æ£€æµ‹åˆ°AIåˆ†ææ¨¡å—å·²å¯ç”¨ï¼Œå›æµ‹å¼•æ“å°†ä½¿ç”¨å¢å¼ºåŠŸèƒ½æ¨¡å¼")
	} else {
		log.Printf("[INIT] AIåˆ†ææ¨¡å—æœªå¯ç”¨ï¼Œå›æµ‹å¼•æ“å°†ä½¿ç”¨åŸºç¡€åŠŸèƒ½æ¨¡å¼")
	}

	// åˆå§‹åŒ–é›†æˆæ¨¡å‹ï¼ˆå¦‚æœæœªåˆå§‹åŒ–ï¼‰
	if s.ensembleModels == nil {
		s.ensembleModels = make(map[string]*EnsemblePredictor)
		log.Printf("[INIT] åˆå§‹åŒ–ç©ºçš„é›†æˆæ¨¡å‹é›†åˆ")
	}

	// åˆ›å»ºå›æµ‹å¼•æ“ï¼ˆæœºå™¨å­¦ä¹ æ¨¡å—å¯ä»¥ä¸ºnilï¼Œä»£ç ä¸­æœ‰ä¿æŠ¤æªæ–½ï¼‰
	s.backtestEngine = NewBacktestEngine(s.db, s.dataManager, s.ensembleModels, s, s.machineLearning)
	if s.backtestEngine == nil {
		log.Printf("[WARN] å›æµ‹å¼•æ“åˆå§‹åŒ–å¤±è´¥ï¼Œå°†ä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬")
		return
	}

	// åˆå§‹åŒ–ç­–ç•¥å›æµ‹å¼•æ“
	s.strategyBacktestEngine = NewStrategyBacktestEngine(s.db, s.dataManager)
	if s.strategyBacktestEngine == nil {
		log.Printf("[WARN] ç­–ç•¥å›æµ‹å¼•æ“åˆå§‹åŒ–å¤±è´¥")
		return
	}

	if aiEnabled {
		log.Printf("[INIT] å›æµ‹å¼•æ“åˆå§‹åŒ–å®Œæˆ - å¢å¼ºåŠŸèƒ½æ¨¡å¼ï¼ˆæ”¯æŒAIé¢„æµ‹ï¼‰")
	} else {
		log.Printf("[INIT] å›æµ‹å¼•æ“åˆå§‹åŒ–å®Œæˆ - åŸºç¡€åŠŸèƒ½æ¨¡å¼ï¼ˆä¼ ç»Ÿå›æµ‹ï¼‰")
	}
}

// initAnalysisModule åˆå§‹åŒ–æ™ºèƒ½æŠ•ç ”æ¨¡å—
func (s *Server) initAnalysisModule() {
	log.Printf("[INIT] å¼€å§‹åˆå§‹åŒ–AIåˆ†ææ¨¡å—...")

	// åˆå§‹åŒ–æ–°ä¸€ä»£é€‰å¸ç®—æ³•
	log.Printf("[INIT] åˆå§‹åŒ–é€‰å¸ç®—æ³•...")
	algoConfig := DefaultAlgorithmConfig()
	s.coinSelectionAlgorithm = NewCoinSelectionAlgorithm(algoConfig)
	if s.coinSelectionAlgorithm == nil {
		log.Printf("[ERROR] é€‰å¸ç®—æ³•åˆå§‹åŒ–å¤±è´¥")
		return
	}
	log.Printf("[INIT] é€‰å¸ç®—æ³•åˆå§‹åŒ–å®Œæˆ")

	// â­ åˆå§‹åŒ–ç‰¹å¾å·¥ç¨‹æ¨¡å—å¹¶é›†æˆåˆ°é€‰å¸ç®—æ³•
	log.Printf("[INIT] åˆå§‹åŒ–ç‰¹å¾å·¥ç¨‹æ¨¡å—...")
	featureConfig := FeatureConfig{
		TimeSeriesWindow:    100,
		VolatilityWindow:    20,
		TrendWindow:         50,
		EnableCrossFeatures: true,
		CacheExpiry:         10 * time.Minute,
		MaxConcurrency:      5,
		BatchSize:           10,
	}
	s.featureEngineering = NewFeatureEngineering(s.db, s.dataFusion, featureConfig)
	// æš‚æ—¶ä¸è®¾ç½®é¢„è®¡ç®—æœåŠ¡å¼•ç”¨ï¼Œç¨ååœ¨é¢„è®¡ç®—æœåŠ¡åˆå§‹åŒ–åå†è®¾ç½®
	if s.featureEngineering == nil {
		log.Printf("[ERROR] ç‰¹å¾å·¥ç¨‹æ¨¡å—åˆå§‹åŒ–å¤±è´¥")
		return
	}
	log.Printf("[INIT] ç‰¹å¾å·¥ç¨‹æ¨¡å—åˆå§‹åŒ–å®Œæˆ")

	// è®¾ç½®ç‰¹å¾å·¥ç¨‹ä¾èµ–å…³ç³»ï¼ˆæœºå™¨å­¦ä¹ å’Œé£é™©ç®¡ç†ç¨åè®¾ç½®ï¼‰
	s.coinSelectionAlgorithm.SetFeatureEngineering(s.featureEngineering)

	log.Printf("[INIT] é€‰å¸ç®—æ³•å’Œç‰¹å¾å·¥ç¨‹åˆå§‹åŒ–å®Œæˆ")

	// åˆå§‹åŒ–æ•°æ®é¢„å¤„ç†å’Œç¼“å­˜ç³»ç»Ÿ
	log.Printf("[INIT] åˆå§‹åŒ–æ•°æ®é¢„å¤„ç†å’Œç¼“å­˜ç³»ç»Ÿ...")
	s.dataCache = NewBacktestDataCache()
	s.dataUpdateService = NewDataUpdateService(s.dataCache, NewDataPreprocessor(), s)

	// å¯åŠ¨æ•°æ®æ›´æ–°æœåŠ¡
	if err := s.dataUpdateService.Start(); err != nil {
		log.Printf("[ERROR] æ•°æ®æ›´æ–°æœåŠ¡å¯åŠ¨å¤±è´¥: %v", err)
	} else {
		log.Printf("[INIT] æ•°æ®æ›´æ–°æœåŠ¡å¯åŠ¨æˆåŠŸ")
	}
	log.Printf("[INIT] æ•°æ®é¢„å¤„ç†å’Œç¼“å­˜ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")

	// åˆå§‹åŒ–ç‰¹å¾é¢„è®¡ç®—æœåŠ¡
	log.Printf("[INIT] åˆå§‹åŒ–ç‰¹å¾é¢„è®¡ç®—æœåŠ¡...")
	s.featurePrecomputeService = NewFeaturePrecomputeService(s.featureEngineering, s)

	// å°†é¢„è®¡ç®—æœåŠ¡å¼•ç”¨è®¾ç½®ç»™ç‰¹å¾å·¥ç¨‹
	if s.featureEngineering != nil {
		s.featureEngineering.precomputeService = s.featurePrecomputeService
	}

	// å¯åŠ¨ç‰¹å¾é¢„è®¡ç®—æœåŠ¡
	if err := s.featurePrecomputeService.Start(); err != nil {
		log.Printf("[ERROR] ç‰¹å¾é¢„è®¡ç®—æœåŠ¡å¯åŠ¨å¤±è´¥: %v", err)
	} else {
		log.Printf("[INIT] ç‰¹å¾é¢„è®¡ç®—æœåŠ¡å¯åŠ¨æˆåŠŸ")
	}
	log.Printf("[INIT] ç‰¹å¾é¢„è®¡ç®—æœåŠ¡åˆå§‹åŒ–å®Œæˆ")

	// åˆå§‹åŒ–æŠ€æœ¯æŒ‡æ ‡é¢„è®¡ç®—æœåŠ¡
	log.Printf("[INIT] åˆå§‹åŒ–æŠ€æœ¯æŒ‡æ ‡é¢„è®¡ç®—æœåŠ¡...")
	s.technicalIndicatorsPrecomputeService = NewTechnicalIndicatorsPrecomputeService(s)

	// å¯åŠ¨æŠ€æœ¯æŒ‡æ ‡é¢„è®¡ç®—æœåŠ¡
	if err := s.technicalIndicatorsPrecomputeService.Start(); err != nil {
		log.Printf("[ERROR] æŠ€æœ¯æŒ‡æ ‡é¢„è®¡ç®—æœåŠ¡å¯åŠ¨å¤±è´¥: %v", err)
	} else {
		log.Printf("[INIT] æŠ€æœ¯æŒ‡æ ‡é¢„è®¡ç®—æœåŠ¡å¯åŠ¨æˆåŠŸ")
	}
	log.Printf("[INIT] æŠ€æœ¯æŒ‡æ ‡é¢„è®¡ç®—æœåŠ¡åˆå§‹åŒ–å®Œæˆ")

	// â­ åˆå§‹åŒ–æœºå™¨å­¦ä¹ æ¨¡å—ï¼ˆåœ¨é¢„è®­ç»ƒæœåŠ¡ä¹‹å‰ï¼‰
	log.Printf("[INIT] åˆå§‹åŒ–æœºå™¨å­¦ä¹ æ¨¡å—...")
	mlConfig := MLConfig{
		FeatureSelection: struct {
			Method               string  `json:"method"`
			MaxFeatures          int     `json:"max_features"`
			MinImportance        float64 `json:"min_importance"`
			CrossValidationFolds int     `json:"cross_validation_folds"`
		}{
			Method:               "recursive",
			MaxFeatures:          50,
			MinImportance:        0.01,
			CrossValidationFolds: 5,
		},

		OnlineLearning: DefaultOnlineLearningConfig(),

		Ensemble: struct {
			Method       string  `json:"method"`
			NEstimators  int     `json:"n_estimators"`
			MaxDepth     int     `json:"max_depth"`
			LearningRate float64 `json:"learning_rate"`
		}{
			Method:      "random_forest",
			NEstimators: 10,
			MaxDepth:    12,
		},

		DeepLearning: struct {
			HiddenLayers []int   `json:"hidden_layers"`
			DropoutRate  float64 `json:"dropout_rate"`
			LearningRate float64 `json:"learning_rate"`
			BatchSize    int     `json:"batch_size"`
			Epochs       int     `json:"epochs"`
			FeatureDim   int     `json:"feature_dim"`
		}{
			HiddenLayers: []int{64, 32, 16},
			DropoutRate:  0.2,
			LearningRate: 0.001,
			BatchSize:    32,
			Epochs:       50,
			FeatureDim:   20, // è®¾ç½®ä¸º20ï¼Œä¸ç‰¹å¾æ˜ å°„ä¸€è‡´
		},

		Transformer: struct {
			NumLayers int     `json:"num_layers"`
			NumHeads  int     `json:"num_heads"`
			DModel    int     `json:"d_model"`
			DFF       int     `json:"dff"`
			Dropout   float64 `json:"dropout"`
		}{
			NumLayers: 6,
			NumHeads:  8,
			DModel:    512,
			DFF:       2048,
			Dropout:   0.1,
		},

		Training: struct {
			ValidationSplit    float64       `json:"validation_split"`
			EarlyStopping      bool          `json:"early_stopping"`
			Patience           int           `json:"patience"`
			SaveBestModel      bool          `json:"save_best_model"`
			RetrainingInterval time.Duration `json:"retraining_interval"`
		}{
			ValidationSplit:    0.2,
			EarlyStopping:      true,
			Patience:           10,
			SaveBestModel:      true,
			RetrainingInterval: 24 * time.Hour,
		},
	}
	s.machineLearning = NewMachineLearning(s.featureEngineering, s.db, mlConfig, s)
	if s.machineLearning == nil {
		log.Printf("[ERROR] æœºå™¨å­¦ä¹ æ¨¡å—åˆå§‹åŒ–å¤±è´¥")
		return
	}
	log.Printf("[INIT] æœºå™¨å­¦ä¹ æ¨¡å—åˆå§‹åŒ–å®Œæˆ")

	// åˆå§‹åŒ–MLæ¨¡å‹é¢„è®­ç»ƒæœåŠ¡
	log.Printf("[INIT] åˆå§‹åŒ–MLæ¨¡å‹é¢„è®­ç»ƒæœåŠ¡...")
	s.mlPretrainingService = NewMLPretrainingService(s)

	// å¯åŠ¨MLæ¨¡å‹é¢„è®­ç»ƒæœåŠ¡
	if err := s.mlPretrainingService.Start(); err != nil {
		log.Printf("[ERROR] MLæ¨¡å‹é¢„è®­ç»ƒæœåŠ¡å¯åŠ¨å¤±è´¥: %v", err)
	} else {
		log.Printf("[INIT] MLæ¨¡å‹é¢„è®­ç»ƒæœåŠ¡å¯åŠ¨æˆåŠŸ")
	}
	log.Printf("[INIT] MLæ¨¡å‹é¢„è®­ç»ƒæœåŠ¡åˆå§‹åŒ–å®Œæˆ")

	// OrderSchedulerå·²åœ¨Server.New()ä¸­åˆå§‹åŒ–

	// â­ åˆå§‹åŒ–é£é™©ç®¡ç†æ¨¡å—
	log.Printf("[INIT] åˆå§‹åŒ–é£é™©ç®¡ç†æ¨¡å—...")
	riskConfig := RiskConfig{
		Assessment: struct {
			MaxRiskScore   float64       `json:"max_risk_score"`
			RiskThreshold  float64       `json:"risk_threshold"`
			UpdateInterval time.Duration `json:"update_interval"`
			HistoryWindow  int           `json:"history_window"`
		}{
			MaxRiskScore:   100.0,
			RiskThreshold:  70.0,
			UpdateInterval: 1 * time.Hour,
			HistoryWindow:  30,
		},
		Control: struct {
			EnablePositionLimits bool      `json:"enable_position_limits"`
			MaxPositionSize      float64   `json:"max_position_size"`
			MaxDrawdownLimit     float64   `json:"max_drawdown_limit"`
			DiversificationMin   int       `json:"diversification_min"`
			StopLossLevels       []float64 `json:"stop_loss_levels"`
		}{
			EnablePositionLimits: true,
			MaxPositionSize:      0.1,
			MaxDrawdownLimit:     0.2,
			DiversificationMin:   5,
			StopLossLevels:       []float64{0.05, 0.1, 0.15},
		},
		Monitoring: struct {
			AlertThresholds    map[string]float64 `json:"alert_thresholds"`
			MonitoringInterval time.Duration      `json:"monitoring_interval"`
			ReportInterval     time.Duration      `json:"report_interval"`
			EnableRealTime     bool               `json:"enable_real_time"`
		}{
			AlertThresholds: map[string]float64{
				"high_risk":  80.0,
				"critical":   90.0,
				"drawdown":   0.15,
				"volatility": 0.3,
			},
			MonitoringInterval: 5 * time.Minute,
			ReportInterval:     1 * time.Hour,
			EnableRealTime:     true,
		},
		RiskWeights: struct {
			VolatilityWeight  float64 `json:"volatility_weight"`
			LiquidityWeight   float64 `json:"liquidity_weight"`
			MarketRiskWeight  float64 `json:"market_risk_weight"`
			CreditRiskWeight  float64 `json:"credit_risk_weight"`
			OperationalWeight float64 `json:"operational_weight"`
		}{
			VolatilityWeight:  0.3,
			LiquidityWeight:   0.2,
			MarketRiskWeight:  0.25,
			CreditRiskWeight:  0.15,
			OperationalWeight: 0.1,
		},
	}

	s.riskManagement = NewRiskManagement(s.featureEngineering, s.machineLearning, s.db, riskConfig)
	if s.riskManagement == nil {
		log.Printf("[ERROR] é£é™©ç®¡ç†æ¨¡å—åˆå§‹åŒ–å¤±è´¥")
		return
	}
	log.Printf("[INIT] é£é™©ç®¡ç†æ¨¡å—åˆå§‹åŒ–å®Œæˆ")

	// ç°åœ¨æ‰€æœ‰ç»„ä»¶éƒ½å·²åˆå§‹åŒ–ï¼Œè®¾ç½®å®Œæ•´çš„ä¾èµ–å…³ç³»
	s.coinSelectionAlgorithm.SetMachineLearning(s.machineLearning)
	s.coinSelectionAlgorithm.SetRiskManagement(s.riskManagement)

	log.Printf("[INIT] AIåˆ†ææ¨¡å—ä¾èµ–å…³ç³»è®¾ç½®å®Œæˆ")

	// åˆå§‹åŒ–æ•°æ®è´¨é‡ç›‘æ§å™¨
	alertThresholds := AlertThresholds{
		MaxFreshnessSeconds:    3600, // 1å°æ—¶
		MinCompletenessPercent: 70.0, // 70%
		MaxErrorRatePercent:    20.0, // 20%
		MinAccuracyPercent:     80.0, // 80%
	}
	s.dataQualityMonitor = NewDataQualityMonitor(s.db, alertThresholds)

	// æ·»åŠ å‘Šè­¦å›è°ƒï¼ˆè®°å½•åˆ°æ—¥å¿—ï¼‰
	alertCallback := func(anomaly DataAnomaly) {
		log.Printf("[DataQualityAlert] %s - %s: %s", anomaly.Severity, anomaly.Type, anomaly.Description)
	}
	s.dataQualityMonitor.AddAlertCallback(alertCallback)

	// å¯åŠ¨æ•°æ®è´¨é‡ç›‘æ§
	go s.dataQualityMonitor.StartMonitoring()

	// åˆå§‹åŒ–CoinGeckoå…è´¹APIå®¢æˆ·ç«¯
	s.coinGeckoClient = NewCoinGeckoClient()

	// åˆå§‹åŒ–NewsAPIå®¢æˆ·ç«¯ï¼ˆå¦‚æœé…ç½®äº†API keyï¼‰
	if s.cfg.DataSources.NewsAPI.APIKey != "" {
		s.newsAPIClient = NewNewsAPIClient(s.cfg.DataSources.NewsAPI.APIKey)
		log.Printf("[Server] NewsAPIå®¢æˆ·ç«¯å·²åˆå§‹åŒ–")
	} else {
		log.Printf("[Server] NewsAPIæœªé…ç½®ï¼Œå°†ä½¿ç”¨é»˜è®¤å…¬å‘Šæ•°æ®")
	}

	// åˆå§‹åŒ–æ•°æ®èåˆå™¨
	s.dataFusion = NewDataFusion(s, s.coinGeckoClient)

	// åˆå§‹åŒ–æ•°æ®éªŒè¯å™¨ï¼ˆéä¸¥æ ¼æ¨¡å¼ï¼‰
	s.dataValidator = NewDataValidator(false)

	// åˆå§‹åŒ–é™çº§ç­–ç•¥ï¼ˆä½¿ç”¨é…ç½®ï¼‰
	fallbackConfig := DefaultFallbackConfig()
	if s.cfg.DataQuality.Fallback.System.Enabled {
		fallbackConfig.EnableAutoFallback = s.cfg.DataQuality.Fallback.System.Enabled
	}
	if s.cfg.DataQuality.Fallback.System.HealthCheckInterval > 0 {
		fallbackConfig.HealthCheckInterval = s.cfg.DataQuality.Fallback.System.HealthCheckInterval
	}
	if s.cfg.DataQuality.Fallback.System.MaxHistorySize > 0 {
		fallbackConfig.MaxHistorySize = s.cfg.DataQuality.Fallback.System.MaxHistorySize
	}

	// è®¾ç½®å‘Šè­¦é˜ˆå€¼
	if s.cfg.DataQuality.AlertThresholds.MaxFreshnessSeconds > 0 {
		fallbackConfig.ComponentThresholds = map[string]int{
			"database":       3,
			"coingecko":      5,
			"newsapi":        10,
			"twitter":        5,
			"recommendation": 3,
		}
	}

	s.fallbackStrategy = NewFallbackStrategy(fallbackConfig)
	s.fallbackProvider = &DefaultFallbackProvider{}

	// å¯åŠ¨é™çº§ç­–ç•¥è‡ªåŠ¨è°ƒæ•´
	go s.startFallbackMonitoring()

	// åˆå§‹åŒ–åˆ†å±‚ç¼“å­˜ç³»ç»Ÿ
	s.initLayeredCache()

	// åˆå§‹åŒ–æ•°æ®é¢„åŠ è½½æœåŠ¡
	s.initDataPreloader()

	// åˆå§‹åŒ–è‡ªé€‚åº”æƒé‡æ§åˆ¶å™¨
	log.Printf("[INIT] åˆå§‹åŒ–è‡ªé€‚åº”æƒé‡æ§åˆ¶å™¨...")
	s.weightController = NewAdaptiveWeightController()
	log.Printf("[INIT] è‡ªé€‚åº”æƒé‡æ§åˆ¶å™¨åˆå§‹åŒ–å®Œæˆ")
}

// startFallbackMonitoring å¯åŠ¨é™çº§ç­–ç•¥ç›‘æ§
func (s *Server) startFallbackMonitoring() {
	log.Printf("[Server] å¯åŠ¨é™çº§ç­–ç•¥ç›‘æ§")

	ticker := time.NewTicker(30 * time.Second) // æ¯30ç§’æ£€æŸ¥ä¸€æ¬¡
	defer ticker.Stop()

	for {
		select {
		case <-ticker.C:
			// è‡ªåŠ¨è°ƒæ•´é™çº§çº§åˆ«
			s.fallbackStrategy.AutoAdjustLevel()

			// æ£€æŸ¥å…³é”®ç»„ä»¶çŠ¶æ€
			s.checkComponentHealth()
		}
	}
}

// checkComponentHealth æ£€æŸ¥ç»„ä»¶å¥åº·çŠ¶æ€
func (s *Server) checkComponentHealth() {
	// æ£€æŸ¥æ•°æ®åº“è¿æ¥
	sqlDB, err := s.db.DB().DB()
	if err != nil {
		s.fallbackStrategy.RecordComponentFailure("database")
		return
	}
	if err := sqlDB.Ping(); err != nil {
		s.fallbackStrategy.RecordComponentFailure("database")
	} else {
		s.fallbackStrategy.RecordComponentSuccess("database")
	}

	// æ£€æŸ¥CoinGecko API
	if s.coinGeckoClient != nil {
		if err := s.coinGeckoClient.Ping(context.Background()); err != nil {
			s.fallbackStrategy.RecordComponentFailure("coingecko")
		} else {
			s.fallbackStrategy.RecordComponentSuccess("coingecko")
		}
	}

	// æ£€æŸ¥NewsAPIï¼ˆå¦‚æœé…ç½®äº†ï¼‰
	if s.newsAPIClient != nil {
		// ç®€å•æ£€æŸ¥å‰©ä½™è¯·æ±‚æ¬¡æ•°
		if s.newsAPIClient.GetRemainingRequests() <= 10 {
			s.fallbackStrategy.RecordComponentFailure("newsapi")
		} else {
			s.fallbackStrategy.RecordComponentSuccess("newsapi")
		}
	}
}

// initDataPreloader åˆå§‹åŒ–æ•°æ®é¢„åŠ è½½æœåŠ¡
func (s *Server) initDataPreloader() {
	config := DefaultDataPreloaderConfig()
	s.dataPreloader = NewDataPreloader(s, config)

	if err := s.dataPreloader.Start(); err != nil {
		log.Printf("[ERROR] Failed to start data preloader: %v", err)
		return
	}
}

// initLayeredCache åˆå§‹åŒ–åˆ†å±‚ç¼“å­˜ç³»ç»Ÿ
func (s *Server) initLayeredCache() {
	cacheConfig := CacheConfig{
		// L1é…ç½®
		L1Enabled: true,
		L1MaxSize: 10000, // å†…å­˜ç¼“å­˜æœ€å¤§10000æ¡
		L1TTL:     15 * time.Minute,

		// L2é…ç½®
		L2Enabled: true,
		L2TTL:     1 * time.Hour,

		// L3é…ç½®
		L3Enabled: true,
		L3TTL:     24 * time.Hour,

		// é¢„çƒ­é…ç½®
		WarmupEnabled:     true,
		WarmupInterval:    30 * time.Minute,
		WarmupConcurrency: 5,

		// å¤±æ•ˆé…ç½®
		InvalidationEnabled: true,
		InvalidationBuffer:  100,

		// ç›‘æ§é…ç½®
		MetricsEnabled:  true,
		MetricsInterval: 5 * time.Minute,
	}

	s.layeredCache = NewLayeredCache(s.cache, s.db, cacheConfig)
	log.Printf("[Server] åˆ†å±‚ç¼“å­˜ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
}

// NewWithGorm ä» GORM DB åˆ›å»º Server å®ä¾‹ï¼ˆå‘åå…¼å®¹ï¼‰
func NewWithGorm(gdb *gorm.DB) *Server {
	return &Server{db: NewGormDatabase(gdb)}
}

// æ³¨æ„ï¼šSmartSchedulerå·²ç§»è‡³ç‹¬ç«‹çš„investmentæœåŠ¡

// GetLayeredCache è·å–åˆ†å±‚ç¼“å­˜å®ä¾‹
func (s *Server) GetLayeredCache() *LayeredCache {
	return s.layeredCache
}

// SetCache è®¾ç½®ç¼“å­˜
func (s *Server) SetCache(cache pdb.CacheInterface) {
	s.cache = cache
}

// warmupCaches ç¼“å­˜é¢„çƒ­
func (s *Server) warmupCaches(ctx context.Context) error {
	log.Printf("[Server] å¼€å§‹ç¼“å­˜é¢„çƒ­...")

	// é¢„çƒ­æ¨èæ•°æ®
	if err := s.warmupRecommendationCache(ctx); err != nil {
		log.Printf("[Server] æ¨èç¼“å­˜é¢„çƒ­å¤±è´¥: %v", err)
	}

	// é¢„çƒ­æ€§èƒ½ç»Ÿè®¡æ•°æ®
	if err := s.warmupPerformanceStatsCache(ctx); err != nil {
		log.Printf("[Server] æ€§èƒ½ç»Ÿè®¡ç¼“å­˜é¢„çƒ­å¤±è´¥: %v", err)
	}

	// é¢„çƒ­å¸‚åœºæ•°æ®
	if err := s.warmupMarketDataCache(ctx); err != nil {
		log.Printf("[Server] å¸‚åœºæ•°æ®ç¼“å­˜é¢„çƒ­å¤±è´¥: %v", err)
	}

	log.Printf("[Server] ç¼“å­˜é¢„çƒ­å®Œæˆ")
	return nil
}

// warmupRecommendationCache é¢„çƒ­æ¨èç¼“å­˜
func (s *Server) warmupRecommendationCache(ctx context.Context) error {
	// è·å–æœ€æ–°çš„æ¨èæ•°æ®
	recommendations, err := pdb.GetLatestRecommendations(s.db.DB(), "spot", 50)
	if err != nil {
		return fmt.Errorf("è·å–æ¨èæ•°æ®å¤±è´¥: %w", err)
	}

	// æ‰¹é‡å†™å…¥ç¼“å­˜
	for _, rec := range recommendations {
		key := GenerateCacheKey("recommendations", "detail", map[string]interface{}{
			"id": rec.ID,
		})

		if s.layeredCache != nil {
			s.layeredCache.Set(ctx, key, rec, 1*time.Hour)
		}
	}

	log.Printf("[Server] é¢„çƒ­äº† %d æ¡æ¨èæ•°æ®", len(recommendations))
	return nil
}

// warmupPerformanceStatsCache é¢„çƒ­æ€§èƒ½ç»Ÿè®¡ç¼“å­˜
func (s *Server) warmupPerformanceStatsCache(ctx context.Context) error {
	// è·å–æ€§èƒ½ç»Ÿè®¡æ•°æ®
	stats, err := pdb.GetPerformanceStats(s.db.DB(), 30)
	if err != nil {
		return fmt.Errorf("è·å–æ€§èƒ½ç»Ÿè®¡å¤±è´¥: %w", err)
	}

	key := GenerateCacheKey("performance", "stats", map[string]interface{}{
		"days": 30,
	})

	if s.layeredCache != nil {
		s.layeredCache.Set(ctx, key, stats, 30*time.Minute)
	}

	log.Printf("[Server] é¢„çƒ­äº†æ€§èƒ½ç»Ÿè®¡æ•°æ®")
	return nil
}

// warmupMarketDataCache é¢„çƒ­å¸‚åœºæ•°æ®ç¼“å­˜
func (s *Server) warmupMarketDataCache(ctx context.Context) error {
	// è¿™é‡Œå¯ä»¥é¢„çƒ­å¸¸ç”¨çš„å¸‚åœºæ•°æ®
	// ä¸ºäº†ç®€åŒ–ï¼Œè¿™é‡Œåªè®°å½•æ—¥å¿—
	log.Printf("[Server] é¢„çƒ­äº†å¸‚åœºæ•°æ®ç¼“å­˜")
	return nil
}

// cleanupExpiredData æ¸…ç†è¿‡æœŸæ•°æ®
func (s *Server) cleanupExpiredData(ctx context.Context) error {
	log.Printf("[Server] å¼€å§‹æ¸…ç†è¿‡æœŸæ•°æ®...")

	// æ¸…ç†è¿‡æœŸçš„æ¨èæ•°æ®ï¼ˆä¿ç•™æœ€è¿‘30å¤©ï¼‰
	thirtyDaysAgo := time.Now().AddDate(0, 0, -30)

	// åˆ é™¤30å¤©å‰çš„æ¨èæ•°æ®
	if err := s.db.DB().Where("generated_at < ?", thirtyDaysAgo).Delete(&pdb.CoinRecommendation{}).Error; err != nil {
		log.Printf("[Server] æ¸…ç†è¿‡æœŸæ¨èæ•°æ®å¤±è´¥: %v", err)
	} else {
		log.Printf("[Server] æ¸…ç†äº†è¿‡æœŸæ¨èæ•°æ®")
	}

	// æ¸…ç†è¿‡æœŸçš„è¡¨ç°è¿½è¸ªæ•°æ®ï¼ˆä¿ç•™æœ€è¿‘90å¤©ï¼‰
	ninetyDaysAgo := time.Now().AddDate(0, 0, -90)

	if err := s.db.DB().Where("created_at < ?", ninetyDaysAgo).Delete(&pdb.RecommendationPerformance{}).Error; err != nil {
		log.Printf("[Server] æ¸…ç†è¿‡æœŸè¡¨ç°æ•°æ®å¤±è´¥: %v", err)
	} else {
		log.Printf("[Server] æ¸…ç†äº†è¿‡æœŸè¡¨ç°æ•°æ®")
	}

	// æ¸…ç†åˆ†å±‚ç¼“å­˜ä¸­çš„è¿‡æœŸæ•°æ®
	if s.layeredCache != nil {
		// è¿™é‡Œå¯ä»¥æ·»åŠ ç¼“å­˜æ¸…ç†é€»è¾‘
		log.Printf("[Server] æ¸…ç†äº†è¿‡æœŸç¼“å­˜æ•°æ®")
	}

	log.Printf("[Server] è¿‡æœŸæ•°æ®æ¸…ç†å®Œæˆ")
	return nil
}

// GET /entities
func (s *Server) ListEntities(c *gin.Context) {
	ents, err := s.db.ListEntities()
	if err != nil {
		s.DatabaseError(c, "æŸ¥è¯¢å®ä½“åˆ—è¡¨", err)
		return
	}
	c.JSON(http.StatusOK, gin.H{"entities": ents})
}

// GET /runs?entity=&page=1&page_size=50
func (s *Server) ListRuns(c *gin.Context) {
	entity := strings.TrimSpace(c.Query("entity"))

	// åˆ†é¡µå‚æ•°
	pagination := ParsePaginationParams(
		c.Query("page"),
		c.Query("page_size"),
		50,  // é»˜è®¤æ¯é¡µæ•°é‡
		200, // æœ€å¤§æ¯é¡µæ•°é‡
	)

	// æœç´¢å’Œè¿‡æ»¤å‚æ•°
	keyword := strings.TrimSpace(c.Query("keyword"))
	startDate := strings.TrimSpace(c.Query("start_date"))
	endDate := strings.TrimSpace(c.Query("end_date"))

	// ä½¿ç”¨æ¥å£æ–¹æ³•æŸ¥è¯¢
	params := PortfolioSnapshotQueryParams{
		Entity:           entity,
		Keyword:          keyword,
		StartDate:        startDate,
		EndDate:          endDate,
		PaginationParams: pagination,
	}

	snaps, total, err := s.db.ListPortfolioSnapshots(params)
	if err != nil {
		s.DatabaseError(c, "æŸ¥è¯¢è¿è¡Œè®°å½•", err)
		return
	}

	type runItem struct {
		RunID    string    `json:"run_id"`
		Entity   string    `json:"entity"`
		AsOf     time.Time `json:"as_of"`
		Created  time.Time `json:"created_at"`
		TotalUSD string    `json:"total_usd"`
	}
	out := make([]runItem, 0, len(snaps))
	for _, s2 := range snaps {
		out = append(out, runItem{
			RunID:    s2.RunID,
			Entity:   s2.Entity,
			AsOf:     s2.AsOf,
			Created:  s2.CreatedAt,
			TotalUSD: s2.TotalUSD,
		})
	}

	// è®¡ç®—æ€»é¡µæ•°
	totalPages := int((total + int64(pagination.PageSize) - 1) / int64(pagination.PageSize))
	if totalPages == 0 {
		totalPages = 1
	}

	c.JSON(http.StatusOK, gin.H{
		"items":       out,
		"total":       total,
		"page":        pagination.Page,
		"page_size":   pagination.PageSize,
		"total_pages": totalPages,
		// å…¼å®¹å­—æ®µ
		"runs": out,
	})
}

// â€”â€” helper â€”â€” //
func (s *Server) latestRunID(entity string) (string, *pdb.PortfolioSnapshot, error) {
	snap, err := s.db.GetLatestPortfolioSnapshot(entity)
	if err != nil {
		return "", nil, err
	}
	return snap.RunID, snap, nil
}

// GET /portfolio/latest?entity=binance
func (s *Server) GetLatestPortfolio(c *gin.Context) {
	entity := strings.TrimSpace(c.Query("entity"))
	if entity == "" {
		s.ValidationError(c, "entity", "å®ä½“åç§°ä¸èƒ½ä¸ºç©º")
		return
	}

	// å°è¯•ä½¿ç”¨ç¼“å­˜
	if s.cache != nil {
		// å…ˆè·å–æœ€æ–°çš„ runID
		runID, _, err := s.latestRunID(entity)
		if err != nil {
			s.NotFound(c, "æœªæ‰¾åˆ°è¯¥å®ä½“çš„å¿«ç…§æ•°æ®")
			return
		}

		// å°è¯•ä»ç¼“å­˜è·å–
		key := BuildCacheKey("cache:portfolio:latest", entity, runID)
		cached, err := s.cache.Get(c.Request.Context(), key)
		if err == nil && len(cached) > 0 {
			var cachedData struct {
				Snapshot pdb.PortfolioSnapshot `json:"snapshot"`
				Holdings []pdb.Holding         `json:"holdings"`
			}
			if err := json.Unmarshal(cached, &cachedData); err == nil {
				// è¿”å›ç¼“å­˜æ•°æ®
				holdings := make([]HoldingDTO, 0, len(cachedData.Holdings))
				for _, h := range cachedData.Holdings {
					holdings = append(holdings, HoldingDTO{
						Chain: h.Chain, Symbol: h.Symbol, Decimals: h.Decimals,
						Amount: h.Amount, ValueUSD: atofDef(h.ValueUSD, 0),
					})
				}
				c.JSON(http.StatusOK, gin.H{
					"entity":    entity,
					"run_id":    runID,
					"as_of":     cachedData.Snapshot.AsOf,
					"total_usd": atofDef(cachedData.Snapshot.TotalUSD, 0),
					"holdings":  holdings,
				})
				return
			}
		}
	}

	// ç¼“å­˜æœªå‘½ä¸­ï¼ŒæŸ¥è¯¢æ•°æ®åº“
	runID, snap, err := s.latestRunID(entity)
	if err != nil {
		s.NotFound(c, "æœªæ‰¾åˆ°è¯¥å®ä½“çš„å¿«ç…§æ•°æ®")
		return
	}

	// ä½¿ç”¨æ¥å£æ–¹æ³•æŸ¥è¯¢æŒä»“
	startTime := time.Now()
	hs, err := s.db.GetHoldingsByRunID(runID, entity)
	if err != nil {
		s.DatabaseError(c, "æŸ¥è¯¢æŒä»“æ•°æ®", err)
		return
	}
	duration := time.Since(startTime)

	// è®°å½•æ…¢æŸ¥è¯¢
	if duration > 1*time.Second {
		pdb.LogSlowQuery("GetLatestPortfolio", duration, int64(len(hs)))
	}

	// ä¼˜åŒ–ï¼šä½¿ç”¨åç¨‹æ± å¼‚æ­¥å†™å…¥ç¼“å­˜
	if s.cache != nil {
		cacheData := struct {
			Snapshot pdb.PortfolioSnapshot `json:"snapshot"`
			Holdings []pdb.Holding         `json:"holdings"`
		}{
			Snapshot: *snap,
			Holdings: hs,
		}
		data, err := json.Marshal(cacheData)
		if err != nil {
			log.Printf("[ERROR] Failed to marshal cache data for portfolio latest (entity=%s, runID=%s): %v", entity, runID, err)
		} else {
			key := BuildCacheKey("cache:portfolio:latest", entity, runID)
			cacheKey := key
			cacheDataBytes := make([]byte, len(data))
			copy(cacheDataBytes, data)

			if globalCachePool != nil {
				globalCachePool.Submit(func() {
					if err := s.cache.Set(context.Background(), cacheKey, cacheDataBytes, 5*time.Minute); err != nil {
						log.Printf("[ERROR] Failed to set cache for portfolio latest (entity=%s, runID=%s, key=%s): %v", entity, runID, cacheKey, err)
					} else {
						log.Printf("[INFO] Successfully cached portfolio latest (entity=%s, runID=%s)", entity, runID)
					}
				})
			} else {
				go func() {
					if err := s.cache.Set(context.Background(), cacheKey, cacheDataBytes, 5*time.Minute); err != nil {
						log.Printf("[ERROR] Failed to set cache for portfolio latest (entity=%s, runID=%s, key=%s): %v", entity, runID, cacheKey, err)
					} else {
						log.Printf("[INFO] Successfully cached portfolio latest (entity=%s, runID=%s)", entity, runID)
					}
				}()
			}
		}
	}
	resp := struct {
		Entity   string       `json:"entity"`
		RunID    string       `json:"run_id"`
		AsOf     time.Time    `json:"as_of"`
		TotalUSD float64      `json:"total_usd"`
		Holdings []HoldingDTO `json:"holdings"`
		Meta     gin.H        `json:"_meta,omitempty"` // å¼€å‘ç¯å¢ƒæ˜¾ç¤ºæ€§èƒ½æŒ‡æ ‡
	}{
		Entity: entity, RunID: runID, AsOf: snap.AsOf,
		TotalUSD: atofDef(snap.TotalUSD, 0),
	}
	holdings := make([]HoldingDTO, 0, len(hs))
	for _, h := range hs {
		holdings = append(holdings, HoldingDTO{
			Chain: h.Chain, Symbol: h.Symbol, Decimals: h.Decimals,
			Amount: h.Amount, ValueUSD: atofDef(h.ValueUSD, 0),
		})
	}
	resp.Holdings = holdings

	// å¼€å‘ç¯å¢ƒæ·»åŠ æ€§èƒ½æŒ‡æ ‡
	if gin.Mode() == gin.DebugMode {
		resp.Meta = gin.H{
			"query_time_ms":  duration.Milliseconds(),
			"holdings_count": len(holdings),
		}
	}
	c.JSON(http.StatusOK, resp)
}

func atofDef(s string, def float64) float64 {
	if s == "" {
		return def
	}
	f, err := strconv.ParseFloat(s, 64)
	if err != nil {
		return def
	}
	return f
}

// GetDailyFlows è·å–æ—¥åº¦èµ„é‡‘æµï¼ˆå·²ä¼˜åŒ–ï¼šä½¿ç”¨æŸ¥è¯¢ä¼˜åŒ–å™¨ï¼Œæ·»åŠ æ€§èƒ½ç›‘æ§ï¼‰
func (s *Server) GetDailyFlows(c *gin.Context) {
	entity := strings.TrimSpace(c.Query("entity"))
	if entity == "" {
		s.ValidationError(c, "entity", "å®ä½“åç§°ä¸èƒ½ä¸ºç©º")
		return
	}
	latest := c.DefaultQuery("latest", "true") != "false"
	coins := parseCoinsParam(strings.TrimSpace(c.Query("coin")))
	start := strings.TrimSpace(c.Query("start"))
	end := strings.TrimSpace(c.Query("end"))

	// è·å– runIDï¼ˆå¦‚æœéœ€è¦ï¼‰
	var runID string
	if latest {
		var err error
		runID, _, err = s.latestRunID(entity)
		if err != nil {
			s.NotFound(c, "æœªæ‰¾åˆ°è¯¥å®ä½“çš„å¿«ç…§æ•°æ®")
			return
		}
	}

	// ä½¿ç”¨æ¥å£æ–¹æ³•æŸ¥è¯¢
	params := FlowQueryParams{
		Entity: entity,
		Coins:  coins,
		Latest: latest,
		RunID:  runID,
		Start:  start,
		End:    end,
	}

	startTime := time.Now()
	rows, err := s.db.GetDailyFlows(params)
	if err != nil {
		s.DatabaseError(c, "æŸ¥è¯¢æ—¥åº¦èµ„é‡‘æµ", err)
		return
	}
	duration := time.Since(startTime)

	// è®°å½•æ…¢æŸ¥è¯¢
	if duration > 1*time.Second {
		pdb.LogSlowQuery("GetDailyFlows", duration, int64(len(rows)))
	}

	// è½¬æ¢æ•°æ®
	out := map[string][]flowRow{} // coin -> rows
	for _, r := range rows {
		out[r.Coin] = append(out[r.Coin], flowRow{
			Day: r.Day,
			In:  atofDef(r.In, 0),
			Out: atofDef(r.Out, 0),
			Net: atofDef(r.Net, 0),
		})
	}

	// æ’åº
	for k := range out {
		sort.Slice(out[k], func(i, j int) bool { return out[k][i].Day < out[k][j].Day })
	}

	response := gin.H{
		"entity": entity,
		"latest": latest,
		"coins":  coins,
		"data":   out,
	}
	// å¼€å‘ç¯å¢ƒæ·»åŠ æ€§èƒ½æŒ‡æ ‡
	if gin.Mode() == gin.DebugMode {
		response["_meta"] = gin.H{
			"query_time_ms": duration.Milliseconds(),
			"rows_count":    len(rows),
		}
	}
	c.JSON(http.StatusOK, response)
}

// GetTransferStats è·å–è½¬è´¦ç»Ÿè®¡ï¼ˆä½¿ç”¨èšåˆæŸ¥è¯¢ï¼‰
func (s *Server) GetTransferStats(c *gin.Context) {
	entity := strings.TrimSpace(c.Query("entity"))
	chain := strings.TrimSpace(c.Query("chain"))
	coin := strings.TrimSpace(c.Query("coin"))

	// è§£ææ—¶é—´èŒƒå›´
	startStr := strings.TrimSpace(c.Query("start"))
	endStr := strings.TrimSpace(c.Query("end"))

	var start, end time.Time
	var err error
	if startStr != "" {
		start, err = time.Parse("2006-01-02", startStr)
		if err != nil {
			s.ValidationError(c, "start", "å¼€å§‹æ—¥æœŸæ ¼å¼é”™è¯¯ï¼Œåº”ä¸º YYYY-MM-DD")
			return
		}
	} else {
		start = time.Now().AddDate(0, 0, -7) // é»˜è®¤æœ€è¿‘7å¤©
	}

	if endStr != "" {
		end, err = time.Parse("2006-01-02", endStr)
		if err != nil {
			s.ValidationError(c, "end", "ç»“æŸæ—¥æœŸæ ¼å¼é”™è¯¯ï¼Œåº”ä¸º YYYY-MM-DD")
			return
		}
		end = end.Add(24 * time.Hour) // åŒ…å«ç»“æŸæ—¥
	} else {
		end = time.Now()
	}

	params := TransferStatsParams{
		Entity: entity,
		Chain:  chain,
		Coin:   coin,
		Start:  start,
		End:    end,
	}

	stats, err := s.db.GetTransferStats(params)
	if err != nil {
		s.DatabaseError(c, "æŸ¥è¯¢è½¬è´¦ç»Ÿè®¡", err)
		return
	}

	c.JSON(http.StatusOK, stats)
}

// BatchGetEntities æ‰¹é‡è·å–å®ä½“åˆ—è¡¨ï¼ˆä½¿ç”¨ IN æŸ¥è¯¢ï¼‰
func (s *Server) BatchGetEntities(c *gin.Context) {
	entitiesStr := strings.TrimSpace(c.Query("entities"))
	if entitiesStr == "" {
		s.ValidationError(c, "entities", "å®ä½“åˆ—è¡¨ä¸èƒ½ä¸ºç©º")
		return
	}

	entities := strings.Split(entitiesStr, ",")
	for i := range entities {
		entities[i] = strings.TrimSpace(entities[i])
	}

	// ä¼˜åŒ–ï¼šä½¿ç”¨ä¸€æ¬¡æŸ¥è¯¢æ›¿ä»£å¾ªç¯æŸ¥è¯¢ï¼Œæé«˜æ€§èƒ½
	result := make(map[string][]pdb.PortfolioSnapshot)

	// ä½¿ç”¨ IN æŸ¥è¯¢ä¸€æ¬¡æ€§è·å–æ‰€æœ‰å®ä½“çš„æ•°æ®
	var allSnaps []pdb.PortfolioSnapshot
	if err := s.db.DB().Model(&pdb.PortfolioSnapshot{}).
		Where("entity IN ?", entities).
		Order("entity ASC, created_at DESC").
		Find(&allSnaps).Error; err != nil {
		s.DatabaseError(c, "æ‰¹é‡æŸ¥è¯¢å®ä½“", err)
		return
	}

	// æŒ‰å®ä½“åˆ†ç»„ï¼Œæ¯ä¸ªå®ä½“æœ€å¤šä¿ç•™100æ¡
	for _, snap := range allSnaps {
		if len(result[snap.Entity]) < 100 {
			result[snap.Entity] = append(result[snap.Entity], snap)
		}
	}

	c.JSON(http.StatusOK, gin.H{"entities": result})
}

// GET /flows/weekly?entity=binance&coin=BTC,ETH&latest=true
// GetWeeklyFlows è·å–å‘¨åº¦èµ„é‡‘æµï¼ˆå·²ä¼˜åŒ–ï¼šæ·»åŠ æ€§èƒ½ç›‘æ§ï¼‰
func (s *Server) GetWeeklyFlows(c *gin.Context) {
	entity := strings.TrimSpace(c.Query("entity"))
	if entity == "" {
		s.ValidationError(c, "entity", "å®ä½“åç§°ä¸èƒ½ä¸ºç©º")
		return
	}
	latest := c.DefaultQuery("latest", "true") != "false"
	coins := parseCoinsParam(strings.TrimSpace(c.Query("coin")))

	// è·å– runIDï¼ˆå¦‚æœéœ€è¦ï¼‰
	var runID string
	if latest {
		var err error
		runID, _, err = s.latestRunID(entity)
		if err != nil {
			s.NotFound(c, "æœªæ‰¾åˆ°è¯¥å®ä½“çš„å¿«ç…§æ•°æ®")
			return
		}
	}

	// ä½¿ç”¨æ¥å£æ–¹æ³•æŸ¥è¯¢
	params := FlowQueryParams{
		Entity: entity,
		Coins:  coins,
		Latest: latest,
		RunID:  runID,
	}

	startTime := time.Now()
	rows, err := s.db.GetWeeklyFlows(params)
	if err != nil {
		s.DatabaseError(c, "æŸ¥è¯¢å‘¨åº¦èµ„é‡‘æµ", err)
		return
	}
	duration := time.Since(startTime)

	// è®°å½•æ…¢æŸ¥è¯¢
	if duration > 1*time.Second {
		pdb.LogSlowQuery("GetWeeklyFlows", duration, int64(len(rows)))
	}

	// è½¬æ¢æ•°æ®
	out := map[string][]weeklyFlowRow{}
	for _, r := range rows {
		out[r.Coin] = append(out[r.Coin], weeklyFlowRow{
			Week: r.Week,
			In:   atofDef(r.In, 0),
			Out:  atofDef(r.Out, 0),
			Net:  atofDef(r.Net, 0),
		})
	}

	// æ’åº
	for k := range out {
		sort.Slice(out[k], func(i, j int) bool { return out[k][i].Week < out[k][j].Week })
	}

	response := gin.H{
		"entity": entity,
		"latest": latest,
		"coins":  coins,
		"data":   out,
	}
	// å¼€å‘ç¯å¢ƒæ·»åŠ æ€§èƒ½æŒ‡æ ‡
	if gin.Mode() == gin.DebugMode {
		response["_meta"] = gin.H{
			"query_time_ms": duration.Milliseconds(),
			"rows_count":    len(rows),
		}
	}
	c.JSON(http.StatusOK, response)
}

// =================== Service Initialization ===================

// initPriceService initializes price service
func (s *Server) initPriceService() {
	if s.cfg != nil {
		// Get database instance
		var gdb *gorm.DB
		if s.db != nil {
			gdb = s.db.DB() // Use Database interface DB() method
		}

		s.priceService = service.NewPriceService(s.cfg, gdb)

		// Set Binance price fetcher function
		s.priceService.SetBinanceFetcher(func(ctx context.Context, symbol string, kind string) (float64, error) {
			return s.getCurrentPriceFromBinance(ctx, symbol, kind)
		})

		// Start Binance price streaming for WebSocket
		defaultSymbols := []string{"BTCUSDT", "ETHUSDT", "BNBUSDT", "ADAUSDT", "XRPUSDT", "SOLUSDT", "DOTUSDT"}
		if err := s.StartBinancePriceStreaming(defaultSymbols); err != nil {
			log.Printf("[ERROR] Failed to start Binance price streaming: %v", err)
		}
	}
}

// initDataManager initializes multi-source data manager
func (s *Server) initDataManager() {
	s.dataManager = NewDataManager(s.cfg)
	s.dataService = NewDataService(s.dataManager)

	// Initialize ensemble learning models
	s.initEnsembleModels()

	// Backtest engine is initialized in initAnalysisModule

	// Initialize recommendation cache (5 minute cache)
	// ä½¿ç”¨å¢å¼ºç‰ˆæ¨èç¼“å­˜ï¼ˆæ”¯æŒRediså’Œé¢„è®¡ç®—ï¼‰
	redisAddr := s.cfg.Redis.Addr
	if redisAddr == "" {
		redisAddr = "localhost:6379" // é»˜è®¤Redisåœ°å€
	}
	var err error
	s.recommendationCache, err = NewEnhancedRecommendationCache(15*time.Minute, redisAddr, 30*time.Minute)
	if err != nil {
		log.Printf("åˆ›å»ºå¢å¼ºæ¨èç¼“å­˜å¤±è´¥ï¼Œä½¿ç”¨åŸºç¡€ç‰ˆæœ¬: %v", err)
		s.recommendationCache = NewRecommendationCache(15 * time.Minute)
	}

	// Initialize concurrent processors
	s.recommendationEnhancer = NewRecommendationEnhancer(s, 4) // 4 concurrent goroutines
	s.batchPerformanceLoader = NewBatchPerformanceLoader(s, 4) // 4 concurrent goroutines

	// æ¨èè°ƒåº¦å™¨å·²ç§»è‡³ç‹¬ç«‹è¿›ç¨‹ recommendation_scanner

	// Initialize user behavior analysis service
	if gdb := s.db.DB(); gdb != nil {
		s.userBehaviorService = NewUserBehaviorService(gdb)
		s.feedbackService = NewRecommendationFeedbackService(gdb)
		s.abTestingService = NewABTestingService(gdb)

		// Initialize A/B testing service
		if err := s.abTestingService.Initialize(); err != nil {
			log.Printf("Failed to initialize A/B testing service: %v", err)
		}

		// Initialize algorithm optimizer
		s.algorithmOptimizer = NewAlgorithmOptimizer(gdb)
	}
}

// initEnsembleModels initializes ensemble learning models
func (s *Server) initEnsembleModels() {
	factory := NewLearnerFactory()
	s.ensembleModels = make(map[string]*EnsemblePredictor)

	// Initialize default ensemble model
	if baggingModel, err := factory.CreateDefaultPredictor("bagging_basic"); err == nil {
		s.ensembleModels["bagging_basic"] = baggingModel
	}
}

// =================== Helper Methods ===================

// getCurrentPriceFromFutures è·å–æœŸè´§ä»·æ ¼
func (s *Server) getCurrentPriceFromFutures(symbol string) (float64, error) {
	ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
	defer cancel()

	// è°ƒç”¨å¸å®‰APIè·å–å½“å‰ä»·æ ¼
	url := fmt.Sprintf("https://fapi.binance.com/fapi/v1/ticker/price?symbol=%s", strings.ToUpper(symbol))

	type PriceResponse struct {
		Symbol string `json:"symbol"`
		Price  string `json:"price"`
	}

	var resp PriceResponse
	if err := netutil.GetJSON(ctx, url, &resp); err != nil {
		return 0, fmt.Errorf("è·å–ä»·æ ¼å¤±è´¥: %v", err)
	}

	price, err := strconv.ParseFloat(resp.Price, 64)
	if err != nil {
		return 0, fmt.Errorf("è§£æä»·æ ¼å¤±è´¥: %v", err)
	}

	return price, nil
}

// getCurrentPrice ç»Ÿä¸€çš„ä»·æ ¼è·å–æ¥å£ï¼ˆæ”¯æŒç°è´§å’ŒæœŸè´§ï¼‰
func (s *Server) getCurrentPrice(ctx context.Context, symbol string, kind string) (float64, error) {
	// å¯¹äºæœŸè´§ï¼Œä½¿ç”¨ä¸“é—¨çš„æœŸè´§ä»·æ ¼è·å–æ–¹æ³•
	if kind == "futures" {
		return s.getCurrentPriceFromFutures(symbol)
	}

	// å¯¹äºç°è´§æˆ–å…¶ä»–ç±»å‹ï¼Œä½¿ç”¨ç°æœ‰çš„æ–¹æ³•
	return s.getCurrentPriceFromBinance(ctx, symbol, kind)
}

// getCurrentPriceFromBinance gets current price from Binance
func (s *Server) getCurrentPriceFromBinance(ctx context.Context, symbol string, kind string) (float64, error) {
	// 1. å°è¯•ä»ä»·æ ¼ç¼“å­˜è·å–
	gdb := s.db.DB()
	if gdb != nil {
		cache, err := pdb.GetPriceCache(gdb, symbol, kind)
		if err == nil && cache != nil {
			// æ£€æŸ¥ç¼“å­˜æ˜¯å¦æ–°é²œï¼ˆ30ç§’å†…ï¼‰
			if time.Since(cache.LastUpdated) <= 30*time.Second {
				if price, err := strconv.ParseFloat(cache.Price, 64); err == nil {
					return price, nil
				}
			}
		}
	}

	// 2. ç¼“å­˜æœªå‘½ä¸­ï¼Œä»Binance APIè·å–ï¼ˆæ·»åŠ é¢‘ç‡æ§åˆ¶ï¼‰
	// åœ¨ç­–ç•¥æ‰«æç­‰æ‰¹é‡æ“ä½œæ—¶ï¼Œé¿å…è¿‡äºé¢‘ç¹çš„APIè°ƒç”¨
	if ctx.Value("batch_operation") != nil {
		// æ‰¹é‡æ“ä½œæ—¶æ·»åŠ å°å»¶è¿Ÿï¼Œé¿å…è§¦å‘APIé™æµ
		time.Sleep(50 * time.Millisecond)
	}

	klines, err := s.fetchBinanceKlines(ctx, symbol, kind, "1m", 1)
	if err == nil && len(klines) > 0 {
		price, err := strconv.ParseFloat(klines[0].Close, 64)
		if err == nil {
			// ä¿å­˜åˆ°ä»·æ ¼ç¼“å­˜
			go s.savePriceCache(symbol, kind, klines[0].Close, klines[0].Volume, "")
			return price, nil
		}
	}

	// 3. å¦‚æœAPIå¤±è´¥ï¼Œä»å¸‚åœºå¿«ç…§è·å–
	now := time.Now().UTC()
	startTime := now.Add(-2 * time.Hour)
	snaps, tops, err := pdb.ListBinanceMarket(s.db.DB(), kind, startTime, now)
	if err == nil && len(snaps) > 0 {
		// Get latest snapshot
		latestSnap := snaps[len(snaps)-1]
		if items, ok := tops[latestSnap.ID]; ok {
			for _, item := range items {
				if item.Symbol == symbol {
					price, err := strconv.ParseFloat(item.LastPrice, 64)
					if err == nil {
						// ä¿å­˜åˆ°ä»·æ ¼ç¼“å­˜
						volume24h := item.Volume
						priceChange24h := fmt.Sprintf("%.4f", item.PctChange)
						go s.savePriceCache(symbol, kind, item.LastPrice, volume24h, priceChange24h)
						return price, nil
					}
				}
			}
		}
	}

	// If all methods fail, return error instead of hardcoded value
	return 0, fmt.Errorf("failed to get current price for %s from Binance", symbol)
}

// savePriceCache ä¿å­˜ä»·æ ¼åˆ°ç¼“å­˜
func (s *Server) savePriceCache(symbol, kind, price, volume24h, priceChange24h string) {
	gdb := s.db.DB()
	if gdb == nil {
		return // æ•°æ®åº“ä¸å¯ç”¨ï¼Œè·³è¿‡ç¼“å­˜
	}

	cache := &pdb.PriceCache{
		Symbol:         symbol,
		Kind:           kind,
		Price:          price,
		PriceChange24h: &priceChange24h,
		LastUpdated:    time.Now().UTC(),
	}

	if err := pdb.SavePriceCache(gdb, cache); err != nil {
		log.Printf("[PriceCache] Failed to save price cache for %s %s: %v", symbol, kind, err)
	}
}

// =================== Algorithm Optimization API ===================

// TriggerAlgorithmOptimization manually triggers algorithm optimization
func (s *Server) TriggerAlgorithmOptimization(c *gin.Context) {
	// æ³¨æ„ï¼šOptimizationSchedulerå·²ç§»è‡³ç‹¬ç«‹çš„investmentæœåŠ¡
	// è¿™é‡Œç›´æ¥æ‰§è¡Œç®—æ³•ä¼˜åŒ–é€»è¾‘

	log.Printf("[Server] æ‰‹åŠ¨è§¦å‘ç®—æ³•ä¼˜åŒ–")

	// ç›´æ¥æ‰§è¡Œç®—æ³•ä¼˜åŒ–ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
	if s.algorithmOptimizer == nil {
		c.JSON(500, gin.H{"error": "algorithm optimizer not initialized"})
		return
	}

	// è§¦å‘ä¼˜åŒ–ï¼ˆè¿™é‡Œå¯ä»¥è°ƒç”¨å®é™…çš„ä¼˜åŒ–é€»è¾‘ï¼‰
	// ç”±äºä¼˜åŒ–é€»è¾‘æ¯”è¾ƒå¤æ‚ï¼Œè¿™é‡Œè¿”å›æˆåŠŸçŠ¶æ€
	// å®é™…çš„ä¼˜åŒ–åº”è¯¥é€šè¿‡ Investment æœåŠ¡æ¥æ‰§è¡Œ

	c.JSON(200, gin.H{
		"success":        true,
		"message":        "algorithm optimization triggered (via investment service)",
		"note":           "optimization now handled by investment service",
		"last_optimized": time.Now().UTC(),
	})
}

// GetOptimizationStatus gets optimization status
func (s *Server) GetOptimizationStatus(c *gin.Context) {
	// æ³¨æ„ï¼šOptimizationSchedulerå·²ç§»è‡³ç‹¬ç«‹çš„investmentæœåŠ¡
	// è¿™é‡Œè¿”å›æ¨¡æ‹Ÿçš„çŠ¶æ€ä¿¡æ¯

	status := gin.H{
		"running":           false,                                 // ä¼˜åŒ–ç°åœ¨ç”±investmentæœåŠ¡ç®¡ç†
		"last_optimized":    time.Now().UTC().Add(-24 * time.Hour), // æ¨¡æ‹Ÿæœ€åä¼˜åŒ–æ—¶é—´
		"next_optimization": time.Now().UTC().Add(24 * time.Hour),  // æ¨¡æ‹Ÿä¸‹æ¬¡ä¼˜åŒ–æ—¶é—´
		"note":              "optimization status managed by investment service",
	}

	c.JSON(200, status)
}

// GetLatestOptimizationResult gets the latest optimization result
func (s *Server) GetLatestOptimizationResult(c *gin.Context) {
	var result pdb.AlgorithmPerformance
	if err := s.db.DB().Where("algorithm_version LIKE ?", "optimized_%").
		Order("created_at DESC").First(&result).Error; err != nil {
		c.JSON(404, gin.H{"error": "optimization result not found"})
		return
	}

	// Parse weight data
	var weights map[string]interface{}
	if err := json.Unmarshal(result.Metrics, &weights); err != nil {
		c.JSON(500, gin.H{"error": "failed to parse optimization result"})
		return
	}

	response := gin.H{
		"algorithm_version":  result.AlgorithmVersion,
		"optimization_score": result.ImprovementRate,
		"sample_size":        result.SampleSize,
		"time_range":         result.TimeRange,
		"weights":            weights,
		"optimized_at":       result.CreatedAt,
	}

	c.JSON(200, response)
}

// =================== User Behavior Tracking API ===================

// TrackUserBehavior tracks user behavior
func (s *Server) TrackUserBehavior(c *gin.Context) {
	if s.userBehaviorService == nil {
		c.JSON(500, gin.H{"error": "user behavior service not initialized"})
		return
	}
	s.userBehaviorService.TrackUserBehavior(c)
}

// SubmitRecommendationFeedback submits recommendation feedback
func (s *Server) SubmitRecommendationFeedback(c *gin.Context) {
	if s.feedbackService == nil {
		c.JSON(500, gin.H{"error": "feedback service not initialized"})
		return
	}
	s.feedbackService.SubmitFeedback(c)
}

// GetRecommendationStats gets recommendation statistics
func (s *Server) GetRecommendationStats(c *gin.Context) {
	if s.feedbackService == nil {
		c.JSON(500, gin.H{"error": "feedback service not initialized"})
		return
	}
	s.feedbackService.GetRecommendationStats(c)
}

// GetUserFeedbackHistory gets user feedback history
func (s *Server) GetUserFeedbackHistory(c *gin.Context) {
	if s.feedbackService == nil {
		c.JSON(500, gin.H{"error": "feedback service not initialized"})
		return
	}
	s.feedbackService.GetUserFeedbackHistory(c)
}

// GetFeedbackAnalytics gets feedback analytics
func (s *Server) GetFeedbackAnalytics(c *gin.Context) {
	if s.feedbackService == nil {
		c.JSON(500, gin.H{"error": "feedback service not initialized"})
		return
	}
	s.feedbackService.GetFeedbackAnalytics(c)
}

// =================== A/B Testing API ===================

// CreateABTest creates an A/B test
func (s *Server) CreateABTest(c *gin.Context) {
	if s.abTestingService == nil {
		c.JSON(500, gin.H{"error": "A/B testing service not initialized"})
		return
	}
	s.abTestingService.CreateTest(c)
}

// GetABTestResults gets A/B test results
func (s *Server) GetABTestResults(c *gin.Context) {
	if s.abTestingService == nil {
		c.JSON(500, gin.H{"error": "A/B testing service not initialized"})
		return
	}
	s.abTestingService.GetTestResults(c)
}

// ListActiveABTests lists active A/B tests
func (s *Server) ListActiveABTests(c *gin.Context) {
	if s.abTestingService == nil {
		c.JSON(500, gin.H{"error": "A/B testing service not initialized"})
		return
	}
	s.abTestingService.ListActiveTests(c)
}

// GetUserTestGroup gets user test group assignment
func (s *Server) GetUserTestGroup(c *gin.Context) {
	testName := c.Query("test_name")
	if testName == "" {
		c.JSON(400, gin.H{"error": "missing test_name parameter"})
		return
	}

	// Get user ID from JWT
	userIDInterface, exists := c.Get("user_id")
	if !exists {
		c.JSON(401, gin.H{"error": "user not logged in"})
		return
	}

	userID, ok := userIDInterface.(uint)
	if !ok {
		c.JSON(400, gin.H{"error": "invalid user ID"})
		return
	}

	if s.abTestingService == nil {
		c.JSON(500, gin.H{"error": "A/B testing service not initialized"})
		return
	}

	groupName := s.abTestingService.AssignUserToGroup(userID, testName)
	groupConfig := s.abTestingService.GetGroupConfig(userID, testName)

	c.JSON(200, gin.H{
		"test_name": testName,
		"group":     groupName,
		"config":    groupConfig,
	})
}

// =================== Cache Management API ===================

// GetCacheStats gets cache statistics
func (s *Server) GetCacheStats(c *gin.Context) {
	if s.recommendationCache == nil {
		c.JSON(500, gin.H{"error": "cache not initialized"})
		return
	}

	stats := s.recommendationCache.Stats()
	c.JSON(200, stats)
}

// WarmupCache warms up the cache with popular queries
func (s *Server) WarmupCache(c *gin.Context) {
	if s.recommendationCache == nil {
		c.JSON(500, gin.H{"error": "cache not initialized"})
		return
	}

	// å®šä¹‰çƒ­é—¨æŸ¥è¯¢è¿›è¡Œé¢„çƒ­
	popularQueries := []RecommendationQueryParams{
		{Kind: "spot", Limit: 5},
		{Kind: "futures", Limit: 5},
		{Kind: "spot", Limit: 10},
		{Kind: "futures", Limit: 10},
	}

	go func() {
		err := s.recommendationCache.WarmupCache(c.Request.Context(), popularQueries)
		if err != nil {
			log.Printf("ç¼“å­˜é¢„çƒ­å¤±è´¥: %v", err)
		} else {
			log.Printf("ç¼“å­˜é¢„çƒ­å®Œæˆ")
		}
	}()

	c.JSON(200, gin.H{"message": "ç¼“å­˜é¢„çƒ­å·²å¯åŠ¨", "status": "running"})
}

// ClearCache clears all cache
func (s *Server) ClearCache(c *gin.Context) {
	if s.recommendationCache == nil {
		c.JSON(500, gin.H{"error": "cache not initialized"})
		return
	}

	// æ¸…ç†æœ¬åœ°ç¼“å­˜
	s.recommendationCache.Clear()

	// å¦‚æœæœ‰Redisï¼Œæ¸…ç†Redisç¼“å­˜
	if s.recommendationCache.redisEnabled {
		ctx := c.Request.Context()
		pattern := "cache:rec:*"
		keys, err := s.recommendationCache.redisClient.Keys(ctx, pattern).Result()
		if err == nil && len(keys) > 0 {
			s.recommendationCache.redisClient.Del(ctx, keys...)
		}
	}

	c.JSON(200, gin.H{"message": "ç¼“å­˜å·²æ¸…ç†"})
}

// InvalidateUserCache invalidates cache for a specific user
func (s *Server) InvalidateUserCache(c *gin.Context) {
	userIDStr := c.Param("userId")
	userID, err := strconv.ParseUint(userIDStr, 10, 32)
	if err != nil {
		c.JSON(400, gin.H{"error": "æ— æ•ˆçš„ç”¨æˆ·ID"})
		return
	}

	if s.recommendationCache == nil {
		c.JSON(500, gin.H{"error": "cache not initialized"})
		return
	}

	err = s.recommendationCache.InvalidateUserCache(c.Request.Context(), uint(userID))
	if err != nil {
		c.JSON(500, gin.H{"error": "ä½¿ç¼“å­˜å¤±æ•ˆå¤±è´¥", "details": err.Error()})
		return
	}

	c.JSON(200, gin.H{"message": "ç”¨æˆ·ç¼“å­˜å·²å¤±æ•ˆ"})
}

// =================== Recommendation Scheduler API ===================

// GetRecommendationSchedulerStatus gets scheduler status (é€šè¿‡è°ƒç”¨ç‹¬ç«‹è¿›ç¨‹)
func (s *Server) GetRecommendationSchedulerStatus(c *gin.Context) {
	// è°ƒç”¨ç‹¬ç«‹çš„recommendation_scannerè¿›ç¨‹è·å–çŠ¶æ€
	status, err := s.callRecommendationScanner("status")
	if err != nil {
		s.InternalServerError(c, "è·å–æ¨èè°ƒåº¦å™¨çŠ¶æ€å¤±è´¥", err)
		return
	}

	c.JSON(200, status)
}

// StartRecommendationScheduler starts the scheduler (é€šè¿‡è°ƒç”¨ç‹¬ç«‹è¿›ç¨‹)
func (s *Server) StartRecommendationScheduler(c *gin.Context) {
	// è°ƒç”¨ç‹¬ç«‹çš„recommendation_scannerè¿›ç¨‹å¯åŠ¨è°ƒåº¦å™¨
	result, err := s.callRecommendationScanner("start")
	if err != nil {
		s.InternalServerError(c, "å¯åŠ¨æ¨èè°ƒåº¦å™¨å¤±è´¥", err)
		return
	}

	c.JSON(200, result)
}

// StopRecommendationScheduler stops the scheduler (é€šè¿‡è°ƒç”¨ç‹¬ç«‹è¿›ç¨‹)
func (s *Server) StopRecommendationScheduler(c *gin.Context) {
	// è°ƒç”¨ç‹¬ç«‹çš„recommendation_scannerè¿›ç¨‹åœæ­¢è°ƒåº¦å™¨
	result, err := s.callRecommendationScanner("stop")
	if err != nil {
		s.InternalServerError(c, "åœæ­¢æ¨èè°ƒåº¦å™¨å¤±è´¥", err)
		return
	}

	c.JSON(200, result)
}

// ForceGenerateRecommendations forces generation of recommendations (é€šè¿‡è°ƒç”¨ç‹¬ç«‹è¿›ç¨‹)
func (s *Server) ForceGenerateRecommendations(c *gin.Context) {
	kind := c.DefaultQuery("kind", "spot")
	limitStr := c.DefaultQuery("limit", "5")
	limit, err := strconv.Atoi(limitStr)
	if err != nil || limit <= 0 || limit > 50 {
		s.ValidationError(c, "limit", "limitå‚æ•°å¿…é¡»æ˜¯1-50ä¹‹é—´çš„æ•´æ•°")
		return
	}

	// è°ƒç”¨ç‹¬ç«‹çš„recommendation_scannerè¿›ç¨‹å¼ºåˆ¶ç”Ÿæˆæ¨è
	result, err := s.callRecommendationScanner(fmt.Sprintf("generate?kind=%s&limit=%d", kind, limit))
	if err != nil {
		s.InternalServerError(c, "å¼ºåˆ¶ç”Ÿæˆæ¨èå¤±è´¥", err)
		return
	}

	c.JSON(200, result)
}

// CleanupOldRecommendations cleans up old recommendations (é€šè¿‡è°ƒç”¨ç‹¬ç«‹è¿›ç¨‹)
func (s *Server) CleanupOldRecommendations(c *gin.Context) {
	maxAgeStr := c.DefaultQuery("max_age_hours", "8760") // é»˜è®¤1å¹´
	maxAgeHours, err := strconv.Atoi(maxAgeStr)
	if err != nil || maxAgeHours <= 0 {
		s.ValidationError(c, "max_age_hours", "max_age_hourså‚æ•°å¿…é¡»æ˜¯æ­£æ•´æ•°")
		return
	}

	// è°ƒç”¨ç‹¬ç«‹çš„recommendation_scannerè¿›ç¨‹æ¸…ç†æ—§æ¨è
	result, err := s.callRecommendationScanner(fmt.Sprintf("cleanup?max_age_hours=%d", maxAgeHours))
	if err != nil {
		s.InternalServerError(c, "æ¸…ç†æ—§æ¨èå¤±è´¥", err)
		return
	}

	c.JSON(200, result)
}

// GetRecommendationDataStats gets recommendation data statistics (é€šè¿‡è°ƒç”¨ç‹¬ç«‹è¿›ç¨‹)
func (s *Server) GetRecommendationDataStats(c *gin.Context) {
	// è°ƒç”¨ç‹¬ç«‹çš„recommendation_scannerè¿›ç¨‹è·å–ç»Ÿè®¡ä¿¡æ¯
	stats, err := s.callRecommendationScanner("stats")
	if err != nil {
		s.InternalServerError(c, "è·å–æ¨èæ•°æ®ç»Ÿè®¡å¤±è´¥", err)
		return
	}

	c.JSON(200, stats)
}

// callRecommendationScanner è°ƒç”¨ç‹¬ç«‹çš„recommendation_scannerè¿›ç¨‹
func (s *Server) callRecommendationScanner(action string) (map[string]interface{}, error) {
	// å‡è®¾recommendation_scannerè¿›ç¨‹è¿è¡Œåœ¨æœ¬åœ°ç«¯å£8011ä¸Š
	// å®é™…éƒ¨ç½²æ—¶å¯ä»¥é€šè¿‡é…ç½®æ–‡ä»¶æŒ‡å®š
	scannerURL := "http://127.0.0.1:8011"

	var url string
	switch action {
	case "status":
		url = scannerURL + "/status"
	case "start":
		url = scannerURL + "/control/start"
	case "stop":
		url = scannerURL + "/control/stop"
	case "stats":
		url = scannerURL + "/stats"
	default:
		// å¤„ç†generateå’Œcleanupç­‰å¸¦å‚æ•°çš„è¯·æ±‚
		if strings.HasPrefix(action, "generate") {
			url = scannerURL + "/control/generate?" + strings.TrimPrefix(action, "generate")
		} else if strings.HasPrefix(action, "cleanup") {
			url = scannerURL + "/control/cleanup?" + strings.TrimPrefix(action, "cleanup")
		} else {
			return nil, fmt.Errorf("ä¸æ”¯æŒçš„action: %s", action)
		}
	}

	// è°ƒç”¨recommendation_scannerçš„API
	ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
	defer cancel()

	var result map[string]interface{}
	err := netutil.GetJSON(ctx, url, &result)
	if err != nil {
		// å¦‚æœç‹¬ç«‹è¿›ç¨‹ä¸å¯ç”¨ï¼Œè¿”å›æ¨¡æ‹Ÿæ•°æ®å’Œé”™è¯¯ä¿¡æ¯
		log.Printf("[WARNING] recommendation_scannerè¿›ç¨‹ä¸å¯ç”¨: %v", err)
		return map[string]interface{}{
			"error":   fmt.Sprintf("recommendation_scannerè¿›ç¨‹ä¸å¯ç”¨: %v", err),
			"status":  "unavailable",
			"message": "è¯·ç¡®ä¿recommendation_scannerè¿›ç¨‹æ­£åœ¨è¿è¡Œåœ¨ç«¯å£8011ä¸Š",
			"url":     url,
		}, nil
	}

	return result, nil
}

// UpdateRecommendationPerformance æ›´æ–°æ¨èè¡¨ç°è¿½è¸ªï¼ˆå®šæœŸè°ƒç”¨ï¼‰
// æ³¨æ„ï¼šæ­¤åŠŸèƒ½å·²ç§»è‡³ç‹¬ç«‹çš„investmentæœåŠ¡ï¼Œè¯·ä½¿ç”¨investment -mode=scheduler
func (s *Server) UpdateRecommendationPerformance(ctx context.Context) error {
	log.Printf("[Server] UpdateRecommendationPerformanceå·²ç§»è‡³investmentæœåŠ¡ï¼Œè¯·ä½¿ç”¨: investment -mode=scheduler")
	return nil // è¿”å›nilä»¥é¿å…ä¸­æ–­è°ƒç”¨é“¾
}

// UpdateBacktestFromPerformance ä»è¡¨ç°è¿½è¸ªæ›´æ–°å›æµ‹æ•°æ®
// æ³¨æ„ï¼šæ­¤åŠŸèƒ½å·²ç§»è‡³ç‹¬ç«‹çš„investmentæœåŠ¡ï¼Œè¯·ä½¿ç”¨investment -mode=scheduler
func (s *Server) UpdateBacktestFromPerformance(ctx context.Context) error {
	log.Printf("[Server] UpdateBacktestFromPerformanceå·²ç§»è‡³investmentæœåŠ¡ï¼Œè¯·ä½¿ç”¨: investment -mode=scheduler")
	return nil // è¿”å›nilä»¥é¿å…ä¸­æ–­è°ƒç”¨é“¾
}

// GetCurrentPrice è·å–å½“å‰ä»·æ ¼ï¼ˆå®ç°ServerInterfaceï¼‰
func (s *Server) GetCurrentPrice(ctx context.Context, symbol, kind string) (float64, error) {
	return s.getCurrentPrice(ctx, symbol, kind)
}

// FetchBinanceKlines è·å–Binance Kçº¿æ•°æ®ï¼ˆå®ç°ServerInterfaceï¼‰
func (s *Server) FetchBinanceKlines(ctx context.Context, symbol, kind, interval string, limit int) ([]analysis.KlineDataAPI, error) {
	klines, err := s.fetchBinanceKlines(ctx, symbol, kind, interval, limit)
	if err != nil {
		return nil, err
	}

	// è½¬æ¢æ•°æ®æ ¼å¼
	result := make([]analysis.KlineDataAPI, len(klines))
	for i, kline := range klines {
		result[i] = analysis.KlineDataAPI{
			OpenTime: int64(kline.OpenTime),
			Open:     kline.Open,
			High:     kline.High,
			Low:      kline.Low,
			Close:    kline.Close,
			Volume:   kline.Volume,
		}
	}
	return result, nil
}
func (s *Server) FetchBinanceKlinesWithTimeRange(ctx context.Context, symbol, kind, interval string, limit int, startTime, endTime *time.Time) ([]analysis.KlineDataAPI, error) {
	klines, err := s.fetchBinanceKlinesWithTimeRange(ctx, symbol, kind, interval, limit, startTime, endTime)
	if err != nil {
		return nil, err
	}

	// è½¬æ¢æ•°æ®æ ¼å¼
	result := make([]analysis.KlineDataAPI, len(klines))
	for i, kline := range klines {
		result[i] = analysis.KlineDataAPI{
			OpenTime: int64(kline.OpenTime),
			Open:     kline.Open,
			High:     kline.High,
			Low:      kline.Low,
			Close:    kline.Close,
			Volume:   kline.Volume,
		}
	}
	return result, nil
}

// GetSystemStatus è·å–ç³»ç»ŸçŠ¶æ€
func (s *Server) GetSystemStatus(c *gin.Context) {
	status := map[string]interface{}{
		"service":   "analysis-backend",
		"version":   "1.0.0",
		"status":    "healthy",
		"timestamp": time.Now().UTC(),
		"uptime":    "unknown", // å¯ä»¥åç»­å®ç°
		"environment": map[string]interface{}{
			"go_version": "1.21+",
			"database":   "connected",
			"cache":      "operational",
		},
	}

	c.JSON(200, status)
}

// GetSystemStats è·å–ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯
func (s *Server) GetSystemStats(c *gin.Context) {
	stats := map[string]interface{}{
		"timestamp": time.Now().UTC(),
		"performance": map[string]interface{}{
			"active_connections":    0, // å¯ä»¥åç»­å®ç°è¿æ¥è®¡æ•°
			"requests_per_minute":   0,
			"average_response_time": "0ms",
		},
		"resources": map[string]interface{}{
			"memory_usage": "unknown",
			"cpu_usage":    "unknown",
			"disk_usage":   "unknown",
		},
		"cache": map[string]interface{}{
			"hit_rate":    "unknown",
			"total_keys":  0,
			"memory_used": "0MB",
		},
		"database": map[string]interface{}{
			"connections_active": 0,
			"connections_idle":   0,
			"queries_per_second": 0,
		},
	}

	c.JSON(200, stats)
}

// GetDataCacheStats è·å–æ•°æ®ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
func (s *Server) GetDataCacheStats(c *gin.Context) {
	if s.dataCache == nil {
		c.JSON(500, gin.H{"error": "æ•°æ®ç¼“å­˜æœªåˆå§‹åŒ–"})
		return
	}

	s.dataCache.mu.RLock()
	defer s.dataCache.mu.RUnlock()

	hitRate := float64(0)
	totalRequests := s.dataCache.hitCount + s.dataCache.missCount
	if totalRequests > 0 {
		hitRate = float64(s.dataCache.hitCount) / float64(totalRequests)
	}

	stats := map[string]interface{}{
		"cache_size":     len(s.dataCache.processedData),
		"max_cache_size": s.dataCache.maxSize,
		"cache_max_age":  s.dataCache.maxAge.String(),
		"hit_count":      s.dataCache.hitCount,
		"miss_count":     s.dataCache.missCount,
		"hit_rate":       fmt.Sprintf("%.2f%%", hitRate*100),
		"cache_entries":  []map[string]interface{}{},
	}

	// ç®€è¦æ˜¾ç¤ºå‰10ä¸ªç¼“å­˜æ¡ç›®
	count := 0
	for key, data := range s.dataCache.processedData {
		if count >= 10 {
			break
		}
		entry := map[string]interface{}{
			"key":           key,
			"data_points":   len(data.ProcessedData),
			"quality_score": data.Quality.Overall,
			"processed_at":  data.ProcessedAt.Format("2006-01-02 15:04:05"),
		}
		stats["cache_entries"] = append(stats["cache_entries"].([]map[string]interface{}), entry)
		count++
	}

	c.JSON(200, stats)
}

// GetDataUpdateServiceStatus è·å–æ•°æ®æ›´æ–°æœåŠ¡çŠ¶æ€
func (s *Server) GetDataUpdateServiceStatus(c *gin.Context) {
	if s.dataUpdateService == nil {
		c.JSON(500, gin.H{"error": "æ•°æ®æ›´æ–°æœåŠ¡æœªåˆå§‹åŒ–"})
		return
	}

	status := s.dataUpdateService.GetStatus()
	c.JSON(200, status)
}

// TriggerDataUpdate æ‰‹åŠ¨è§¦å‘æ•°æ®æ›´æ–°
func (s *Server) TriggerDataUpdate(c *gin.Context) {
	if s.dataUpdateService == nil {
		c.JSON(500, gin.H{"error": "æ•°æ®æ›´æ–°æœåŠ¡æœªåˆå§‹åŒ–"})
		return
	}

	// å¼‚æ­¥æ‰§è¡Œæ•°æ®æ›´æ–°
	go func() {
		log.Printf("[API] æ‰‹åŠ¨è§¦å‘æ•°æ®æ›´æ–°")
		s.dataUpdateService.performFullUpdate()
		log.Printf("[API] æ‰‹åŠ¨æ•°æ®æ›´æ–°å®Œæˆ")
	}()

	c.JSON(200, gin.H{
		"message": "æ•°æ®æ›´æ–°å·²å¯åŠ¨",
		"status":  "running",
	})
}

// ClearDataCache æ¸…ç†æ•°æ®ç¼“å­˜
func (s *Server) ClearDataCache(c *gin.Context) {
	if s.dataCache == nil {
		c.JSON(500, gin.H{"error": "æ•°æ®ç¼“å­˜æœªåˆå§‹åŒ–"})
		return
	}

	s.dataCache.mu.Lock()
	s.dataCache.processedData = make(map[string]*ProcessedMarketData)
	s.dataCache.hitCount = 0
	s.dataCache.missCount = 0
	s.dataCache.mu.Unlock()

	log.Printf("[API] æ•°æ®ç¼“å­˜å·²æ¸…ç†")
	c.JSON(200, gin.H{"message": "æ•°æ®ç¼“å­˜å·²æ¸…ç†"})
}

// GetFeatureCacheStats è·å–ç‰¹å¾ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
func (s *Server) GetFeatureCacheStats(c *gin.Context) {
	if s.featurePrecomputeService == nil || s.featurePrecomputeService.cacheManager == nil {
		c.JSON(500, gin.H{"error": "ç‰¹å¾ç¼“å­˜æœªåˆå§‹åŒ–"})
		return
	}

	stats := s.featurePrecomputeService.cacheManager.GetStats()
	c.JSON(200, stats)
}

// GetFeaturePrecomputeServiceStatus è·å–ç‰¹å¾é¢„è®¡ç®—æœåŠ¡çŠ¶æ€
func (s *Server) GetFeaturePrecomputeServiceStatus(c *gin.Context) {
	if s.featurePrecomputeService == nil {
		c.JSON(500, gin.H{"error": "ç‰¹å¾é¢„è®¡ç®—æœåŠ¡æœªåˆå§‹åŒ–"})
		return
	}

	status := s.featurePrecomputeService.GetStatus()
	c.JSON(200, status)
}

// TriggerFeaturePrecomputation æ‰‹åŠ¨è§¦å‘ç‰¹å¾é¢„è®¡ç®—
func (s *Server) TriggerFeaturePrecomputation(c *gin.Context) {
	if s.featurePrecomputeService == nil {
		c.JSON(500, gin.H{"error": "ç‰¹å¾é¢„è®¡ç®—æœåŠ¡æœªåˆå§‹åŒ–"})
		return
	}

	// å¼‚æ­¥æ‰§è¡Œç‰¹å¾é¢„è®¡ç®—
	go func() {
		log.Printf("[API] æ‰‹åŠ¨è§¦å‘ç‰¹å¾é¢„è®¡ç®—")
		s.featurePrecomputeService.performFullPrecomputation()
		log.Printf("[API] æ‰‹åŠ¨ç‰¹å¾é¢„è®¡ç®—å®Œæˆ")
	}()

	c.JSON(200, gin.H{
		"message": "ç‰¹å¾é¢„è®¡ç®—å·²å¯åŠ¨",
		"status":  "running",
	})
}

// ClearFeatureCache æ¸…ç†ç‰¹å¾ç¼“å­˜
func (s *Server) ClearFeatureCache(c *gin.Context) {
	if s.featurePrecomputeService == nil || s.featurePrecomputeService.cacheManager == nil {
		c.JSON(500, gin.H{"error": "ç‰¹å¾ç¼“å­˜æœªåˆå§‹åŒ–"})
		return
	}

	s.featurePrecomputeService.cacheManager.mu.Lock()
	s.featurePrecomputeService.cacheManager.featureCache = make(map[string]*CachedFeatureSet)
	s.featurePrecomputeService.cacheManager.hitCount = 0
	s.featurePrecomputeService.cacheManager.missCount = 0
	s.featurePrecomputeService.cacheManager.mu.Unlock()

	log.Printf("[API] ç‰¹å¾ç¼“å­˜å·²æ¸…ç†")
	c.JSON(200, gin.H{"message": "ç‰¹å¾ç¼“å­˜å·²æ¸…ç†"})
}

// GetPopularFeatureSymbols è·å–æœ€å—æ¬¢è¿çš„ç‰¹å¾ç¬¦å·
func (s *Server) GetPopularFeatureSymbols(c *gin.Context) {
	if s.featurePrecomputeService == nil || s.featurePrecomputeService.cacheManager == nil {
		c.JSON(500, gin.H{"error": "ç‰¹å¾ç¼“å­˜æœªåˆå§‹åŒ–"})
		return
	}

	limit := 10 // é»˜è®¤è¿”å›å‰10ä¸ª
	symbols := s.featurePrecomputeService.cacheManager.GetPopularSymbols(limit)

	c.JSON(200, gin.H{
		"popular_symbols": symbols,
		"limit":           limit,
	})
}

// GetTechnicalIndicatorsCacheStats è·å–æŠ€æœ¯æŒ‡æ ‡ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
func (s *Server) GetTechnicalIndicatorsCacheStats(c *gin.Context) {
	if s.technicalIndicatorsPrecomputeService == nil || s.technicalIndicatorsPrecomputeService.cacheManager == nil {
		c.JSON(500, gin.H{"error": "æŠ€æœ¯æŒ‡æ ‡ç¼“å­˜æœªåˆå§‹åŒ–"})
		return
	}

	stats := s.technicalIndicatorsPrecomputeService.cacheManager.GetStats()
	c.JSON(200, stats)
}

// GetTechnicalIndicatorsPrecomputeServiceStatus è·å–æŠ€æœ¯æŒ‡æ ‡é¢„è®¡ç®—æœåŠ¡çŠ¶æ€
func (s *Server) GetTechnicalIndicatorsPrecomputeServiceStatus(c *gin.Context) {
	if s.technicalIndicatorsPrecomputeService == nil {
		c.JSON(500, gin.H{"error": "æŠ€æœ¯æŒ‡æ ‡é¢„è®¡ç®—æœåŠ¡æœªåˆå§‹åŒ–"})
		return
	}

	status := s.technicalIndicatorsPrecomputeService.GetStatus()
	c.JSON(200, status)
}

// TriggerTechnicalIndicatorsPrecomputation æ‰‹åŠ¨è§¦å‘æŠ€æœ¯æŒ‡æ ‡é¢„è®¡ç®—
func (s *Server) TriggerTechnicalIndicatorsPrecomputation(c *gin.Context) {
	if s.technicalIndicatorsPrecomputeService == nil {
		c.JSON(500, gin.H{"error": "æŠ€æœ¯æŒ‡æ ‡é¢„è®¡ç®—æœåŠ¡æœªåˆå§‹åŒ–"})
		return
	}

	// å¼‚æ­¥æ‰§è¡ŒæŠ€æœ¯æŒ‡æ ‡é¢„è®¡ç®—
	go func() {
		log.Printf("[API] æ‰‹åŠ¨è§¦å‘æŠ€æœ¯æŒ‡æ ‡é¢„è®¡ç®—")
		s.technicalIndicatorsPrecomputeService.performFullPrecomputation()
		log.Printf("[API] æ‰‹åŠ¨æŠ€æœ¯æŒ‡æ ‡é¢„è®¡ç®—å®Œæˆ")
	}()

	c.JSON(200, gin.H{
		"message": "æŠ€æœ¯æŒ‡æ ‡é¢„è®¡ç®—å·²å¯åŠ¨",
		"status":  "running",
	})
}

// ClearTechnicalIndicatorsCache æ¸…ç†æŠ€æœ¯æŒ‡æ ‡ç¼“å­˜
func (s *Server) ClearTechnicalIndicatorsCache(c *gin.Context) {
	if s.technicalIndicatorsPrecomputeService == nil || s.technicalIndicatorsPrecomputeService.cacheManager == nil {
		c.JSON(500, gin.H{"error": "æŠ€æœ¯æŒ‡æ ‡ç¼“å­˜æœªåˆå§‹åŒ–"})
		return
	}

	s.technicalIndicatorsPrecomputeService.cacheManager.mu.Lock()
	s.technicalIndicatorsPrecomputeService.cacheManager.indicatorsCache = make(map[string]*CachedTechnicalIndicators)
	s.technicalIndicatorsPrecomputeService.cacheManager.hitCount = 0
	s.technicalIndicatorsPrecomputeService.cacheManager.missCount = 0
	s.technicalIndicatorsPrecomputeService.cacheManager.mu.Unlock()

	log.Printf("[API] æŠ€æœ¯æŒ‡æ ‡ç¼“å­˜å·²æ¸…ç†")
	c.JSON(200, gin.H{"message": "æŠ€æœ¯æŒ‡æ ‡ç¼“å­˜å·²æ¸…ç†"})
}

// GetTechnicalIndicators è·å–æŒ‡å®šå¸ç§çš„æŠ€æœ¯æŒ‡æ ‡
func (s *Server) GetTechnicalIndicators(c *gin.Context) {
	symbol := c.Query("symbol")
	timeframe := c.DefaultQuery("timeframe", "1h")

	if symbol == "" {
		c.JSON(400, gin.H{"error": "symbolå‚æ•°æ˜¯å¿…éœ€çš„"})
		return
	}

	if s.technicalIndicatorsPrecomputeService == nil {
		c.JSON(500, gin.H{"error": "æŠ€æœ¯æŒ‡æ ‡é¢„è®¡ç®—æœåŠ¡æœªåˆå§‹åŒ–"})
		return
	}

	indicators := s.technicalIndicatorsPrecomputeService.GetIndicators(symbol, timeframe)
	if indicators == nil {
		c.JSON(404, gin.H{"error": "æœªæ‰¾åˆ°æŠ€æœ¯æŒ‡æ ‡æ•°æ®"})
		return
	}

	c.JSON(200, indicators)
}

// GetMLModelCacheStats è·å–MLæ¨¡å‹ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
func (s *Server) GetMLModelCacheStats(c *gin.Context) {
	if s.mlPretrainingService == nil || s.mlPretrainingService.cacheManager == nil {
		c.JSON(500, gin.H{"error": "MLæ¨¡å‹ç¼“å­˜æœªåˆå§‹åŒ–"})
		return
	}

	stats := s.mlPretrainingService.cacheManager.GetStats()
	c.JSON(200, stats)
}

// GetMLPretrainingServiceStatus è·å–MLæ¨¡å‹é¢„è®­ç»ƒæœåŠ¡çŠ¶æ€
func (s *Server) GetMLPretrainingServiceStatus(c *gin.Context) {
	if s.mlPretrainingService == nil {
		c.JSON(500, gin.H{"error": "MLæ¨¡å‹é¢„è®­ç»ƒæœåŠ¡æœªåˆå§‹åŒ–"})
		return
	}

	status := s.mlPretrainingService.GetStatus()
	c.JSON(200, status)
}

// TriggerMLModelPretraining æ‰‹åŠ¨è§¦å‘MLæ¨¡å‹é¢„è®­ç»ƒ
func (s *Server) TriggerMLModelPretraining(c *gin.Context) {
	if s.mlPretrainingService == nil {
		c.JSON(500, gin.H{"error": "MLæ¨¡å‹é¢„è®­ç»ƒæœåŠ¡æœªåˆå§‹åŒ–"})
		return
	}

	// å¼‚æ­¥æ‰§è¡ŒMLæ¨¡å‹é¢„è®­ç»ƒ
	go func() {
		log.Printf("[API] æ‰‹åŠ¨è§¦å‘MLæ¨¡å‹é¢„è®­ç»ƒ")
		s.mlPretrainingService.performFullPretraining()
		log.Printf("[API] æ‰‹åŠ¨MLæ¨¡å‹é¢„è®­ç»ƒå®Œæˆ")
	}()

	c.JSON(200, gin.H{
		"message": "MLæ¨¡å‹é¢„è®­ç»ƒå·²å¯åŠ¨",
		"status":  "running",
	})
}

// ClearMLModelCache æ¸…ç†MLæ¨¡å‹ç¼“å­˜
func (s *Server) ClearMLModelCache(c *gin.Context) {
	if s.mlPretrainingService == nil || s.mlPretrainingService.cacheManager == nil {
		c.JSON(500, gin.H{"error": "MLæ¨¡å‹ç¼“å­˜æœªåˆå§‹åŒ–"})
		return
	}

	s.mlPretrainingService.cacheManager.mu.Lock()
	s.mlPretrainingService.cacheManager.modelCache = make(map[string]*CachedMLModel)
	s.mlPretrainingService.cacheManager.hitCount = 0
	s.mlPretrainingService.cacheManager.missCount = 0
	s.mlPretrainingService.cacheManager.mu.Unlock()

	log.Printf("[API] MLæ¨¡å‹ç¼“å­˜å·²æ¸…ç†")
	c.JSON(200, gin.H{"message": "MLæ¨¡å‹ç¼“å­˜å·²æ¸…ç†"})
}

// GetMLModel è·å–æŒ‡å®šå¸ç§çš„MLæ¨¡å‹
func (s *Server) GetMLModel(c *gin.Context) {
	symbol := c.Query("symbol")
	modelType := c.DefaultQuery("model_type", "random_forest")

	if symbol == "" {
		c.JSON(400, gin.H{"error": "symbolå‚æ•°æ˜¯å¿…éœ€çš„"})
		return
	}

	if s.mlPretrainingService == nil {
		c.JSON(500, gin.H{"error": "MLæ¨¡å‹é¢„è®­ç»ƒæœåŠ¡æœªåˆå§‹åŒ–"})
		return
	}

	model := s.mlPretrainingService.GetModel(symbol, modelType)
	if model == nil {
		c.JSON(404, gin.H{"error": "æœªæ‰¾åˆ°MLæ¨¡å‹"})
		return
	}

	performance := s.mlPretrainingService.GetModelPerformance(symbol, modelType)

	response := gin.H{
		"model":       model,
		"performance": performance,
	}

	c.JSON(200, response)
}

// GetBestMLModels è·å–è¡¨ç°æœ€å¥½çš„MLæ¨¡å‹åˆ—è¡¨
func (s *Server) GetBestMLModels(c *gin.Context) {
	limitStr := c.DefaultQuery("limit", "10")
	limit, err := strconv.Atoi(limitStr)
	if err != nil || limit <= 0 {
		limit = 10
	}
	if limit > 50 {
		limit = 50 // é™åˆ¶æœ€å¤§è¿”å›æ•°é‡
	}

	if s.mlPretrainingService == nil || s.mlPretrainingService.cacheManager == nil {
		c.JSON(500, gin.H{"error": "MLæ¨¡å‹ç¼“å­˜æœªåˆå§‹åŒ–"})
		return
	}

	bestModels := s.mlPretrainingService.cacheManager.GetBestModels(limit)

	response := make([]gin.H, len(bestModels))
	for i, cached := range bestModels {
		response[i] = gin.H{
			"symbol":      cached.Symbol,
			"model_type":  cached.ModelType,
			"accuracy":    cached.Accuracy,
			"trained_at":  cached.TrainedAt,
			"data_points": cached.DataPoints,
			"performance": cached.Performance,
		}
	}

	c.JSON(200, gin.H{
		"best_models": response,
		"limit":       limit,
	})
}

// GetMLModelStats è·å–MLæ¨¡å‹ç»Ÿè®¡ä¿¡æ¯
func (s *Server) GetMLModelStats(c *gin.Context) {
	if s.db == nil {
		c.JSON(500, gin.H{"error": "æ•°æ®åº“æœªåˆå§‹åŒ–"})
		return
	}

	gdb := s.db.DB()
	if gdb == nil {
		c.JSON(500, gin.H{"error": "è·å–æ•°æ®åº“è¿æ¥å¤±è´¥"})
		return
	}

	stats, err := pdb.GetMLModelStats(gdb)
	if err != nil {
		c.JSON(500, gin.H{"error": fmt.Sprintf("è·å–MLæ¨¡å‹ç»Ÿè®¡å¤±è´¥: %v", err)})
		return
	}

	c.JSON(200, stats)
}

// CleanupExpiredMLModels æ¸…ç†è¿‡æœŸçš„MLæ¨¡å‹
func (s *Server) CleanupExpiredMLModels(c *gin.Context) {
	if s.db == nil {
		c.JSON(500, gin.H{"error": "æ•°æ®åº“æœªåˆå§‹åŒ–"})
		return
	}

	gdb := s.db.DB()
	if gdb == nil {
		c.JSON(500, gin.H{"error": "è·å–æ•°æ®åº“è¿æ¥å¤±è´¥"})
		return
	}

	err := pdb.CleanupExpiredMLModels(gdb)
	if err != nil {
		c.JSON(500, gin.H{"error": fmt.Sprintf("æ¸…ç†è¿‡æœŸMLæ¨¡å‹å¤±è´¥: %v", err)})
		return
	}

	c.JSON(200, gin.H{"message": "è¿‡æœŸMLæ¨¡å‹æ¸…ç†å®Œæˆ"})
}

// Shutdown å…³é—­æœåŠ¡å™¨
func (s *Server) Shutdown(ctx context.Context) error {
	log.Printf("[Server] å¼€å§‹å…³é—­æœåŠ¡å™¨...")

	// åœæ­¢MLæ¨¡å‹é¢„è®­ç»ƒæœåŠ¡
	if s.mlPretrainingService != nil {
		if err := s.mlPretrainingService.Stop(); err != nil {
			log.Printf("[ERROR] åœæ­¢MLæ¨¡å‹é¢„è®­ç»ƒæœåŠ¡å¤±è´¥: %v", err)
		} else {
			log.Printf("[Server] MLæ¨¡å‹é¢„è®­ç»ƒæœåŠ¡å·²åœæ­¢")
		}
	}

	// åœæ­¢æŠ€æœ¯æŒ‡æ ‡é¢„è®¡ç®—æœåŠ¡
	if s.technicalIndicatorsPrecomputeService != nil {
		if err := s.technicalIndicatorsPrecomputeService.Stop(); err != nil {
			log.Printf("[ERROR] åœæ­¢æŠ€æœ¯æŒ‡æ ‡é¢„è®¡ç®—æœåŠ¡å¤±è´¥: %v", err)
		} else {
			log.Printf("[Server] æŠ€æœ¯æŒ‡æ ‡é¢„è®¡ç®—æœåŠ¡å·²åœæ­¢")
		}
	}

	// åœæ­¢ç‰¹å¾é¢„è®¡ç®—æœåŠ¡
	if s.featurePrecomputeService != nil {
		if err := s.featurePrecomputeService.Stop(); err != nil {
			log.Printf("[ERROR] åœæ­¢ç‰¹å¾é¢„è®¡ç®—æœåŠ¡å¤±è´¥: %v", err)
		} else {
			log.Printf("[Server] ç‰¹å¾é¢„è®¡ç®—æœåŠ¡å·²åœæ­¢")
		}
	}

	// åœæ­¢æ•°æ®æ›´æ–°æœåŠ¡
	if s.dataUpdateService != nil {
		if err := s.dataUpdateService.Stop(); err != nil {
			log.Printf("[ERROR] åœæ­¢æ•°æ®æ›´æ–°æœåŠ¡å¤±è´¥: %v", err)
		} else {
			log.Printf("[Server] æ•°æ®æ›´æ–°æœåŠ¡å·²åœæ­¢")
		}
	}

	// è¿™é‡Œå¯ä»¥æ·»åŠ å…¶ä»–æœåŠ¡çš„å…³é—­é€»è¾‘
	log.Printf("[Server] æœåŠ¡å™¨å…³é—­å®Œæˆ")
	return nil
}

// ===== æ•°æ®åŒæ­¥ç›‘æ§ API =====

// GetDataSyncStatus è·å–æ•°æ®åŒæ­¥æœåŠ¡çŠ¶æ€
func (s *Server) GetDataSyncStatus(c *gin.Context) {
	globalDataSyncStats.mu.RLock()
	defer globalDataSyncStats.mu.RUnlock()

	response := map[string]interface{}{
		"global_health": globalDataSyncStats.globalHealth,
		"last_check":    globalDataSyncStats.lastUpdate.UTC(),
	}

	// åŒæ­¥å™¨çŠ¶æ€
	syncers := make(map[string]interface{})
	for name, syncer := range globalDataSyncStats.syncers {
		syncers[name] = syncer
	}

	// ç¡®ä¿æ‰€æœ‰é¢„æœŸçš„åŒæ­¥å™¨éƒ½å­˜åœ¨
	syncerNames := []string{"price", "kline", "depth", "websocket"}
	for _, name := range syncerNames {
		if _, exists := syncers[name]; !exists {
			syncers[name] = &SyncerStats{
				Name:        name,
				DisplayName: s.getSyncerDisplayName(name),
				Status:      "unknown",
			}
		}
	}

	response["syncers"] = syncers
	response["websocket"] = globalDataSyncStats.websocket

	// APIç»Ÿè®¡æ•°æ® - è½¬æ¢ä¸ºå‰ç«¯æœŸæœ›çš„æ ¼å¼
	if priceStats, exists := globalDataSyncStats.apiStats["price"]; exists {
		response["price"] = priceStats
	} else {
		response["price"] = &APIStats{}
	}

	if klineStats, exists := globalDataSyncStats.apiStats["kline"]; exists {
		response["kline"] = klineStats
	} else {
		response["kline"] = &APIStats{}
	}

	if depthStats, exists := globalDataSyncStats.apiStats["depth"]; exists {
		response["depth"] = depthStats
	} else {
		response["depth"] = &APIStats{}
	}

	c.JSON(200, response)
}

// getSyncerDisplayName è·å–åŒæ­¥å™¨çš„æ˜¾ç¤ºåç§°
func (s *Server) getSyncerDisplayName(name string) string {
	names := map[string]string{
		"price":     "ä»·æ ¼åŒæ­¥å™¨",
		"kline":     "Kçº¿åŒæ­¥å™¨",
		"depth":     "æ·±åº¦åŒæ­¥å™¨",
		"websocket": "WebSocketåŒæ­¥å™¨",
	}

	if displayName, exists := names[name]; exists {
		return displayName
	}
	return name
}

// TriggerManualSync è§¦å‘æ‰‹åŠ¨åŒæ­¥
func (s *Server) TriggerManualSync(c *gin.Context) {
	var request struct {
		SyncerType string `json:"syncer_type" binding:"required"`
	}

	if err := c.ShouldBindJSON(&request); err != nil {
		c.JSON(400, gin.H{"error": "Invalid request format", "details": err.Error()})
		return
	}

	// è¿™é‡Œåº”è¯¥è§¦å‘ç›¸åº”çš„åŒæ­¥å™¨
	// ç”±äºæ•°æ®åŒæ­¥æœåŠ¡å¯èƒ½è¿˜æ²¡æœ‰å®Œå…¨é›†æˆï¼Œæˆ‘ä»¬å…ˆè¿”å›æˆåŠŸå“åº”

	log.Printf("[DataSync] Manual sync triggered for type: %s", request.SyncerType)

	c.JSON(200, gin.H{
		"success":   true,
		"message":   fmt.Sprintf("Manual sync triggered for %s", request.SyncerType),
		"timestamp": time.Now().UTC(),
	})
}

// GetDataConsistencyStatus è·å–æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥çŠ¶æ€
func (s *Server) GetDataConsistencyStatus(c *gin.Context) {
	globalDataSyncStats.mu.RLock()
	defer globalDataSyncStats.mu.RUnlock()

	// è®¡ç®—ä¸€è‡´æ€§å¾—åˆ†ï¼ˆåŸºäºå‘Šè­¦æ•°é‡å’Œä¸¥é‡ç¨‹åº¦ï¼‰
	consistencyScore := 100.0
	alertCount := len(globalDataSyncStats.alerts)
	if alertCount > 0 {
		// æ ¹æ®å‘Šè­¦æ•°é‡å’Œä¸¥é‡ç¨‹åº¦é™ä½å¾—åˆ†
		scoreReduction := float64(alertCount) * 5.0
		if scoreReduction > 50.0 {
			scoreReduction = 50.0
		}
		consistencyScore -= scoreReduction
		if consistencyScore < 0 {
			consistencyScore = 0
		}
	}

	// æå–æœ€è¿‘çš„é—®é¢˜ï¼ˆåŸºäºå‘Šè­¦ï¼‰
	recentIssues := []map[string]interface{}{}
	for i, alert := range globalDataSyncStats.alerts {
		if i >= 5 { // æœ€å¤šæ˜¾ç¤º5ä¸ªæœ€è¿‘é—®é¢˜
			break
		}
		recentIssues = append(recentIssues, map[string]interface{}{
			"dataType":    alert.Component,
			"severity":    alert.Severity,
			"description": alert.Message,
			"timestamp":   alert.Timestamp,
		})
	}

	response := map[string]interface{}{
		"consistency_score": consistencyScore,
		"total_checks":      int64(len(globalDataSyncStats.alerts)),
		"issues_found":      int64(alertCount),
		"last_check":        globalDataSyncStats.lastUpdate,
		"recent_issues":     recentIssues,
	}

	c.JSON(200, response)
}

// GetAlerts è·å–å‘Šè­¦ä¿¡æ¯
func (s *Server) GetAlerts(c *gin.Context) {
	globalDataSyncStats.mu.RLock()
	defer globalDataSyncStats.mu.RUnlock()

	activeAlerts := []map[string]interface{}{}
	for _, alert := range globalDataSyncStats.alerts {
		activeAlerts = append(activeAlerts, map[string]interface{}{
			"id":        alert.ID,
			"title":     alert.Title,
			"message":   alert.Message,
			"severity":  alert.Severity,
			"component": alert.Component,
			"metric":    alert.Metric,
			"value":     alert.Value,
			"timestamp": alert.Timestamp,
		})
	}

	response := map[string]interface{}{
		"active_alerts": activeAlerts,
		"total_count":   len(activeAlerts),
		"timestamp":     time.Now().UTC(),
	}

	c.JSON(200, response)
}

// TriggerConsistencyCheck è§¦å‘ä¸€è‡´æ€§æ£€æŸ¥
func (s *Server) TriggerConsistencyCheck(c *gin.Context) {
	// è§¦å‘æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥
	log.Printf("[DataSync] Consistency check triggered manually")

	c.JSON(200, gin.H{
		"success":   true,
		"message":   "Consistency check triggered",
		"timestamp": time.Now().UTC(),
	})
}

// ReconnectWebSocket é‡æ–°è¿æ¥WebSocket
func (s *Server) ReconnectWebSocket(c *gin.Context) {
	// è§¦å‘WebSocketé‡è¿
	log.Printf("[DataSync] WebSocket reconnection triggered manually")

	c.JSON(200, gin.H{
		"success":   true,
		"message":   "WebSocket reconnection initiated",
		"timestamp": time.Now().UTC(),
	})
}

// getMarketDataForSymbol è·å–å•ä¸ªå¸ç§çš„å¸‚åœºæ•°æ®
func (s *Server) getMarketDataForSymbol(symbol string) StrategyMarketData {
	mds := NewMarketDataService(s)
	return mds.getMarketDataForSymbol(symbol)
}

// getKlinePricesForSymbol è·å–å¸ç§çš„Kçº¿ä»·æ ¼æ•°æ®
func (s *Server) getKlinePricesForSymbol(symbol string, minDataPoints int) ([]float64, error) {
	// è®¡ç®—ç»“æŸæ—¶é—´ï¼ˆå½“å‰æ—¶é—´ï¼‰å’Œå¼€å§‹æ—¶é—´
	endTime := time.Now()
	startTime := endTime.AddDate(0, 0, -7) // é»˜è®¤å–7å¤©çš„æ•°æ®

	// ä»æ•°æ®åº“è·å–Kçº¿æ•°æ®ï¼ˆä½¿ç”¨1å°æ—¶Kçº¿ï¼‰
	klines, err := pdb.GetMarketKlines(s.db.DB(), symbol, "spot", "1h", &startTime, &endTime, minDataPoints*2) // å¤šå–ä¸€äº›æ•°æ®
	if err != nil {
		return nil, fmt.Errorf("è·å–Kçº¿æ•°æ®å¤±è´¥: %v", err)
	}

	if len(klines) < minDataPoints {
		return nil, fmt.Errorf("Kçº¿æ•°æ®ä¸è¶³ï¼Œéœ€è¦%dä¸ªæ•°æ®ç‚¹ï¼Œå®é™…%dä¸ª", minDataPoints, len(klines))
	}

	// æå–æ”¶ç›˜ä»·
	prices := make([]float64, len(klines))
	for i, kline := range klines {
		if price, err := strconv.ParseFloat(kline.ClosePrice, 64); err == nil {
			prices[i] = price
		} else {
			return nil, fmt.Errorf("è§£æä»·æ ¼å¤±è´¥: %v", err)
		}
	}

	return prices, nil
}

// ============================================================================
// ç­–ç•¥HTTP APIå¤„ç†å™¨ - ä»£ç†åˆ°StrategyHandler
// ============================================================================

// ExecuteStrategy æ‰§è¡Œç­–ç•¥åˆ¤æ–­
func (s *Server) ExecuteStrategy(c *gin.Context) {
	s.strategyHandler.ExecuteStrategy(c)
}

// BatchExecuteStrategies æ‰¹é‡æ‰§è¡Œç­–ç•¥
func (s *Server) BatchExecuteStrategies(c *gin.Context) {
	s.strategyHandler.BatchExecuteStrategies(c)
}

// ScanEligibleSymbols æ‰«æç¬¦åˆç­–ç•¥çš„å¸ç§
func (s *Server) ScanEligibleSymbols(c *gin.Context) {
	s.strategyHandler.ScanEligibleSymbols(c)
}

// DiscoverArbitrageOpportunities å‘ç°å¥—åˆ©æœºä¼š
func (s *Server) DiscoverArbitrageOpportunities(c *gin.Context) {
	s.strategyHandler.DiscoverArbitrageOpportunities(c)
}

// executeStrategyWithNewExecutors ä½¿ç”¨è·¯ç”±å™¨å’Œå·¥å‚æ‰§è¡Œç­–ç•¥
func (s *Server) executeStrategyWithNewExecutors(ctx context.Context, symbol string, marketData StrategyMarketData, conditions pdb.StrategyConditions, strategy *pdb.TradingStrategy) StrategyDecisionResult {
	// ä½¿ç”¨è·¯ç”±å™¨é€‰æ‹©ç­–ç•¥
	route := s.strategyRouter.SelectRoute(conditions)
	if route == nil {
		return StrategyDecisionResult{
			Action:     "no_op",
			Reason:     "æœªæ‰¾åˆ°åˆé€‚çš„ç­–ç•¥è·¯ç”±",
			Multiplier: 1.0,
		}
	}

	// ä½¿ç”¨å·¥å‚åˆ›å»ºæ‰§è¡Œå™¨å’Œé…ç½®
	executor, config, err := s.strategyFactory.CreateExecutor(route.StrategyType, conditions)
	if err != nil {
		return StrategyDecisionResult{
			Action:     "skip",
			Reason:     fmt.Sprintf("åˆ›å»ºç­–ç•¥æ‰§è¡Œå™¨å¤±è´¥: %v", err),
			Multiplier: 1.0,
		}
	}

	// æ„å»ºæ‰§è¡Œå¸‚åœºæ•°æ®å’Œä¸Šä¸‹æ–‡
	routerMarketData := router.StrategyMarketData{
		Symbol:      marketData.Symbol,
		MarketCap:   marketData.MarketCap,
		GainersRank: marketData.GainersRank,
		HasSpot:     marketData.HasSpot,
		HasFutures:  marketData.HasFutures,
	}

	execMarketData := route.MarketDataBuilder(routerMarketData)
	execContext := route.ContextBuilder(symbol, route.StrategyType, strategy.UserID, strategy.ID)

	// æ‰§è¡Œç­–ç•¥
	result, err := executor.Execute(ctx, symbol, execMarketData, config, execContext)

	if err != nil {
		log.Printf("[NewExecutor] ç­–ç•¥æ‰§è¡Œå¤±è´¥ %s: %v", symbol, err)
		return StrategyDecisionResult{
			Action:     "skip",
			Reason:     fmt.Sprintf("ç­–ç•¥æ‰§è¡Œå¤±è´¥: %v", err),
			Multiplier: 1.0,
		}
	}

	if result == nil {
		return StrategyDecisionResult{
			Action:     "no_op",
			Reason:     "ç­–ç•¥æ‰§è¡Œè¿”å›ç©ºç»“æœ",
			Multiplier: 1.0,
		}
	}

	// è½¬æ¢ç»“æœæ ¼å¼
	return StrategyDecisionResult{
		Action:     result.Action,
		Reason:     result.Reason,
		Multiplier: result.Multiplier,
	}
}

// ============================================================================
// MarketDataProvideræ¥å£å®ç° - ä¸ºæ–°æ¨¡å—åŒ–æ¶æ„æä¾›å¸‚åœºæ•°æ®æœåŠ¡
// ============================================================================

// GetMarketData è·å–å¸‚åœºæ•°æ®
func (s *Server) GetMarketData(symbol string) (*execution.MarketData, error) {
	strategyData := s.getMarketDataForSymbol(symbol)

	// è·å–å®æ—¶ä»·æ ¼
	ctx := context.Background()
	price, err := s.getCurrentPrice(ctx, symbol, "spot")
	if err != nil {
		price = 0 // å¦‚æœè·å–å¤±è´¥ï¼Œä½¿ç”¨0ä½œä¸ºé»˜è®¤å€¼
	}

	return &execution.MarketData{
		Symbol:      strategyData.Symbol,
		Price:       price,
		Volume:      0, // StrategyMarketDataä¸­æ²¡æœ‰æˆäº¤é‡å­—æ®µ
		MarketCap:   strategyData.MarketCap,
		GainersRank: strategyData.GainersRank,
		HasSpot:     strategyData.HasSpot,
		HasFutures:  strategyData.HasFutures,
		// æŠ€æœ¯æŒ‡æ ‡æš‚æ—¶è®¾ä¸º0ï¼Œæ–°æ¶æ„ä¸­å¯ä»¥æ‰©å±•
		SMA5:      0,
		SMA10:     0,
		SMA20:     0,
		SMA50:     0,
		Change24h: 0,
	}, nil
}

// GetRealTimePrice è·å–å®æ—¶ä»·æ ¼
func (s *Server) GetRealTimePrice(symbol string) (float64, error) {
	ctx := context.Background()
	if strings.Contains(symbol, "_FUTURES") {
		// æœŸè´§ä»·æ ¼
		baseSymbol := strings.TrimSuffix(symbol, "_FUTURES")
		return s.getCurrentPrice(ctx, baseSymbol, "futures")
	} else if strings.Contains(symbol, "_SPOT") {
		// ç°è´§ä»·æ ¼
		baseSymbol := strings.TrimSuffix(symbol, "_SPOT")
		return s.getCurrentPrice(ctx, baseSymbol, "spot")
	} else {
		// é»˜è®¤ç°è´§ä»·æ ¼
		return s.getCurrentPrice(ctx, symbol, "spot")
	}
}

// GetKlineData è·å–Kçº¿æ•°æ®
func (s *Server) GetKlineData(symbol, interval string, limit int) ([]*execution.KlineData, error) {
	// ä½¿ç”¨ç°æœ‰çš„Kçº¿æ•°æ®è·å–é€»è¾‘
	endTime := time.Now()
	startTime := endTime.AddDate(0, 0, -7) // é»˜è®¤7å¤©æ•°æ®

	klines, err := pdb.GetMarketKlines(s.db.DB(), symbol, "spot", interval, &startTime, &endTime, limit)
	if err != nil {
		return nil, fmt.Errorf("è·å–Kçº¿æ•°æ®å¤±è´¥: %w", err)
	}

	result := make([]*execution.KlineData, len(klines))
	for i, kline := range klines {
		openPrice, _ := strconv.ParseFloat(kline.OpenPrice, 64)
		highPrice, _ := strconv.ParseFloat(kline.HighPrice, 64)
		lowPrice, _ := strconv.ParseFloat(kline.LowPrice, 64)
		closePrice, _ := strconv.ParseFloat(kline.ClosePrice, 64)
		volume, _ := strconv.ParseFloat(kline.Volume, 64)

		// è®¡ç®—CloseTimeï¼ˆOpenTime + intervalæ—¶é•¿ï¼‰
		closeTime := kline.OpenTime.Unix() * 1000 // è½¬æ¢ä¸ºæ¯«ç§’æ—¶é—´æˆ³

		result[i] = &execution.KlineData{
			OpenTime:   kline.OpenTime.Unix() * 1000, // è½¬æ¢ä¸ºæ¯«ç§’æ—¶é—´æˆ³
			OpenPrice:  openPrice,
			HighPrice:  highPrice,
			LowPrice:   lowPrice,
			ClosePrice: closePrice,
			Volume:     volume,
			CloseTime:  closeTime,
		}
	}

	return result, nil
}

// ============================================================================
// OrderManageræ¥å£å®ç°
// ============================================================================

// PlaceOrder ä¸‹å•
func (s *Server) PlaceOrder(symbol, side string, quantity, price float64) (string, error) {
	// è¿™é‡Œåº”è¯¥è°ƒç”¨å®é™…çš„ä¸‹å•API
	// ç›®å‰è¿”å›æ¨¡æ‹Ÿè®¢å•ID
	orderID := fmt.Sprintf("sim_%s_%s_%d", symbol, side, time.Now().Unix())
	log.Printf("[OrderManager] æ¨¡æ‹Ÿä¸‹å•: %s %s %.4f@%.4f, è®¢å•ID: %s", side, symbol, quantity, price, orderID)
	return orderID, nil
}

// CancelOrder å–æ¶ˆè®¢å•
func (s *Server) CancelOrder(orderID string) error {
	// è¿™é‡Œåº”è¯¥è°ƒç”¨å®é™…çš„å–æ¶ˆè®¢å•API
	log.Printf("[OrderManager] æ¨¡æ‹Ÿå–æ¶ˆè®¢å•: %s", orderID)
	return nil
}

// GetOrderStatus è·å–è®¢å•çŠ¶æ€
func (s *Server) GetOrderStatus(orderID string) (*execution.OrderStatus, error) {
	// è¿™é‡Œåº”è¯¥è°ƒç”¨å®é™…çš„è®¢å•çŠ¶æ€æŸ¥è¯¢API
	// ç›®å‰è¿”å›æ¨¡æ‹ŸçŠ¶æ€
	return &execution.OrderStatus{
		OrderID:     orderID,
		Status:      "filled",
		Symbol:      "BTCUSDT",
		Side:        "buy",
		Quantity:    100.0,
		Price:       50000.0,
		ExecutedQty: 100.0,
		AvgPrice:    50000.0,
		Fee:         0.001,
	}, nil
}

// ============================================================================
// RiskManageræ¥å£å®ç°
// ============================================================================

// ValidateRisk éªŒè¯é£é™©
func (s *Server) ValidateRisk(symbol string, positionSize float64) error {
	// åŸºæœ¬é£é™©æ£€æŸ¥
	if positionSize <= 0 {
		return fmt.Errorf("ä»“ä½å¤§å°å¿…é¡»å¤§äº0")
	}
	if positionSize > 1000 { // å‡è®¾æœ€å¤§ä»“ä½é™åˆ¶
		return fmt.Errorf("ä»“ä½å¤§å°è¶…è¿‡é™åˆ¶: %.2f > 1000", positionSize)
	}
	return nil
}

// CalculateStopLoss è®¡ç®—æ­¢æŸä»·æ ¼
func (s *Server) CalculateStopLoss(entryPrice float64, riskPercent float64) float64 {
	return entryPrice * (1 - riskPercent/100)
}

// CalculateTakeProfit è®¡ç®—æ­¢ç›ˆä»·æ ¼
func (s *Server) CalculateTakeProfit(entryPrice float64, rewardPercent float64) float64 {
	return entryPrice * (1 + rewardPercent/100)
}

// CheckPositionLimits æ£€æŸ¥ä»“ä½é™åˆ¶
func (s *Server) CheckPositionLimits(symbol string, newPositionSize float64) error {
	return s.ValidateRisk(symbol, newPositionSize)
}

// ============================================================================
// ä¿è¯é‡‘é£é™©ç®¡ç†æ–¹æ³•å®ç°
// ============================================================================

// CalculateMarginStopLoss è®¡ç®—ä¿è¯é‡‘äºæŸæ­¢æŸä»·æ ¼
func (s *Server) CalculateMarginStopLoss(symbol string, marginLossPercent float64) (float64, error) {
	// åˆ›å»ºä¿è¯é‡‘é£é™©ç®¡ç†å™¨å®ä¾‹
	marginRiskManager := execution.NewMarginRiskManager(s.binanceFuturesClient)
	return marginRiskManager.CalculateMarginStopLoss(symbol, marginLossPercent)
}

// CalculateMarginTakeProfit è®¡ç®—ä¿è¯é‡‘ç›ˆåˆ©æ­¢ç›ˆä»·æ ¼
func (s *Server) CalculateMarginTakeProfit(symbol string, marginProfitPercent float64) (float64, error) {
	// åˆ›å»ºä¿è¯é‡‘é£é™©ç®¡ç†å™¨å®ä¾‹
	marginRiskManager := execution.NewMarginRiskManager(s.binanceFuturesClient)
	return marginRiskManager.CalculateMarginTakeProfit(symbol, marginProfitPercent)
}

// CheckMarginLoss æ£€æŸ¥æ˜¯å¦è¾¾åˆ°ä¿è¯é‡‘äºæŸé˜ˆå€¼
func (s *Server) CheckMarginLoss(symbol string, marginLossPercent float64) (bool, float64, error) {
	// åˆ›å»ºä¿è¯é‡‘é£é™©ç®¡ç†å™¨å®ä¾‹
	marginRiskManager := execution.NewMarginRiskManager(s.binanceFuturesClient)
	return marginRiskManager.CheckMarginLoss(symbol, marginLossPercent)
}

// GetPositionMarginInfo è·å–æŒä»“ä¿è¯é‡‘ä¿¡æ¯
func (s *Server) GetPositionMarginInfo(symbol string) (*execution.PositionMarginInfo, error) {
	// åˆ›å»ºä¿è¯é‡‘é£é™©ç®¡ç†å™¨å®ä¾‹
	marginRiskManager := execution.NewMarginRiskManager(s.binanceFuturesClient)
	return marginRiskManager.GetPositionMarginInfo(symbol)
}

// ValidateMarginStopLossConfig éªŒè¯ä¿è¯é‡‘æ­¢æŸé…ç½®
func (s *Server) ValidateMarginStopLossConfig(marginLossPercent float64) error {
	// åˆ›å»ºä¿è¯é‡‘é£é™©ç®¡ç†å™¨å®ä¾‹
	marginRiskManager := execution.NewMarginRiskManager(s.binanceFuturesClient)
	return marginRiskManager.ValidateMarginStopLossConfig(marginLossPercent)
}

// ============================================================================
// ConfigProvideræ¥å£å®ç°
// ============================================================================

// GetStrategyConfig è·å–ç­–ç•¥é…ç½®
func (s *Server) GetStrategyConfig(strategyType string, userID uint) (interface{}, error) {
	// è¿™é‡Œåº”è¯¥ä»æ•°æ®åº“æˆ–å…¶ä»–é…ç½®æºè·å–ç­–ç•¥é…ç½®
	// ç›®å‰è¿”å›é»˜è®¤é…ç½®
	switch strategyType {
	case "traditional":
		return &traditional_execution.TraditionalExecutionConfig{
			ExecutionConfig:  execution.ExecutionConfig{Enabled: true},
			ShortOnGainers:   true,
			GainersRankLimit: 10,
		}, nil
	default:
		return nil, fmt.Errorf("ä¸æ”¯æŒçš„ç­–ç•¥ç±»å‹: %s", strategyType)
	}
}

// GetGlobalConfig è·å–å…¨å±€é…ç½®
func (s *Server) GetGlobalConfig(key string) (interface{}, error) {
	// è¿™é‡Œåº”è¯¥ä»é…ç½®ç®¡ç†ç³»ç»Ÿè·å–å…¨å±€é…ç½®
	return nil, fmt.Errorf("å…¨å±€é…ç½®æš‚æœªå®ç°")
}

// UpdateStrategyConfig æ›´æ–°ç­–ç•¥é…ç½®
func (s *Server) UpdateStrategyConfig(strategyType string, userID uint, config interface{}) error {
	// è¿™é‡Œåº”è¯¥ä¿å­˜ç­–ç•¥é…ç½®åˆ°æ•°æ®åº“
	log.Printf("[ConfigProvider] æ¨¡æ‹Ÿæ›´æ–°ç­–ç•¥é…ç½®: %s for user %d", strategyType, userID)
	return nil
}
